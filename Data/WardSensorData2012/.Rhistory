dev.new(height=4.5, width=7)#
par(mfrow=c(2,3), family="Times", mar=c(4,3,1,1), oma=c(2,2,0,0), cex.axis=1.25)#
plot(RollTimeIndex, TrueRollVar, bty="l", xlab="", ylab="")#
mtext("Variance", side=2,line=3, cex=1.5)#
plot(RollTimeIndex, Chl_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Metab_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2], bty="l", xlab="", ylab="")#
mtext("AR(1)", side=2,line=3, cex=1.5)#
mtext(expression(True~sigma[epsilon]^2*","~phi1[1]), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Chl_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(Chl*"-"*italic(a)), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Metab_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(widehat(M)*etabolism), side=1, line=4, cex=1.5)#
#
# LoopCounter <- LoopCounter + 1#
# LoopProgress <- LoopCounter/zzCounter#
# LoopElapsed <- (proc.time() - StartLoopTime)[[3]]/60#
# print(c("Elapsed"=round(LoopElapsed,1),"%Complete"=round(LoopProgress*100,1), "ETA"=round(LoopElapsed/LoopProgress-LoopElapsed,1), "LaYe"=paste(Lakes[La],Years[Ye],sep="_")))#
#
# dev.new()#
# plot(TrueRollVar, sqrt(Metab_RollVar))#
# summary(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# #
# dev.new()#
# plot(TrueRollAR1, Metab_RollAR1)#
# summary(lm(Metab_RollAR1~TrueRollAR1))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(Metab_RollAR1~TrueRollAR1))
#Ryan Batt#
#26-April-2012#
#Steve suggested using a toy model to assess how the noise can mask a squeal signal in metabolism, when the signal is seen in Chl#
#
# =============================================================#
# = Steve's suggested "simplest toy model of the GPP problem" =#
# =============================================================#
#Squeal Signal for Chl:#
#Chl[t+1] = Phi[t]*Chl[t] + Eps[t]#
#Phi[t] = 1 - exp(-K_Phi*t)  #Note that Phi grows asymptotically to 1#
#Sigma2_Eps[t] = K_Eps*t #The variance of the Chl autoregressive process grows over time#
#
#GPP + Junk Noise#
#DO[t+1] = K_GPP*DO[t] - K_DO*(DO[t] - DO[1]) + Junk[t]#
#Metab_hat = DO[t+1] - DO[t]#
#
rm(list=ls())#
graphics.off()#
require("zoo")#
#
Ar1 <-function(x){#
Nrmlzd <- x-mean(x)#
Y <- (x-mean(x))[-1]#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
}#
Ar1_Detrended <-function(x){#
#First detrend, if needed#
Model <- lm(x~c(1:length(x)))#
Summary <- coef(summary(Model))#
Slope <- Summary[2,1]#
PValue <- Summary[2,4]#
if(PValue<0.05){#
Xnew <- x-(Slope*c(1:length(x)))#
}else{#
Xnew <- x#
}#
#Calculate AR(1)#
Nrmlzd <- Xnew-mean(Xnew)#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(Xnew)])$coef[[2]])#
}#
#
# StartLoopTime <- proc.time()#
#
# RepsPerVar <- 3#
# JunkVarianceS <- seq(1E-6, 1E6, length.out=100)#
NStepsDefault <- 1000#
JunkVariance <- 1E-2#
#
#
WindowSize <- 40#
RollTimeIndex <- 1:(NStepsDefault - (WindowSize-1))#
#
#
#
#Fiddling to find a way to "slowly" increase phi#
# Nsteps=1000#
# Time <- 1:Nsteps#
# K_Phi = -(log(0.5*(-0.95 + 1)))/(Nsteps) #-(log(-0.999 + 1.5)-2)/(Nsteps)#
# Phi <- 1 - 0.5*exp(-K_Phi*Time)  #1.5 - exp(-K_Phi*Time+2) #
# plot(Time, Phi)#
#
Chl_Model <- function(K_Phi=-(log(0.5*(-0.95 + 1)))/(Nsteps), K_Eps=1E-5, K_DO=0.5, Junk_Var=JunkVariance, Nsteps=NStepsDefault){#
Time <- 1:Nsteps#
Chl_0 <- 5 #A reasonable concentration of chlorophyll for Peter Lake in units of μg/L#
DO_0 <- 250 #A reasonable concentration of dissolved oxygen when O2 is near saturation at a typical temperature in Peter Lake, in units of μmols/L (is equal to 8 mg/L)#
#
Chl <- c(Chl_0,rep(NA,Nsteps-1))#
DO <- c(DO_0, rep(NA, Nsteps-1))#
#
Phi <- 1 - 0.5*exp(-K_Phi*Time)#
Sigma2_Eps <- K_Eps*Time#
#
K_GPP_t <- rep(NA,Nsteps)#
Junk <- rnorm(n=Nsteps, mean=0, sd=sqrt(Junk_Var))#
Metab_hat <- rep(NA,Nsteps-1)#
#
for(i in 1:(Nsteps-1)){#
Eps <- rnorm(n=1, mean=0, sd=sqrt(Sigma2_Eps[i]))#
Chl[i+1] <- Phi[i]*Chl[i] + Eps + Chl_0*(1-Phi[i]) #AR(1) plus noise model, with changing AR(1) coefficient and centered around a time series mean of Chl_0#
#
K_GPP_t[i] <- 1+log(Chl[i]/Chl_0) #The idea here is to allow [DO] to grow with the log ratio of current chlorophyll to the inital value of chlorophyll (supporting the notion that the system is at equilibrium when Chlorophyll and DO are at their initial values--- when chlorophyll is higher than its initial value, DO will increase; when chlorophyll is lower than its initial value, DO will decrease)#
DO[i+1] <- K_GPP_t[i]*DO[i] -K_DO*(DO[i]-DO_0) + Junk[i]#
Metab_hat[i] <- DO[i+1] - DO[i]#FIXME this should probably just be Metab_hat[i], but I did the +1 so that the last value wasn't NA#
#
}#
return(list("Chl"=matrix(data=c(Time,Chl), ncol=2),"K_GPP_t"=matrix(data=c(Time,K_GPP_t), ncol=2), "DO"=matrix(data=c(Time,DO), ncol=2), "Metab_hat"=matrix(data=c(Time[-length(Time)],Metab_hat), ncol=2), "True_Sigma2_Eps"=matrix(data=c(Time,Sigma2_Eps), ncol=2), "True_Phi"=matrix(data=c(Time,Phi), ncol=2)))#
#
#
}#
#
Test <- Chl_Model()#
dev.new()#
par(mfrow=c(2,2), mar=c(4,5,1,1))#
plot(Test[[1]], col="forestgreen", bty="l", ylab="Chl", xlab="", xaxt="n")#
plot(Test[[2]], ylab="K_GPP_t", xlab="", pch=20, bty="l", xaxt="n")#
plot(Test[[3]], ylab="DO", xlab="", bty="l")#
plot(Test[[4]], ylab="Metab_hat", xlab="", bty="l")#
#
Chl_RollVar <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=var)#
Chl_RollAR1 <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=Ar1_Detrended)#
#
Metab_RollVar <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=var)#
Metab_RollAR1 <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=Ar1_Detrended)#
#
TrueRollVar <- Test[[5]][is.element(Test[[5]][,1], RollTimeIndex),2]#
TrueRollAR1 <- Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2]#
#
dev.new(height=4.5, width=7)#
par(mfrow=c(2,3), family="Times", mar=c(4,3,1,1), oma=c(2,2,0,0), cex.axis=1.25)#
plot(RollTimeIndex, TrueRollVar, bty="l", xlab="", ylab="")#
mtext("Variance", side=2,line=3, cex=1.5)#
plot(RollTimeIndex, Chl_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Metab_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2], bty="l", xlab="", ylab="")#
mtext("AR(1)", side=2,line=3, cex=1.5)#
mtext(expression(True~sigma[epsilon]^2*","~phi1[1]), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Chl_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(Chl*"-"*italic(a)), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Metab_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(widehat(M)*etabolism), side=1, line=4, cex=1.5)#
#
# LoopCounter <- LoopCounter + 1#
# LoopProgress <- LoopCounter/zzCounter#
# LoopElapsed <- (proc.time() - StartLoopTime)[[3]]/60#
# print(c("Elapsed"=round(LoopElapsed,1),"%Complete"=round(LoopProgress*100,1), "ETA"=round(LoopElapsed/LoopProgress-LoopElapsed,1), "LaYe"=paste(Lakes[La],Years[Ye],sep="_")))#
#
# dev.new()#
# plot(TrueRollVar, sqrt(Metab_RollVar))#
# summary(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# #
# dev.new()#
# plot(TrueRollAR1, Metab_RollAR1)#
# summary(lm(Metab_RollAR1~TrueRollAR1))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(Metab_RollAR1~TrueRollAR1))
#Ryan Batt#
#26-April-2012#
#Steve suggested using a toy model to assess how the noise can mask a squeal signal in metabolism, when the signal is seen in Chl#
#
# =============================================================#
# = Steve's suggested "simplest toy model of the GPP problem" =#
# =============================================================#
#Squeal Signal for Chl:#
#Chl[t+1] = Phi[t]*Chl[t] + Eps[t]#
#Phi[t] = 1 - exp(-K_Phi*t)  #Note that Phi grows asymptotically to 1#
#Sigma2_Eps[t] = K_Eps*t #The variance of the Chl autoregressive process grows over time#
#
#GPP + Junk Noise#
#DO[t+1] = K_GPP*DO[t] - K_DO*(DO[t] - DO[1]) + Junk[t]#
#Metab_hat = DO[t+1] - DO[t]#
#
rm(list=ls())#
graphics.off()#
require("zoo")#
#
Ar1 <-function(x){#
Nrmlzd <- x-mean(x)#
Y <- (x-mean(x))[-1]#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
}#
Ar1_Detrended <-function(x){#
#First detrend, if needed#
Model <- lm(x~c(1:length(x)))#
Summary <- coef(summary(Model))#
Slope <- Summary[2,1]#
PValue <- Summary[2,4]#
if(PValue<0.05){#
Xnew <- x-(Slope*c(1:length(x)))#
}else{#
Xnew <- x#
}#
#Calculate AR(1)#
Nrmlzd <- Xnew-mean(Xnew)#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(Xnew)])$coef[[2]])#
}#
#
# StartLoopTime <- proc.time()#
#
# RepsPerVar <- 3#
# JunkVarianceS <- seq(1E-6, 1E6, length.out=100)#
NStepsDefault <- 1000#
JunkVariance <- 1E2#
#
#
WindowSize <- 40#
RollTimeIndex <- 1:(NStepsDefault - (WindowSize-1))#
#
#
#
#Fiddling to find a way to "slowly" increase phi#
# Nsteps=1000#
# Time <- 1:Nsteps#
# K_Phi = -(log(0.5*(-0.95 + 1)))/(Nsteps) #-(log(-0.999 + 1.5)-2)/(Nsteps)#
# Phi <- 1 - 0.5*exp(-K_Phi*Time)  #1.5 - exp(-K_Phi*Time+2) #
# plot(Time, Phi)#
#
Chl_Model <- function(K_Phi=-(log(0.5*(-0.95 + 1)))/(Nsteps), K_Eps=1E-5, K_DO=0.5, Junk_Var=JunkVariance, Nsteps=NStepsDefault){#
Time <- 1:Nsteps#
Chl_0 <- 5 #A reasonable concentration of chlorophyll for Peter Lake in units of μg/L#
DO_0 <- 250 #A reasonable concentration of dissolved oxygen when O2 is near saturation at a typical temperature in Peter Lake, in units of μmols/L (is equal to 8 mg/L)#
#
Chl <- c(Chl_0,rep(NA,Nsteps-1))#
DO <- c(DO_0, rep(NA, Nsteps-1))#
#
Phi <- 1 - 0.5*exp(-K_Phi*Time)#
Sigma2_Eps <- K_Eps*Time#
#
K_GPP_t <- rep(NA,Nsteps)#
Junk <- rnorm(n=Nsteps, mean=0, sd=sqrt(Junk_Var))#
Metab_hat <- rep(NA,Nsteps-1)#
#
for(i in 1:(Nsteps-1)){#
Eps <- rnorm(n=1, mean=0, sd=sqrt(Sigma2_Eps[i]))#
Chl[i+1] <- Phi[i]*Chl[i] + Eps + Chl_0*(1-Phi[i]) #AR(1) plus noise model, with changing AR(1) coefficient and centered around a time series mean of Chl_0#
#
K_GPP_t[i] <- 1+log(Chl[i]/Chl_0) #The idea here is to allow [DO] to grow with the log ratio of current chlorophyll to the inital value of chlorophyll (supporting the notion that the system is at equilibrium when Chlorophyll and DO are at their initial values--- when chlorophyll is higher than its initial value, DO will increase; when chlorophyll is lower than its initial value, DO will decrease)#
DO[i+1] <- K_GPP_t[i]*DO[i] -K_DO*(DO[i]-DO_0) + Junk[i]#
Metab_hat[i] <- DO[i+1] - DO[i]#FIXME this should probably just be Metab_hat[i], but I did the +1 so that the last value wasn't NA#
#
}#
return(list("Chl"=matrix(data=c(Time,Chl), ncol=2),"K_GPP_t"=matrix(data=c(Time,K_GPP_t), ncol=2), "DO"=matrix(data=c(Time,DO), ncol=2), "Metab_hat"=matrix(data=c(Time[-length(Time)],Metab_hat), ncol=2), "True_Sigma2_Eps"=matrix(data=c(Time,Sigma2_Eps), ncol=2), "True_Phi"=matrix(data=c(Time,Phi), ncol=2)))#
#
#
}#
#
Test <- Chl_Model()#
dev.new()#
par(mfrow=c(2,2), mar=c(4,5,1,1))#
plot(Test[[1]], col="forestgreen", bty="l", ylab="Chl", xlab="", xaxt="n")#
plot(Test[[2]], ylab="K_GPP_t", xlab="", pch=20, bty="l", xaxt="n")#
plot(Test[[3]], ylab="DO", xlab="", bty="l")#
plot(Test[[4]], ylab="Metab_hat", xlab="", bty="l")#
#
Chl_RollVar <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=var)#
Chl_RollAR1 <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=Ar1_Detrended)#
#
Metab_RollVar <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=var)#
Metab_RollAR1 <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=Ar1_Detrended)#
#
TrueRollVar <- Test[[5]][is.element(Test[[5]][,1], RollTimeIndex),2]#
TrueRollAR1 <- Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2]#
#
dev.new(height=4.5, width=7)#
par(mfrow=c(2,3), family="Times", mar=c(4,3,1,1), oma=c(2,2,0,0), cex.axis=1.25)#
plot(RollTimeIndex, TrueRollVar, bty="l", xlab="", ylab="")#
mtext("Variance", side=2,line=3, cex=1.5)#
plot(RollTimeIndex, Chl_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Metab_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2], bty="l", xlab="", ylab="")#
mtext("AR(1)", side=2,line=3, cex=1.5)#
mtext(expression(True~sigma[epsilon]^2*","~phi1[1]), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Chl_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(Chl*"-"*italic(a)), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Metab_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(widehat(M)*etabolism), side=1, line=4, cex=1.5)#
#
# LoopCounter <- LoopCounter + 1#
# LoopProgress <- LoopCounter/zzCounter#
# LoopElapsed <- (proc.time() - StartLoopTime)[[3]]/60#
# print(c("Elapsed"=round(LoopElapsed,1),"%Complete"=round(LoopProgress*100,1), "ETA"=round(LoopElapsed/LoopProgress-LoopElapsed,1), "LaYe"=paste(Lakes[La],Years[Ye],sep="_")))#
#
# dev.new()#
# plot(TrueRollVar, sqrt(Metab_RollVar))#
# summary(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# #
# dev.new()#
# plot(TrueRollAR1, Metab_RollAR1)#
# summary(lm(Metab_RollAR1~TrueRollAR1))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(Metab_RollAR1~TrueRollAR1))
#Ryan Batt#
#26-April-2012#
#Steve suggested using a toy model to assess how the noise can mask a squeal signal in metabolism, when the signal is seen in Chl#
#
# =============================================================#
# = Steve's suggested "simplest toy model of the GPP problem" =#
# =============================================================#
#Squeal Signal for Chl:#
#Chl[t+1] = Phi[t]*Chl[t] + Eps[t]#
#Phi[t] = 1 - exp(-K_Phi*t)  #Note that Phi grows asymptotically to 1#
#Sigma2_Eps[t] = K_Eps*t #The variance of the Chl autoregressive process grows over time#
#
#GPP + Junk Noise#
#DO[t+1] = K_GPP*DO[t] - K_DO*(DO[t] - DO[1]) + Junk[t]#
#Metab_hat = DO[t+1] - DO[t]#
#
rm(list=ls())#
graphics.off()#
require("zoo")#
#
Ar1 <-function(x){#
Nrmlzd <- x-mean(x)#
Y <- (x-mean(x))[-1]#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
}#
Ar1_Detrended <-function(x){#
#First detrend, if needed#
Model <- lm(x~c(1:length(x)))#
Summary <- coef(summary(Model))#
Slope <- Summary[2,1]#
PValue <- Summary[2,4]#
if(PValue<0.05){#
Xnew <- x-(Slope*c(1:length(x)))#
}else{#
Xnew <- x#
}#
#Calculate AR(1)#
Nrmlzd <- Xnew-mean(Xnew)#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(Xnew)])$coef[[2]])#
}#
#
# StartLoopTime <- proc.time()#
#
# RepsPerVar <- 3#
# JunkVarianceS <- seq(1E-6, 1E6, length.out=100)#
NStepsDefault <- 1000#
JunkVariance <- 1E0#
#
#
WindowSize <- 40#
RollTimeIndex <- 1:(NStepsDefault - (WindowSize-1))#
#
#
#
#Fiddling to find a way to "slowly" increase phi#
# Nsteps=1000#
# Time <- 1:Nsteps#
# K_Phi = -(log(0.5*(-0.95 + 1)))/(Nsteps) #-(log(-0.999 + 1.5)-2)/(Nsteps)#
# Phi <- 1 - 0.5*exp(-K_Phi*Time)  #1.5 - exp(-K_Phi*Time+2) #
# plot(Time, Phi)#
#
Chl_Model <- function(K_Phi=-(log(0.5*(-0.95 + 1)))/(Nsteps), K_Eps=1E-5, K_DO=0.5, Junk_Var=JunkVariance, Nsteps=NStepsDefault){#
Time <- 1:Nsteps#
Chl_0 <- 5 #A reasonable concentration of chlorophyll for Peter Lake in units of μg/L#
DO_0 <- 250 #A reasonable concentration of dissolved oxygen when O2 is near saturation at a typical temperature in Peter Lake, in units of μmols/L (is equal to 8 mg/L)#
#
Chl <- c(Chl_0,rep(NA,Nsteps-1))#
DO <- c(DO_0, rep(NA, Nsteps-1))#
#
Phi <- 1 - 0.5*exp(-K_Phi*Time)#
Sigma2_Eps <- K_Eps*Time#
#
K_GPP_t <- rep(NA,Nsteps)#
Junk <- rnorm(n=Nsteps, mean=0, sd=sqrt(Junk_Var))#
Metab_hat <- rep(NA,Nsteps-1)#
#
for(i in 1:(Nsteps-1)){#
Eps <- rnorm(n=1, mean=0, sd=sqrt(Sigma2_Eps[i]))#
Chl[i+1] <- Phi[i]*Chl[i] + Eps + Chl_0*(1-Phi[i]) #AR(1) plus noise model, with changing AR(1) coefficient and centered around a time series mean of Chl_0#
#
K_GPP_t[i] <- 1+log(Chl[i]/Chl_0) #The idea here is to allow [DO] to grow with the log ratio of current chlorophyll to the inital value of chlorophyll (supporting the notion that the system is at equilibrium when Chlorophyll and DO are at their initial values--- when chlorophyll is higher than its initial value, DO will increase; when chlorophyll is lower than its initial value, DO will decrease)#
DO[i+1] <- K_GPP_t[i]*DO[i] -K_DO*(DO[i]-DO_0) + Junk[i]#
Metab_hat[i] <- DO[i+1] - DO[i]#FIXME this should probably just be Metab_hat[i], but I did the +1 so that the last value wasn't NA#
#
}#
return(list("Chl"=matrix(data=c(Time,Chl), ncol=2),"K_GPP_t"=matrix(data=c(Time,K_GPP_t), ncol=2), "DO"=matrix(data=c(Time,DO), ncol=2), "Metab_hat"=matrix(data=c(Time[-length(Time)],Metab_hat), ncol=2), "True_Sigma2_Eps"=matrix(data=c(Time,Sigma2_Eps), ncol=2), "True_Phi"=matrix(data=c(Time,Phi), ncol=2)))#
#
#
}#
#
Test <- Chl_Model()#
dev.new()#
par(mfrow=c(2,2), mar=c(4,5,1,1))#
plot(Test[[1]], col="forestgreen", bty="l", ylab="Chl", xlab="", xaxt="n")#
plot(Test[[2]], ylab="K_GPP_t", xlab="", pch=20, bty="l", xaxt="n")#
plot(Test[[3]], ylab="DO", xlab="", bty="l")#
plot(Test[[4]], ylab="Metab_hat", xlab="", bty="l")#
#
Chl_RollVar <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=var)#
Chl_RollAR1 <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=Ar1_Detrended)#
#
Metab_RollVar <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=var)#
Metab_RollAR1 <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=Ar1_Detrended)#
#
TrueRollVar <- Test[[5]][is.element(Test[[5]][,1], RollTimeIndex),2]#
TrueRollAR1 <- Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2]#
#
dev.new(height=4.5, width=7)#
par(mfrow=c(2,3), family="Times", mar=c(4,3,1,1), oma=c(2,2,0,0), cex.axis=1.25)#
plot(RollTimeIndex, TrueRollVar, bty="l", xlab="", ylab="")#
mtext("Variance", side=2,line=3, cex=1.5)#
plot(RollTimeIndex, Chl_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Metab_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2], bty="l", xlab="", ylab="")#
mtext("AR(1)", side=2,line=3, cex=1.5)#
mtext(expression(True~sigma[epsilon]^2*","~phi1[1]), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Chl_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(Chl*"-"*italic(a)), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Metab_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(widehat(M)*etabolism), side=1, line=4, cex=1.5)#
#
# LoopCounter <- LoopCounter + 1#
# LoopProgress <- LoopCounter/zzCounter#
# LoopElapsed <- (proc.time() - StartLoopTime)[[3]]/60#
# print(c("Elapsed"=round(LoopElapsed,1),"%Complete"=round(LoopProgress*100,1), "ETA"=round(LoopElapsed/LoopProgress-LoopElapsed,1), "LaYe"=paste(Lakes[La],Years[Ye],sep="_")))#
#
# dev.new()#
# plot(TrueRollVar, sqrt(Metab_RollVar))#
# summary(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# #
# dev.new()#
# plot(TrueRollAR1, Metab_RollAR1)#
# summary(lm(Metab_RollAR1~TrueRollAR1))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(Metab_RollAR1~TrueRollAR1))
graphics.off()
#pushup workout script
dev.new(width=10, height=3)
par(mfrow=c(1,4), mar=c(2,1,1,1), oma=c(3,3,3,0), las=1, family="Times")
TempLM <- lm(R08_BK_Smooth[,"GPP"]~R08ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R08ChlDaily, R08_BK_Smooth[,"GPP"], xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("Filtered BK GPP", side=2, line=2.5, las=0)
mtext("R 2008 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R09_BK_Smooth[,"GPP"]~R09ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R09ChlDaily, R09_BK_Smooth[,"GPP"], xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2009 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R10_BK_Smooth[,"GPP"]~R10ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R10ChlDaily, R10_BK_Smooth[,"GPP"], xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2010 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R11_BK_Smooth[,"GPP"]~R11ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R11ChlDaily, R11_BK_Smooth[,"GPP"], xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2011 Chl", side=1, line=2.5, las=0)
dev.new(width=10, height=3)
par(mfrow=c(1,4), mar=c(2,1,1,1), oma=c(3,3,3,0), las=1, family="Times")
TempLM <- lm(R08_BK_Smooth_Impd_GPP~R08ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R08ChlDaily, R08_BK_Smooth_Impd_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("Filtered BK GPP", side=2, line=2.5, las=0)
mtext("R 2008 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R09_BK_Smooth_Impd_GPP~R09ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R09ChlDaily, R09_BK_Smooth_Impd_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2009 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R10_BK_Smooth_Impd_GPP~R10ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R10ChlDaily, R10_BK_Smooth_Impd_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2010 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R11_BK_Smooth_Impd_GPP~R11ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R11ChlDaily, R11_BK_Smooth_Impd_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2011 Chl", side=1, line=2.5, las=0)
dev.new(width=10, height=3)
par(mfrow=c(1,4), mar=c(2,1,1,1), oma=c(3,3,3,0), las=1, family="Times")
TempLM <- lm(R08_BK_Smooth_AR1_Pred_GPP~R08ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R08ChlDaily, R08_BK_Smooth_AR1_Pred_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("Filtered BK GPP", side=2, line=2.5, las=0)
mtext("R 2008 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R09_BK_Smooth_AR1_Pred_GPP~R09ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R09ChlDaily, R09_BK_Smooth_AR1_Pred_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2009 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R10_BK_Smooth_AR1_Pred_GPP~R10ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R10ChlDaily, R10_BK_Smooth_AR1_Pred_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2010 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R11_BK_Smooth_AR1_Pred_GPP~R11ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R11ChlDaily, R11_BK_Smooth_AR1_Pred_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2011 Chl", side=1, line=2.5, las=0)
#0.1.0 == Scrapped old strategy in favor of using "zoo" package to do rolling window statistics, etc.
load("/Users/Battrd/Documents/School&Work/WiscResearch/SquealMetabolism/SquealMetabolism_v1.0.2_DailyZoopTest_FinishedRun.RData")
SS_R08_BK_NEP
?array
?t.test
ls()
Variables
Stats
SS_L10ChlDaily
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			StatTable[vari,ye,stat] <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep="")[,stat]) - get(paste("SS_L",ye_s[ye],vari_s[vari], sep="")[,stat])#
		}#
		#
		#
	}#
	#
}
get(paste("SS_R",ye_s[ye],vari_s[vari], sep="")
get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			StatTable[vari,ye,stat] <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
		}#
		#
		#
	}#
	#
}
get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat]
get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]
TempoVecDiff
length(which(TempoVecDiff>0))/length(TempoVecDiff)
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
			StatTable[vari,ye,stat] <- length(which(TempoVecDiff>0))/length(TempoVecDiff)#
		}#
		#
		#
	}#
	#
}
StatTable
TempoVecDiff
t.test(x=get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat], y=get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat], paried=TRUE)
sum(TempoVecDiff[which(TempoVecDiff>0))]) / -sum(TempoVecDiff[which(TempoVecDiff>0))])
-sum(TempoVecDiff[which(TempoVecDiff>0)])
sum(TempoVecDiff[which(TempoVecDiff>0)])
-sum(TempoVecDiff[which(TempoVecDiff<0)])
sum(TempoVecDiff[which(TempoVecDiff>0)]) / -sum(TempoVecDiff[which(TempoVecDiff<0)])
#
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
			# StatTable[vari,ye,stat] <- length(which(TempoVecDiff>0))/length(TempoVecDiff)#
			StatTable[vari,ye,stat] <- sum(TempoVecDiff[which(TempoVecDiff>0)]) / -sum(TempoVecDiff[which(TempoVecDiff<0)])#
		}#
		#
		#
	}#
	#
}
StatTable
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
			# StatTable[vari,ye,stat] <- length(which(TempoVecDiff>0))/length(TempoVecDiff)#
			# StatTable[vari,ye,stat] <- sum(TempoVecDiff[which(TempoVecDiff>0)]) / -sum(TempoVecDiff[which(TempoVecDiff<0)])#
			StatTable[vari,ye,stat] <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] / get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
		}#
		#
		#
	}#
	#
}
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
			# StatTable[vari,ye,stat] <- length(which(TempoVecDiff>0))/length(TempoVecDiff)#
			# StatTable[vari,ye,stat] <- sum(TempoVecDiff[which(TempoVecDiff>0)]) / -sum(TempoVecDiff[which(TempoVecDiff<0)])#
			StatTable[vari,ye,stat] <- sum(get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat]) / sum(get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat])#
		}#
		#
		#
	}#
	#
}
StatTable
as.POSIXct("2010-08-20")
format(as.POSIXct("2010-08-20"), "%j")
format(as.POSIXct("2010-08-18"), "%j")
length(xout08)
length(Days08)
length(Days09)
length(Days10)
length(Days11)
?cor
cor(1:10, ((1:10)+rnorm(n=10)))
cor.test(1:10, ((1:10)+rnorm(n=10)))
#Ryan Batt! 8-Oct-09#
#Calculating the area and volume between each contour on Ward Lake Bathymetric Map.  #
#The volumes are calculated in terms of a)"volume that is <= 2 meters" b)"volume that is between 3 meters and 5 meters"#
#Taking these known areas/volumes to transform volumetric metabolism data into absolute metabolism data for the 0-2m layer, and the 3-5m layer.#
#
#
#***Other Notes****#
#0-2m is the epilimnion, and is referred to as "shallow"#
#3-5m is a portion of the metalimnion, and is referred to as "deep"#
#Metabolism estimates are from simultaneously deployed sondes at 4m and 1m; deployment length was 12 days.#
#1m sonde sampled temp/DO every 5 minutes#
#4m sonde sampled temp/DO ever 10 minutes (should have been 5)#
#There was a strong oxygen and chl-a maximum at 4m when the sonde data was collected#
#
rm.list=ls()#
graphics.off()#
#
#Convert pixels to hectares#
#List of pixels between each set of contours#
PixPart <- c(66, 6598, 17408, 24901, 87470, 28071, 24258, 17435, 24731, 44946)#
#
#
#
#Total area of Ward Lake in Pixels#
PixTot <- sum(PixPart)#
#
#Total area of Ward Lake in hectares#
HectTot <- 2.74#
#
#
#
#List of areas between each set of contours in hectares#
HectPart <- rep(0, 10)#
for (i in 1:10) {#
	HectPart[i] <- (PixPart[i]*HectTot)/PixTot#
	}#
#Set sequence to outer-inner#
HP <- rev(HectPart)#
#
#Convert area to square meters (SMP = square meter part)#
SMP <- HP * 10000 #
#
#
ContsFt <- c(0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 27)#
ContsMet <- ContsFt*.305#
ContsMet#
length(ContsMet)#
#
#Shorten object names (aids in laziness)#
HT <- HectTot#
CM <- ContsMet#
#
#Calc total volume that is <= 2m#
ShalVols <- rep(0, 10) #create empty vector for shallow volumes#
SVs <- ShalVols #just so I can be lazy#
#
#
#
for(i in 1:10) {#
	if(CM[i+1] <= 2) {#
		SVs[i] <- ((CM[i+1] + CM[i])/2) * SMP[i]#
		} else {#
			if(CM[i] >= 2) {#
				SVs[i] <- SMP[i] * 2#
				} else {#
					SVs[i] <- ((((CM[i+1]-2)/(CM[i+1]-CM[i])) * 2) + (((2-CM[i])/(CM[i+1]-CM[i])) * (.5*(2+CM[i])))) * SMP[i]#
					}#
					}#
			}#
TotalShallowVolume <- sum(SVs)#
#TotalShallowVolume #in Meters Cubed#
#
#Calc total volume between 3m and 5m; I am cheating here and just doing the calculations. They are still accurate, but not applicable to other contour series.#
#
#First 3 are 0#
#Second 3 are lame#
#Last 4 are 2#
#
#Set up the vector to store the deep volumes#
DVs <- rep(0, 10)#
#
DVs[4] <- ((0+.66)/2) * SMP[4]#
DVs[5] <- ((.66+1.575)/2) * SMP[5]#
DVs[6] <- (((.490/.915)*2) + ((.425/.915)*(.5*(1.575+2))))*SMP[6]#
DVs[7:10] <- 2*SMP[7:10]#
#
#
TotalDeepVolume <- sum(DVs)#
#
TotalShallowVolume#
TotalDeepVolume#
#
TotalVolumeMeasured <- TotalShallowVolume + TotalDeepVolume#
TotalVolumeMeasured#
TotalDeepVolume/TotalShallowVolume#
TotalDeepVolume/TotalVolumeMeasured#
#
DeepGPPVol <- 42.22#
DeepRVol <- -53.79#
DeepNEPVol <- -11.57#
DeepVolEst <- c(42.22, -53.79, -11.57) #GPP, R, NEP#
#
ShalGPPVol <- 24.37#
ShalRVol <- -28.73#
ShalNEPVol <- -4.361#
ShalVolEst <- c(24.37, -28.73, -4.361) #GPP, R, NEP#
#
ShalTotEst <- TotalShallowVolume * ShalVolEst#
DeepTotEst <- TotalDeepVolume * DeepVolEst #
#
ShalTotEst #Shallow GPP, R, NEP in mmol C/day#
DeepTotEst #Deep GPP, R, NEP in mmol C/day#
#
TotalEst <- ShalTotEst + DeepTotEst#
#
ShalTotEst/TotalEst #%GPP, R, NEP that occured in Shallow#
DeepTotEst/TotalEst #%GPP, R, NEP that occured in Deep#
#
(DeepTotEst-ShalTotEst)/TotalEst#
#
sum(PixPart[7:10])/PixTot#
#
AvgDepthPerCont <- c(27, 25.5, 22.5, 19.5, 16.5, 13.5, 10.5, 7.5, 4.5, 1.5)#
#VolumeInfected in units of m^3#
VolumeInfected <- sum((AvgDepthPerCont[7:10]*0.305 * HectPart[7:10]) * 0.38 *10000) #38% macrophytes in this region of Ward Lake (supposed to be within 30 m of shore, so I guessed this tends to be at the 12 ft contour)#
PVI <- VolumeInfected / sum(AvgDepthPerCont * HectPart *0.305 *10000) *100#
MeanDepthWard <- sum(AvgDepthPerCont*0.305 * HectPart*10000 /(HectTot*10000))
MeanDepthWard
AvgDepthPerCont
HectPart
MeanDepthWard <- sum(AvgDepthPerCont*0.305 * (HectPart*10000 /(HectTot*10000)))
MeanDepthWard
(HectPart*10000 /(HectTot*10000))
HectTot
AvgDepthPerCont*0.305 * (HectPart*10000 /(HectTot*10000))
sum(HectPart*10000 /(HectTot*10000))
MeanDepthWard <- sum(AvgDepthPerCont*0.305 * (HectPart*10000 /(HectTot*10000)))
MeanDepthWard
AvgDepthPerCont
Pre_AvgDepthPerCont <- c(AvgDepthPerCont[-1],0)
Pre_AvgDepthPerCont
(Pre_AvgDepthPerCont + AvgDepthPerCont)/2
Avg_AvgDepthPerCont <- (Pre_AvgDepthPerCont + AvgDepthPerCont)/2
MeanDepthWard <- sum(Avg_AvgDepthPerCont*0.305 * (HectPart*10000 /(HectTot*10000)))
MeanDepthWard
plot(1:10, exp(1:10))
plot(1:10, 1:10)
plot(exp(1:10), 1:10)
#Ryan Batt#
#13-July-2012#
#Assess the concentration of aquashade in ward lake water using spectral absorbance#
rm(list=ls())#
graphics.off()#
#
# =======================================================================#
# = Set Options for File Name and Range of Lambda to Use as a Reference =#
# =======================================================================#
FileName <- c(paste("InSeasonWeeklyReadings/","WardFiltrate_",format.Date(Sys.Date(), "%d%b%Y"), ".csv", sep=""))#, "InSeasonWeeklyReadings/1000ppmWardPMLFiltrate22Apr12.csv")[2] #Use this default if you want the file from the current day#
# FileName <- "InSeasonWeeklyReadings/WardFiltrate_12Jul2012.csv"#
StdLambda <- list(620:630,300:900,400:700, 635)[[1]]#
#
AquashadeAdditions <- data.frame("Date"=as.POSIXct(c("23-Apr-2012", "24-Apr-2012", "26-Apr-2012",  "24-May-2012", "11-Jun-2012"), format="%d-%b-%Y"), "Gal"=c(9, 5, 10, 1, 4))#
#
# =============================#
# = Set the Working Directory =#
# =============================#
BeginDirectory <- paste("/Users/",Sys.info()["user"], sep="")#
setwd(paste(BeginDirectory,"/TheCascadeProject/WardSpecScans2012", sep=""))#
#
# =======================================================================#
# = Read in the Data ('Standards' and Today's Ward Absorbance Spectrum) =#
# =======================================================================#
MQ2ppmStandard_0 <- read.csv("PreSeasonStandards/2ppmAquashadeMQ23Apr2012.csv", header=TRUE, skip=1)[,1:2]#
PreWardH2O_0 <- read.csv("PreSeasonStandards/WardFiltrate23Apr2012.csv", header=TRUE, skip=1)[,1:2]#
#
# ===============================================#
# = Clip the Spectra to the Desired Wavelengths =#
# ===============================================#
StdIndex <- is.element(MQ2ppmStandard_0[,1], StdLambda)#
MQ2ppmStandard <- MQ2ppmStandard_0[StdIndex,]#
PreWardH2O <- PreWardH2O_0[StdIndex,]#
PreLong <- mean(PreWardH2O_0[401:601,2])#
#
# ===============================================================================================#
# = TheoreticalWavelengths/TheoreticalConcentration = ObservedWavelengths/ObservedConcentration =#
# ===============================================================================================#
#
# list.files("InSeasonWeeklyReadings/")#
# file.info(paste("InSeasonWeeklyReadings/",list.files("InSeasonWeeklyReadings/"), sep=""))#
ListFileDates_00 <- unlist(strsplit(list.files("InSeasonWeeklyReadings/"), split="WardFiltrate_"))#
ListFileDates_0 <- ListFileDates_00[-c(seq(1, (length(ListFileDates_00)-1), by=2))]#
ListFileDates <- as.POSIXct(unlist(strsplit(ListFileDates_0, split=".csv")), format="%d%b%Y")#
#
OrderedFileDates <- ListFileDates[order(ListFileDates)]#
OrderedFiles <- list.files("InSeasonWeeklyReadings/")[order(ListFileDates)]#
EstAquashadeConc <- rep(NA, length(OrderedFiles))#
SDAquashadeConc <- rep(NA, length(OrderedFiles))#
for(i in 1:length(EstAquashadeConc)){#
	ThisWardH2O_0 <- read.csv(paste("InSeasonWeeklyReadings/",OrderedFiles[i],sep=""), header=TRUE, skip=1)[,1:2]#
	ThisWardH2O <- ThisWardH2O_0[StdIndex,]#
	ThisLong <- mean(ThisWardH2O_0[401:601,2])#
	#
	This_Adj_For_Base <- (ThisWardH2O[,2]-ThisLong) #The absorbance of recent Ward H2O, adjusted so that baseline absorbance (abs between 700 and 900 nm) is 0#
	Pre_Adj_For_Base <- (PreWardH2O[,2]-PreLong) #Adjust pre-aquashade absorbance so that its 700 to 900 nm absorbance is 0#
	This_Adj_For_PreAqua <- This_Adj_For_Base - Pre_Adj_For_Base #The absorbance of recent Ward H2O in the Aquashade region (StdIndex), normalized to the absorbance of Ward H2O before the Aquashade addition#
	This_Frac_Of_2ppm <- mean(This_Adj_For_PreAqua / MQ2ppmStandard[,2])#
	EstAquashadeConc[i] <- This_Frac_Of_2ppm * 2#
	# EstAquashadeConc[i] <- mean(((ThisWardH2O[,2]-PreWardH2O[,2] +PreLong-ThisLong)*2)/(MQ2ppmStandard[,2]))#
	# SDAquashadeConc[i] <- sd(((ThisWardH2O[,2]-PreWardH2O[,2] +PreLong-ThisLong)*2)/(MQ2ppmStandard[,2]))#
}#
#
# Ward2012Light_DoY <- as.POSIXct(c("2012-04-14 CDT", "2012-04-19 CDT", "2012-04-26 CDT", "2012-05-03 CDT", "2012-05-10 CDT", "2012-05-17 CDT", "2012-05-24 CDT", "2012-05-31 CDT", "2012-06-07 CDT", "2012-06-11 CDT", "2012-06-18 CDT")) #c(105, 110, 117, 124, 131, 138, 145, 152, 159, 163, 170)#
# Ward2012_1percLight <-  c(2.3, 2.8, 1.85, 1.75, 1.9, 1.9, 1.8, 1.75, 2.0, 1.5, 2.0)#
# ZmixDays <- as.POSIXct(c("2012-04-14 CDT", "2012-04-19 CDT", "2012-04-26 CDT", "2012-05-03 CDT", "2012-05-10 CDT", "2012-05-17 CDT", "2012-05-24 CDT", "2012-05-31 CDT", "2012-06-07 CDT", "2012-06-11 CDT", "2012-06-18 CDT"))  #c(105, 110, 117, 124, 131, 138, 145, 152, 159, 163, 170)#
# ZmixDepths <- c(1.0,2.0,2.0,0.5,0.5, 1.0, 1.0, 1.5, 0.5, 1.0, 1.0)#
#
LM_z <- c(2,2,2,1,1, 1)#
LM_ppm <- c((0.8203199-0), (1.4287381-0.8203199), (1.8709102-1.1050495), (approx(x=c(1,7), y=c(1.5072962, 1.4256601), xout=2)$y-1.5072962), (1.7712213-1.4158847), (1.8219112-1.2064273))#
LM_gal <- c(9,5,10,1,4, 6)#
ppm_perGal_perZ <- summary(lm(LM_ppm ~ I(LM_gal/LM_z) -1))$coef[1]#
Gal2Add <- (2 - EstAquashadeConc[i]) / ppm_perGal_perZ#
#
#
plot(OrderedFileDates, EstAquashadeConc, type="o", ylab="Aquahsade (ppm)", xlab="Date", bty="l") #, ylim=c(0,max(EstAquashadeConc))#
grid()#
# abline(v=AquashadeAdditions[,1], col="blue")#
legend("bottom", paste(format(OrderedFileDates[i], "%d-%b-%Y")," = ", round(EstAquashadeConc[i],2), " ppm", "\n", "Add (", as.character(round(Gal2Add,2)), " * Zmix) ", "gallons of Aquahshade", sep=""), bty="n", cex=1.25)
rm(list=ls())#
graphics.off()#
#
setwd("/Users/Battrd/Documents/School&Work/WiscResearch/SquealMetabolism")#
source("Conc2Sat.R")#
source("KO2.R")#
source("Sat2Conc.R")#
source("SatdConc.R")#
source("MyBookkeepingMetabolism.R")#
#
setwd("/Users/Battrd/Documents/School&Work/WiscResearch/WardSensorData2012")#
#
# UNDERC_Weather <- rbind(read.csv("UNDERC_Weather_April2012.csv"), read.csv("UNDERC_Weather_May2012.csv"))#
UNDERC_Weather <- read.csv("UNDERC_Weather_2012.csv")#
names(UNDERC_Weather) <- c("Year", "DoY", "Time", "Wind", "PAR")#
#
HourChar <- as.character(ifelse(UNDERC_Weather[,"Time"]/100==24, "0",UNDERC_Weather[,"Time"]/100))#
WhichHourSingleDigit <- which(nchar(HourChar)==1)#
HourChar[WhichHourSingleDigit] <- paste("0",HourChar[WhichHourSingleDigit],sep="")#
UNDERC_Weather[,"Time"] <- paste(HourChar, "00", sep=":")#
# as.POSIXct(UNDERC_Weather[,"Time"], format="%H:%M")#
#
SondeA1 <- read.table("A14APR12.CDF", sep=",", header=TRUE, skip=0)[-1,]#
SondeB1 <- read.table("B14APR12.CDF", sep=",", header=TRUE, skip=0)[-1,]#
SondeA2 <- read.table("A03MAY12.txt", sep=",", header=FALSE, skip=0)[-c(1,2,3,4),]#
names(SondeA2) <- c("Date", "Time", "Temp", "SpCond", "pH", "BGA.PC.Conc", "BGA.PC", "ODO.", "ODOconc", "Chlorophyll", "Chlorophyll.1", "Battery")#
SondeB2 <- read.table("B03MAY12.txt", sep=",", header=FALSE, skip=0)[-c(1,2,3,4),]#
names(SondeB2) <- c("Date", "Time", "Temp", "SpCond", "pH", "BGA.PC.Conc", "BGA.PC", "ODO.", "ODOconc", "Chlorophyll", "Chlorophyll.1", "Battery")#
SondeA3 <- read.table("A03JUN12.txt", sep=",", header=FALSE, skip=0)[-c(1,2,3,4),]#
names(SondeA3) <- c("Date", "Time", "Temp", "SpCond", "pH", "BGA.PC.Conc", "BGA.PC", "ODO.", "ODOconc", "Chlorophyll", "Chlorophyll.1", "Battery")#
SondeB3 <- read.table("B03JUN12.txt", sep=",", header=FALSE, skip=0)[-c(1,2,3,4),]#
names(SondeB3) <- c("Date", "Time", "Temp", "SpCond", "pH", "BGA.PC.Conc", "BGA.PC", "ODO.", "ODOconc", "Chlorophyll", "Chlorophyll.1", "Battery")#
#
#
SondeA1_DoY <- as.numeric(format.Date(as.POSIXct(as.character(SondeA1[,1]), format="%m/%d/%y"), format="%j")) + as.numeric(difftime(time1=as.POSIXct(paste(SondeA1[,1], SondeA1[,2]), format="%m/%d/%y %H:%M:%S"), time2=as.POSIXct(paste(SondeA1[,1], "00:00:00"), format="%m/%d/%y %H:%M:%S"), units="days"))#
SondeB1_DoY <- as.numeric(format.Date(as.POSIXct(as.character(SondeB1[,1]), format="%m/%d/%y"), format="%j")) + as.numeric(difftime(time1=as.POSIXct(paste(SondeB1[,1], SondeB1[,2]), format="%m/%d/%y %H:%M:%S"), time2=as.POSIXct(paste(SondeB1[,1], "00:00:00"), format="%m/%d/%y %H:%M:%S"), units="days"))#
SondeA2_DoY <- as.numeric(format.Date(as.POSIXct(SondeA2[,1], format="%Y/%m/%d"), format="%j")) + as.numeric(difftime(time1=as.POSIXct(paste(SondeA2[,1], SondeA2[,2]), format="%Y/%m/%d %H:%M:%S"), time2=as.POSIXct(paste(SondeA2[,1], "00:00:00"), format="%Y/%m/%d %H:%M:%S"), units="days"))#
SondeB2_DoY <- as.numeric(format.Date(as.POSIXct(SondeB2[,1], format="%Y/%m/%d"), format="%j")) + as.numeric(difftime(time1=as.POSIXct(paste(SondeB2[,1], SondeB2[,2]), format="%Y/%m/%d %H:%M:%S"), time2=as.POSIXct(paste(SondeB2[,1], "00:00:00"), format="%Y/%m/%d %H:%M:%S"), units="days"))#
SondeA3_DoY <- as.numeric(format.Date(as.POSIXct(SondeA3[,1], format="%Y/%m/%d"), format="%j")) + as.numeric(difftime(time1=as.POSIXct(paste(SondeA3[,1], SondeA3[,2]), format="%Y/%m/%d %H:%M:%S"), time2=as.POSIXct(paste(SondeA3[,1], "00:00:00"), format="%Y/%m/%d %H:%M:%S"), units="days"))#
SondeB3_DoY <- as.numeric(format.Date(as.POSIXct(SondeB3[,1], format="%Y/%m/%d"), format="%j")) + as.numeric(difftime(time1=as.POSIXct(paste(SondeB3[,1], SondeB3[,2]), format="%Y/%m/%d %H:%M:%S"), time2=as.POSIXct(paste(SondeB3[,1], "00:00:00"), format="%Y/%m/%d %H:%M:%S"), units="days"))#
#
#
# ======================================#
# = Read in Zmix Data... or make it up =#
# ======================================#
ZmixDays <- c(105, 110, 117, 124, 131, 138, 145, 152, 159, 163, 170)#
ZmixDepths <- c(1.0,2.0,2.0,0.5,0.5, 1.0, 1.0, 1.5, 0.5, 1.0, 1.0)#
#
#
K_A1 <- KO2(as.numeric(as.character(SondeA1[,"Temp"])), 288, approx(as.numeric(UNDERC_Weather[,"DoY"]), as.numeric(UNDERC_Weather[,"Wind"]), xout=SondeA1_DoY)$y)#
KO2zmix_A1 <- K_A1/approx(x=ZmixDays,y=ZmixDepths, xout=SondeA1_DoY, rule=2)$y#
DOsatd_A1 <- SatdConc(as.numeric(as.character(SondeA1[,"Temp"])), 0.942*760)#
SondeA1_Data4BK <- data.frame("Year"=rep(2012, length(SondeA1_DoY)), "DoY"=trunc(SondeA1_DoY), "Fract"=SondeA1_DoY-trunc(SondeA1_DoY), "Temp"=as.numeric(as.character(SondeA1[,"Temp"])), "DOsat"=as.numeric(as.character(SondeA1[,"ODO."])), "DepID"=rep(1, length(SondeA1_DoY)) )#
SondeB1_Data4BK <- data.frame("Year"=rep(2012, length(SondeB1_DoY)), "DoY"=trunc(SondeB1_DoY), "Fract"=SondeB1_DoY-trunc(SondeB1_DoY), "Temp"=as.numeric(as.character(SondeB1[,"Temp"])), "DOsat"=as.numeric(as.character(SondeB1[,"ODO."])), "DepID"=rep(1, length(SondeB1_DoY)) )#
SondeA1_BK <- Metabolism(Data=SondeA1_Data4BK, zmix=approx(x=ZmixDays,y=ZmixDepths, xout=SondeA1_DoY, rule=2)$y, Wind=approx(as.numeric(UNDERC_Weather[,"DoY"]), as.numeric(UNDERC_Weather[,"Wind"]), xout=SondeA1_DoY)$y, Volumetric=TRUE)#
abline(v=114, col="darkblue")#
#
K_A2 <- KO2(as.numeric(as.character(SondeA2[,"Temp"])), 288, approx(as.numeric(UNDERC_Weather[,"DoY"]), as.numeric(UNDERC_Weather[,"Wind"]), xout=SondeA2_DoY)$y)#
KO2zmix_A2 <- K_A2/approx(x=ZmixDays,y=ZmixDepths, xout=SondeA2_DoY, rule=2)$y#
DOsatd_A2 <- SatdConc(as.numeric(as.character(SondeA2[,"Temp"])), 0.942*760)#
SondeA2_Data4BK <- data.frame("Year"=rep(2012, length(SondeA2_DoY)), "DoY"=trunc(SondeA2_DoY), "Fract"=SondeA2_DoY-trunc(SondeA2_DoY), "Temp"=as.numeric(as.character(SondeA2[,"Temp"])), "DOsat"=as.numeric(as.character(SondeA2[,"ODO."])), "DepID"=rep(1, length(SondeA2_DoY)) )#
SondeB1_Data4BK <- data.frame("Year"=rep(2012, length(SondeB1_DoY)), "DoY"=trunc(SondeB1_DoY), "Fract"=SondeB1_DoY-trunc(SondeB1_DoY), "Temp"=as.numeric(as.character(SondeB1[,"Temp"])), "DOsat"=as.numeric(as.character(SondeB1[,"ODO."])), "DepID"=rep(1, length(SondeB1_DoY)) )#
SondeA2_BK <- Metabolism(Data=SondeA2_Data4BK, zmix=approx(x=ZmixDays,y=ZmixDepths, xout=SondeA2_DoY, rule=2)$y, Wind=approx(as.numeric(UNDERC_Weather[,"DoY"]), as.numeric(UNDERC_Weather[,"Wind"]), xout=SondeA2_DoY)$y, Volumetric=TRUE)#
abline(v=145, col="darkblue")#
#
K_A3 <- KO2(as.numeric(as.character(SondeA3[,"Temp"])), 288, approx(as.numeric(UNDERC_Weather[,"DoY"]), as.numeric(UNDERC_Weather[,"Wind"]), xout=SondeA3_DoY)$y)#
KO2zmix_A3 <- K_A3/approx(x=ZmixDays,y=ZmixDepths, xout=SondeA3_DoY, rule=2)$y#
DOsatd_A3 <- SatdConc(as.numeric(as.character(SondeA3[,"Temp"])), 0.942*760)#
SondeA3_Data4BK <- data.frame("Year"=rep(2012, length(SondeA3_DoY)), "DoY"=trunc(SondeA3_DoY), "Fract"=SondeA3_DoY-trunc(SondeA3_DoY), "Temp"=as.numeric(as.character(SondeA3[,"Temp"])), "DOsat"=as.numeric(as.character(SondeA3[,"ODO."])), "DepID"=rep(1, length(SondeA3_DoY)) )#
SondeB1_Data4BK <- data.frame("Year"=rep(2012, length(SondeB1_DoY)), "DoY"=trunc(SondeB1_DoY), "Fract"=SondeB1_DoY-trunc(SondeB1_DoY), "Temp"=as.numeric(as.character(SondeB1[,"Temp"])), "DOsat"=as.numeric(as.character(SondeB1[,"ODO."])), "DepID"=rep(1, length(SondeB1_DoY)) )#
SondeA3_BK <- Metabolism(Data=SondeA3_Data4BK, zmix=approx(x=ZmixDays,y=ZmixDepths, xout=SondeA3_DoY, rule=2)$y, Wind=approx(as.numeric(UNDERC_Weather[,"DoY"]), as.numeric(UNDERC_Weather[,"Wind"]), xout=SondeA3_DoY)$y, Volumetric=TRUE)#
abline(v=160, col="darkblue")#
#
# SondeB_BK <- Metabolism(Data=SondeB_Data4BK, zmix=approx(x=c(105,110,117,124),y=c(1.0,2.0,2.0,0.5), xout=SondeB_DoY, rule=2)$y, Wind=approx(as.numeric(UNDERC_Weather[,"DoY"]), as.numeric(UNDERC_Weather[,"Wind"]), xout=SondeB_DoY)$y)#
# abline(v=114, col="darkblue")#
#
# dev.new()#
# par(mar=c(3,3,1,1))#
# plot(SondeA_BK[,1], SondeA_BK[,3], type="o", lwd=2, bty="l")#
#
dev.new()#
boxplot(list("Pre-Manipulation"=SondeA1_BK[1:9,3], "Aquashade"=SondeA1_BK[10:19,3]), main="Ward Lake Epilimnetic GPP \n 15-Apr to 03-May", ylab=expression(mu*mol~O[2]~day^-1))#
#
t.test(SondeA1_BK[1:9,3], SondeA1_BK[10:19,3])#
#
#
Ward2010Light <- read.csv("/Users/Battrd/Documents/School&Work/WiscResearch/WardLimno/WardWeekly2010.csv")#
Ward2010Light_DoY <- as.numeric(format.Date(as.POSIXct(as.character(Ward2010Light[,1]), format="%d-%b-%y"), format="%j"))#
Ward2010_1percLight <- c(4.25, 4.5, 4.5, 4.25, 4.25, 4.25, 3.75, 4)#
#
Ward2012Light_DoY <- c(105, 110, 117, 124, 131, 138, 145, 152, 159, 163, 170)#
Ward2012_1percLight <- c(2.3, 2.8, 1.85, 1.75, 1.9, 1.9, 1.8, 1.75, 2.0, 1.5, 2.0)#
#
GuessLight <- approx(c(105,110,unique(Ward2010Light_DoY)), y=c(2.3,2.8,Ward2010_1percLight), xout=105:max(Ward2010Light_DoY))#
#
dev.new()#
plot(unique(Ward2010Light_DoY), Ward2010_1percLight, ylim=c(5,0), xlim=c(min(Ward2012Light_DoY), max(Ward2010Light_DoY)), type="o", lwd=2, ylab="Depth (m) of 1% Surface PAR", xlab="DoY")#
lines(GuessLight, lty="dotted", lwd=2)#
lines(Ward2012Light_DoY, Ward2012_1percLight, type="o", pch=22, lwd=2, col="blue")#
abline(v=114, col="darkblue")#
#
dev.new()#
plot(SondeA1_DoY, as.numeric(as.character(SondeA1[,"Chlorophyll"])), type="l", col="green", lwd=1, bty="l", xlab="DoY", ylab="Chl-a (ug/L)")#
abline(v=114, col="darkblue")#
dev.new()#
plot(SondeA2_DoY, as.numeric(as.character(SondeA2[,"Chlorophyll"])), type="l", col="green", lwd=1, bty="l", xlab="DoY", ylab="Chl-a (ug/L)")#
abline(v=145, col="darkblue")#
dev.new()#
plot(SondeA3_DoY, as.numeric(as.character(SondeA3[,"Chlorophyll"])), type="l", col="green", lwd=1, bty="l", xlab="DoY", ylab="Chl-a (ug/L)")#
abline(v=160, col="darkblue")
