dev.new(height=4.5, width=7)#
par(mfrow=c(2,3), family="Times", mar=c(4,3,1,1), oma=c(2,2,0,0), cex.axis=1.25)#
plot(RollTimeIndex, TrueRollVar, bty="l", xlab="", ylab="")#
mtext("Variance", side=2,line=3, cex=1.5)#
plot(RollTimeIndex, Chl_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Metab_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2], bty="l", xlab="", ylab="")#
mtext("AR(1)", side=2,line=3, cex=1.5)#
mtext(expression(True~sigma[epsilon]^2*","~phi1[1]), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Chl_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(Chl*"-"*italic(a)), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Metab_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(widehat(M)*etabolism), side=1, line=4, cex=1.5)#
#
# LoopCounter <- LoopCounter + 1#
# LoopProgress <- LoopCounter/zzCounter#
# LoopElapsed <- (proc.time() - StartLoopTime)[[3]]/60#
# print(c("Elapsed"=round(LoopElapsed,1),"%Complete"=round(LoopProgress*100,1), "ETA"=round(LoopElapsed/LoopProgress-LoopElapsed,1), "LaYe"=paste(Lakes[La],Years[Ye],sep="_")))#
#
# dev.new()#
# plot(TrueRollVar, sqrt(Metab_RollVar))#
# summary(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# #
# dev.new()#
# plot(TrueRollAR1, Metab_RollAR1)#
# summary(lm(Metab_RollAR1~TrueRollAR1))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(Metab_RollAR1~TrueRollAR1))
#Ryan Batt#
#26-April-2012#
#Steve suggested using a toy model to assess how the noise can mask a squeal signal in metabolism, when the signal is seen in Chl#
#
# =============================================================#
# = Steve's suggested "simplest toy model of the GPP problem" =#
# =============================================================#
#Squeal Signal for Chl:#
#Chl[t+1] = Phi[t]*Chl[t] + Eps[t]#
#Phi[t] = 1 - exp(-K_Phi*t)  #Note that Phi grows asymptotically to 1#
#Sigma2_Eps[t] = K_Eps*t #The variance of the Chl autoregressive process grows over time#
#
#GPP + Junk Noise#
#DO[t+1] = K_GPP*DO[t] - K_DO*(DO[t] - DO[1]) + Junk[t]#
#Metab_hat = DO[t+1] - DO[t]#
#
rm(list=ls())#
graphics.off()#
require("zoo")#
#
Ar1 <-function(x){#
Nrmlzd <- x-mean(x)#
Y <- (x-mean(x))[-1]#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
}#
Ar1_Detrended <-function(x){#
#First detrend, if needed#
Model <- lm(x~c(1:length(x)))#
Summary <- coef(summary(Model))#
Slope <- Summary[2,1]#
PValue <- Summary[2,4]#
if(PValue<0.05){#
Xnew <- x-(Slope*c(1:length(x)))#
}else{#
Xnew <- x#
}#
#Calculate AR(1)#
Nrmlzd <- Xnew-mean(Xnew)#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(Xnew)])$coef[[2]])#
}#
#
# StartLoopTime <- proc.time()#
#
# RepsPerVar <- 3#
# JunkVarianceS <- seq(1E-6, 1E6, length.out=100)#
NStepsDefault <- 1000#
JunkVariance <- 1E-2#
#
#
WindowSize <- 40#
RollTimeIndex <- 1:(NStepsDefault - (WindowSize-1))#
#
#
#
#Fiddling to find a way to "slowly" increase phi#
# Nsteps=1000#
# Time <- 1:Nsteps#
# K_Phi = -(log(0.5*(-0.95 + 1)))/(Nsteps) #-(log(-0.999 + 1.5)-2)/(Nsteps)#
# Phi <- 1 - 0.5*exp(-K_Phi*Time)  #1.5 - exp(-K_Phi*Time+2) #
# plot(Time, Phi)#
#
Chl_Model <- function(K_Phi=-(log(0.5*(-0.95 + 1)))/(Nsteps), K_Eps=1E-5, K_DO=0.5, Junk_Var=JunkVariance, Nsteps=NStepsDefault){#
Time <- 1:Nsteps#
Chl_0 <- 5 #A reasonable concentration of chlorophyll for Peter Lake in units of μg/L#
DO_0 <- 250 #A reasonable concentration of dissolved oxygen when O2 is near saturation at a typical temperature in Peter Lake, in units of μmols/L (is equal to 8 mg/L)#
#
Chl <- c(Chl_0,rep(NA,Nsteps-1))#
DO <- c(DO_0, rep(NA, Nsteps-1))#
#
Phi <- 1 - 0.5*exp(-K_Phi*Time)#
Sigma2_Eps <- K_Eps*Time#
#
K_GPP_t <- rep(NA,Nsteps)#
Junk <- rnorm(n=Nsteps, mean=0, sd=sqrt(Junk_Var))#
Metab_hat <- rep(NA,Nsteps-1)#
#
for(i in 1:(Nsteps-1)){#
Eps <- rnorm(n=1, mean=0, sd=sqrt(Sigma2_Eps[i]))#
Chl[i+1] <- Phi[i]*Chl[i] + Eps + Chl_0*(1-Phi[i]) #AR(1) plus noise model, with changing AR(1) coefficient and centered around a time series mean of Chl_0#
#
K_GPP_t[i] <- 1+log(Chl[i]/Chl_0) #The idea here is to allow [DO] to grow with the log ratio of current chlorophyll to the inital value of chlorophyll (supporting the notion that the system is at equilibrium when Chlorophyll and DO are at their initial values--- when chlorophyll is higher than its initial value, DO will increase; when chlorophyll is lower than its initial value, DO will decrease)#
DO[i+1] <- K_GPP_t[i]*DO[i] -K_DO*(DO[i]-DO_0) + Junk[i]#
Metab_hat[i] <- DO[i+1] - DO[i]#FIXME this should probably just be Metab_hat[i], but I did the +1 so that the last value wasn't NA#
#
}#
return(list("Chl"=matrix(data=c(Time,Chl), ncol=2),"K_GPP_t"=matrix(data=c(Time,K_GPP_t), ncol=2), "DO"=matrix(data=c(Time,DO), ncol=2), "Metab_hat"=matrix(data=c(Time[-length(Time)],Metab_hat), ncol=2), "True_Sigma2_Eps"=matrix(data=c(Time,Sigma2_Eps), ncol=2), "True_Phi"=matrix(data=c(Time,Phi), ncol=2)))#
#
#
}#
#
Test <- Chl_Model()#
dev.new()#
par(mfrow=c(2,2), mar=c(4,5,1,1))#
plot(Test[[1]], col="forestgreen", bty="l", ylab="Chl", xlab="", xaxt="n")#
plot(Test[[2]], ylab="K_GPP_t", xlab="", pch=20, bty="l", xaxt="n")#
plot(Test[[3]], ylab="DO", xlab="", bty="l")#
plot(Test[[4]], ylab="Metab_hat", xlab="", bty="l")#
#
Chl_RollVar <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=var)#
Chl_RollAR1 <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=Ar1_Detrended)#
#
Metab_RollVar <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=var)#
Metab_RollAR1 <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=Ar1_Detrended)#
#
TrueRollVar <- Test[[5]][is.element(Test[[5]][,1], RollTimeIndex),2]#
TrueRollAR1 <- Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2]#
#
dev.new(height=4.5, width=7)#
par(mfrow=c(2,3), family="Times", mar=c(4,3,1,1), oma=c(2,2,0,0), cex.axis=1.25)#
plot(RollTimeIndex, TrueRollVar, bty="l", xlab="", ylab="")#
mtext("Variance", side=2,line=3, cex=1.5)#
plot(RollTimeIndex, Chl_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Metab_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2], bty="l", xlab="", ylab="")#
mtext("AR(1)", side=2,line=3, cex=1.5)#
mtext(expression(True~sigma[epsilon]^2*","~phi1[1]), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Chl_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(Chl*"-"*italic(a)), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Metab_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(widehat(M)*etabolism), side=1, line=4, cex=1.5)#
#
# LoopCounter <- LoopCounter + 1#
# LoopProgress <- LoopCounter/zzCounter#
# LoopElapsed <- (proc.time() - StartLoopTime)[[3]]/60#
# print(c("Elapsed"=round(LoopElapsed,1),"%Complete"=round(LoopProgress*100,1), "ETA"=round(LoopElapsed/LoopProgress-LoopElapsed,1), "LaYe"=paste(Lakes[La],Years[Ye],sep="_")))#
#
# dev.new()#
# plot(TrueRollVar, sqrt(Metab_RollVar))#
# summary(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# #
# dev.new()#
# plot(TrueRollAR1, Metab_RollAR1)#
# summary(lm(Metab_RollAR1~TrueRollAR1))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(Metab_RollAR1~TrueRollAR1))
#Ryan Batt#
#26-April-2012#
#Steve suggested using a toy model to assess how the noise can mask a squeal signal in metabolism, when the signal is seen in Chl#
#
# =============================================================#
# = Steve's suggested "simplest toy model of the GPP problem" =#
# =============================================================#
#Squeal Signal for Chl:#
#Chl[t+1] = Phi[t]*Chl[t] + Eps[t]#
#Phi[t] = 1 - exp(-K_Phi*t)  #Note that Phi grows asymptotically to 1#
#Sigma2_Eps[t] = K_Eps*t #The variance of the Chl autoregressive process grows over time#
#
#GPP + Junk Noise#
#DO[t+1] = K_GPP*DO[t] - K_DO*(DO[t] - DO[1]) + Junk[t]#
#Metab_hat = DO[t+1] - DO[t]#
#
rm(list=ls())#
graphics.off()#
require("zoo")#
#
Ar1 <-function(x){#
Nrmlzd <- x-mean(x)#
Y <- (x-mean(x))[-1]#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
}#
Ar1_Detrended <-function(x){#
#First detrend, if needed#
Model <- lm(x~c(1:length(x)))#
Summary <- coef(summary(Model))#
Slope <- Summary[2,1]#
PValue <- Summary[2,4]#
if(PValue<0.05){#
Xnew <- x-(Slope*c(1:length(x)))#
}else{#
Xnew <- x#
}#
#Calculate AR(1)#
Nrmlzd <- Xnew-mean(Xnew)#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(Xnew)])$coef[[2]])#
}#
#
# StartLoopTime <- proc.time()#
#
# RepsPerVar <- 3#
# JunkVarianceS <- seq(1E-6, 1E6, length.out=100)#
NStepsDefault <- 1000#
JunkVariance <- 1E2#
#
#
WindowSize <- 40#
RollTimeIndex <- 1:(NStepsDefault - (WindowSize-1))#
#
#
#
#Fiddling to find a way to "slowly" increase phi#
# Nsteps=1000#
# Time <- 1:Nsteps#
# K_Phi = -(log(0.5*(-0.95 + 1)))/(Nsteps) #-(log(-0.999 + 1.5)-2)/(Nsteps)#
# Phi <- 1 - 0.5*exp(-K_Phi*Time)  #1.5 - exp(-K_Phi*Time+2) #
# plot(Time, Phi)#
#
Chl_Model <- function(K_Phi=-(log(0.5*(-0.95 + 1)))/(Nsteps), K_Eps=1E-5, K_DO=0.5, Junk_Var=JunkVariance, Nsteps=NStepsDefault){#
Time <- 1:Nsteps#
Chl_0 <- 5 #A reasonable concentration of chlorophyll for Peter Lake in units of μg/L#
DO_0 <- 250 #A reasonable concentration of dissolved oxygen when O2 is near saturation at a typical temperature in Peter Lake, in units of μmols/L (is equal to 8 mg/L)#
#
Chl <- c(Chl_0,rep(NA,Nsteps-1))#
DO <- c(DO_0, rep(NA, Nsteps-1))#
#
Phi <- 1 - 0.5*exp(-K_Phi*Time)#
Sigma2_Eps <- K_Eps*Time#
#
K_GPP_t <- rep(NA,Nsteps)#
Junk <- rnorm(n=Nsteps, mean=0, sd=sqrt(Junk_Var))#
Metab_hat <- rep(NA,Nsteps-1)#
#
for(i in 1:(Nsteps-1)){#
Eps <- rnorm(n=1, mean=0, sd=sqrt(Sigma2_Eps[i]))#
Chl[i+1] <- Phi[i]*Chl[i] + Eps + Chl_0*(1-Phi[i]) #AR(1) plus noise model, with changing AR(1) coefficient and centered around a time series mean of Chl_0#
#
K_GPP_t[i] <- 1+log(Chl[i]/Chl_0) #The idea here is to allow [DO] to grow with the log ratio of current chlorophyll to the inital value of chlorophyll (supporting the notion that the system is at equilibrium when Chlorophyll and DO are at their initial values--- when chlorophyll is higher than its initial value, DO will increase; when chlorophyll is lower than its initial value, DO will decrease)#
DO[i+1] <- K_GPP_t[i]*DO[i] -K_DO*(DO[i]-DO_0) + Junk[i]#
Metab_hat[i] <- DO[i+1] - DO[i]#FIXME this should probably just be Metab_hat[i], but I did the +1 so that the last value wasn't NA#
#
}#
return(list("Chl"=matrix(data=c(Time,Chl), ncol=2),"K_GPP_t"=matrix(data=c(Time,K_GPP_t), ncol=2), "DO"=matrix(data=c(Time,DO), ncol=2), "Metab_hat"=matrix(data=c(Time[-length(Time)],Metab_hat), ncol=2), "True_Sigma2_Eps"=matrix(data=c(Time,Sigma2_Eps), ncol=2), "True_Phi"=matrix(data=c(Time,Phi), ncol=2)))#
#
#
}#
#
Test <- Chl_Model()#
dev.new()#
par(mfrow=c(2,2), mar=c(4,5,1,1))#
plot(Test[[1]], col="forestgreen", bty="l", ylab="Chl", xlab="", xaxt="n")#
plot(Test[[2]], ylab="K_GPP_t", xlab="", pch=20, bty="l", xaxt="n")#
plot(Test[[3]], ylab="DO", xlab="", bty="l")#
plot(Test[[4]], ylab="Metab_hat", xlab="", bty="l")#
#
Chl_RollVar <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=var)#
Chl_RollAR1 <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=Ar1_Detrended)#
#
Metab_RollVar <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=var)#
Metab_RollAR1 <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=Ar1_Detrended)#
#
TrueRollVar <- Test[[5]][is.element(Test[[5]][,1], RollTimeIndex),2]#
TrueRollAR1 <- Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2]#
#
dev.new(height=4.5, width=7)#
par(mfrow=c(2,3), family="Times", mar=c(4,3,1,1), oma=c(2,2,0,0), cex.axis=1.25)#
plot(RollTimeIndex, TrueRollVar, bty="l", xlab="", ylab="")#
mtext("Variance", side=2,line=3, cex=1.5)#
plot(RollTimeIndex, Chl_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Metab_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2], bty="l", xlab="", ylab="")#
mtext("AR(1)", side=2,line=3, cex=1.5)#
mtext(expression(True~sigma[epsilon]^2*","~phi1[1]), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Chl_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(Chl*"-"*italic(a)), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Metab_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(widehat(M)*etabolism), side=1, line=4, cex=1.5)#
#
# LoopCounter <- LoopCounter + 1#
# LoopProgress <- LoopCounter/zzCounter#
# LoopElapsed <- (proc.time() - StartLoopTime)[[3]]/60#
# print(c("Elapsed"=round(LoopElapsed,1),"%Complete"=round(LoopProgress*100,1), "ETA"=round(LoopElapsed/LoopProgress-LoopElapsed,1), "LaYe"=paste(Lakes[La],Years[Ye],sep="_")))#
#
# dev.new()#
# plot(TrueRollVar, sqrt(Metab_RollVar))#
# summary(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# #
# dev.new()#
# plot(TrueRollAR1, Metab_RollAR1)#
# summary(lm(Metab_RollAR1~TrueRollAR1))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(Metab_RollAR1~TrueRollAR1))
#Ryan Batt#
#26-April-2012#
#Steve suggested using a toy model to assess how the noise can mask a squeal signal in metabolism, when the signal is seen in Chl#
#
# =============================================================#
# = Steve's suggested "simplest toy model of the GPP problem" =#
# =============================================================#
#Squeal Signal for Chl:#
#Chl[t+1] = Phi[t]*Chl[t] + Eps[t]#
#Phi[t] = 1 - exp(-K_Phi*t)  #Note that Phi grows asymptotically to 1#
#Sigma2_Eps[t] = K_Eps*t #The variance of the Chl autoregressive process grows over time#
#
#GPP + Junk Noise#
#DO[t+1] = K_GPP*DO[t] - K_DO*(DO[t] - DO[1]) + Junk[t]#
#Metab_hat = DO[t+1] - DO[t]#
#
rm(list=ls())#
graphics.off()#
require("zoo")#
#
Ar1 <-function(x){#
Nrmlzd <- x-mean(x)#
Y <- (x-mean(x))[-1]#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
}#
Ar1_Detrended <-function(x){#
#First detrend, if needed#
Model <- lm(x~c(1:length(x)))#
Summary <- coef(summary(Model))#
Slope <- Summary[2,1]#
PValue <- Summary[2,4]#
if(PValue<0.05){#
Xnew <- x-(Slope*c(1:length(x)))#
}else{#
Xnew <- x#
}#
#Calculate AR(1)#
Nrmlzd <- Xnew-mean(Xnew)#
return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(Xnew)])$coef[[2]])#
}#
#
# StartLoopTime <- proc.time()#
#
# RepsPerVar <- 3#
# JunkVarianceS <- seq(1E-6, 1E6, length.out=100)#
NStepsDefault <- 1000#
JunkVariance <- 1E0#
#
#
WindowSize <- 40#
RollTimeIndex <- 1:(NStepsDefault - (WindowSize-1))#
#
#
#
#Fiddling to find a way to "slowly" increase phi#
# Nsteps=1000#
# Time <- 1:Nsteps#
# K_Phi = -(log(0.5*(-0.95 + 1)))/(Nsteps) #-(log(-0.999 + 1.5)-2)/(Nsteps)#
# Phi <- 1 - 0.5*exp(-K_Phi*Time)  #1.5 - exp(-K_Phi*Time+2) #
# plot(Time, Phi)#
#
Chl_Model <- function(K_Phi=-(log(0.5*(-0.95 + 1)))/(Nsteps), K_Eps=1E-5, K_DO=0.5, Junk_Var=JunkVariance, Nsteps=NStepsDefault){#
Time <- 1:Nsteps#
Chl_0 <- 5 #A reasonable concentration of chlorophyll for Peter Lake in units of μg/L#
DO_0 <- 250 #A reasonable concentration of dissolved oxygen when O2 is near saturation at a typical temperature in Peter Lake, in units of μmols/L (is equal to 8 mg/L)#
#
Chl <- c(Chl_0,rep(NA,Nsteps-1))#
DO <- c(DO_0, rep(NA, Nsteps-1))#
#
Phi <- 1 - 0.5*exp(-K_Phi*Time)#
Sigma2_Eps <- K_Eps*Time#
#
K_GPP_t <- rep(NA,Nsteps)#
Junk <- rnorm(n=Nsteps, mean=0, sd=sqrt(Junk_Var))#
Metab_hat <- rep(NA,Nsteps-1)#
#
for(i in 1:(Nsteps-1)){#
Eps <- rnorm(n=1, mean=0, sd=sqrt(Sigma2_Eps[i]))#
Chl[i+1] <- Phi[i]*Chl[i] + Eps + Chl_0*(1-Phi[i]) #AR(1) plus noise model, with changing AR(1) coefficient and centered around a time series mean of Chl_0#
#
K_GPP_t[i] <- 1+log(Chl[i]/Chl_0) #The idea here is to allow [DO] to grow with the log ratio of current chlorophyll to the inital value of chlorophyll (supporting the notion that the system is at equilibrium when Chlorophyll and DO are at their initial values--- when chlorophyll is higher than its initial value, DO will increase; when chlorophyll is lower than its initial value, DO will decrease)#
DO[i+1] <- K_GPP_t[i]*DO[i] -K_DO*(DO[i]-DO_0) + Junk[i]#
Metab_hat[i] <- DO[i+1] - DO[i]#FIXME this should probably just be Metab_hat[i], but I did the +1 so that the last value wasn't NA#
#
}#
return(list("Chl"=matrix(data=c(Time,Chl), ncol=2),"K_GPP_t"=matrix(data=c(Time,K_GPP_t), ncol=2), "DO"=matrix(data=c(Time,DO), ncol=2), "Metab_hat"=matrix(data=c(Time[-length(Time)],Metab_hat), ncol=2), "True_Sigma2_Eps"=matrix(data=c(Time,Sigma2_Eps), ncol=2), "True_Phi"=matrix(data=c(Time,Phi), ncol=2)))#
#
#
}#
#
Test <- Chl_Model()#
dev.new()#
par(mfrow=c(2,2), mar=c(4,5,1,1))#
plot(Test[[1]], col="forestgreen", bty="l", ylab="Chl", xlab="", xaxt="n")#
plot(Test[[2]], ylab="K_GPP_t", xlab="", pch=20, bty="l", xaxt="n")#
plot(Test[[3]], ylab="DO", xlab="", bty="l")#
plot(Test[[4]], ylab="Metab_hat", xlab="", bty="l")#
#
Chl_RollVar <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=var)#
Chl_RollAR1 <- rollapplyr(Test[[1]][,2], width=WindowSize, by=1, FUN=Ar1_Detrended)#
#
Metab_RollVar <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=var)#
Metab_RollAR1 <- rollapplyr(Test[[4]][,2], width=WindowSize-1, by=1, FUN=Ar1_Detrended)#
#
TrueRollVar <- Test[[5]][is.element(Test[[5]][,1], RollTimeIndex),2]#
TrueRollAR1 <- Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2]#
#
dev.new(height=4.5, width=7)#
par(mfrow=c(2,3), family="Times", mar=c(4,3,1,1), oma=c(2,2,0,0), cex.axis=1.25)#
plot(RollTimeIndex, TrueRollVar, bty="l", xlab="", ylab="")#
mtext("Variance", side=2,line=3, cex=1.5)#
plot(RollTimeIndex, Chl_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Metab_RollVar, bty="l", xlab="", ylab="")#
plot(RollTimeIndex, Test[[6]][is.element(Test[[6]][,1], RollTimeIndex),2], bty="l", xlab="", ylab="")#
mtext("AR(1)", side=2,line=3, cex=1.5)#
mtext(expression(True~sigma[epsilon]^2*","~phi1[1]), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Chl_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(Chl*"-"*italic(a)), side=1, line=4, cex=1.5)#
plot(RollTimeIndex, Metab_RollAR1, bty="l", xlab="", ylab="")#
mtext(expression(widehat(M)*etabolism), side=1, line=4, cex=1.5)#
#
# LoopCounter <- LoopCounter + 1#
# LoopProgress <- LoopCounter/zzCounter#
# LoopElapsed <- (proc.time() - StartLoopTime)[[3]]/60#
# print(c("Elapsed"=round(LoopElapsed,1),"%Complete"=round(LoopProgress*100,1), "ETA"=round(LoopElapsed/LoopProgress-LoopElapsed,1), "LaYe"=paste(Lakes[La],Years[Ye],sep="_")))#
#
# dev.new()#
# plot(TrueRollVar, sqrt(Metab_RollVar))#
# summary(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(sqrt(Metab_RollVar)~TrueRollVar))#
# #
# dev.new()#
# plot(TrueRollAR1, Metab_RollAR1)#
# summary(lm(Metab_RollAR1~TrueRollAR1))#
# dev.new();par(mfrow=c(2,2))#
# plot(lm(Metab_RollAR1~TrueRollAR1))
graphics.off()
#pushup workout script
dev.new(width=10, height=3)
par(mfrow=c(1,4), mar=c(2,1,1,1), oma=c(3,3,3,0), las=1, family="Times")
TempLM <- lm(R08_BK_Smooth[,"GPP"]~R08ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R08ChlDaily, R08_BK_Smooth[,"GPP"], xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("Filtered BK GPP", side=2, line=2.5, las=0)
mtext("R 2008 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R09_BK_Smooth[,"GPP"]~R09ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R09ChlDaily, R09_BK_Smooth[,"GPP"], xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2009 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R10_BK_Smooth[,"GPP"]~R10ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R10ChlDaily, R10_BK_Smooth[,"GPP"], xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2010 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R11_BK_Smooth[,"GPP"]~R11ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R11ChlDaily, R11_BK_Smooth[,"GPP"], xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2011 Chl", side=1, line=2.5, las=0)
dev.new(width=10, height=3)
par(mfrow=c(1,4), mar=c(2,1,1,1), oma=c(3,3,3,0), las=1, family="Times")
TempLM <- lm(R08_BK_Smooth_Impd_GPP~R08ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R08ChlDaily, R08_BK_Smooth_Impd_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("Filtered BK GPP", side=2, line=2.5, las=0)
mtext("R 2008 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R09_BK_Smooth_Impd_GPP~R09ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R09ChlDaily, R09_BK_Smooth_Impd_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2009 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R10_BK_Smooth_Impd_GPP~R10ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R10ChlDaily, R10_BK_Smooth_Impd_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2010 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R11_BK_Smooth_Impd_GPP~R11ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R11ChlDaily, R11_BK_Smooth_Impd_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2011 Chl", side=1, line=2.5, las=0)
dev.new(width=10, height=3)
par(mfrow=c(1,4), mar=c(2,1,1,1), oma=c(3,3,3,0), las=1, family="Times")
TempLM <- lm(R08_BK_Smooth_AR1_Pred_GPP~R08ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R08ChlDaily, R08_BK_Smooth_AR1_Pred_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("Filtered BK GPP", side=2, line=2.5, las=0)
mtext("R 2008 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R09_BK_Smooth_AR1_Pred_GPP~R09ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R09ChlDaily, R09_BK_Smooth_AR1_Pred_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2009 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R10_BK_Smooth_AR1_Pred_GPP~R10ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R10ChlDaily, R10_BK_Smooth_AR1_Pred_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2010 Chl", side=1, line=2.5, las=0)
TempLM <- lm(R11_BK_Smooth_AR1_Pred_GPP~R11ChlDaily)
TempMain <- paste("R^2",round(summary(TempLM)$r.squared,3),sep="=")
plot(R11ChlDaily, R11_BK_Smooth_AR1_Pred_GPP, xlab="", ylab="", bty="l", xaxt="s", main=TempMain)
abline(TempLM, lwd=2)
mtext("R 2011 Chl", side=1, line=2.5, las=0)
#0.1.0 == Scrapped old strategy in favor of using "zoo" package to do rolling window statistics, etc.
load("/Users/Battrd/Documents/School&Work/WiscResearch/SquealMetabolism/SquealMetabolism_v1.0.2_DailyZoopTest_FinishedRun.RData")
SS_R08_BK_NEP
?array
?t.test
ls()
Variables
Stats
SS_L10ChlDaily
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			StatTable[vari,ye,stat] <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep="")[,stat]) - get(paste("SS_L",ye_s[ye],vari_s[vari], sep="")[,stat])#
		}#
		#
		#
	}#
	#
}
get(paste("SS_R",ye_s[ye],vari_s[vari], sep="")
get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			StatTable[vari,ye,stat] <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
		}#
		#
		#
	}#
	#
}
get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat]
get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]
TempoVecDiff
length(which(TempoVecDiff>0))/length(TempoVecDiff)
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
			StatTable[vari,ye,stat] <- length(which(TempoVecDiff>0))/length(TempoVecDiff)#
		}#
		#
		#
	}#
	#
}
StatTable
TempoVecDiff
t.test(x=get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat], y=get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat], paried=TRUE)
sum(TempoVecDiff[which(TempoVecDiff>0))]) / -sum(TempoVecDiff[which(TempoVecDiff>0))])
-sum(TempoVecDiff[which(TempoVecDiff>0)])
sum(TempoVecDiff[which(TempoVecDiff>0)])
-sum(TempoVecDiff[which(TempoVecDiff<0)])
sum(TempoVecDiff[which(TempoVecDiff>0)]) / -sum(TempoVecDiff[which(TempoVecDiff<0)])
#
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
			# StatTable[vari,ye,stat] <- length(which(TempoVecDiff>0))/length(TempoVecDiff)#
			StatTable[vari,ye,stat] <- sum(TempoVecDiff[which(TempoVecDiff>0)]) / -sum(TempoVecDiff[which(TempoVecDiff<0)])#
		}#
		#
		#
	}#
	#
}
StatTable
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
			# StatTable[vari,ye,stat] <- length(which(TempoVecDiff>0))/length(TempoVecDiff)#
			# StatTable[vari,ye,stat] <- sum(TempoVecDiff[which(TempoVecDiff>0)]) / -sum(TempoVecDiff[which(TempoVecDiff<0)])#
			StatTable[vari,ye,stat] <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] / get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
		}#
		#
		#
	}#
	#
}
StatTable <- array(dim=c(4,4,length(Stats)))#
vari_s <- c("_BK_NEP", "_DO_Mean", "ChlDaily", "pHDaily")#
ye_s <- c("08", "09", "10", "11")#
for(vari in 1:4){#
	for(ye in 1:4){#
		for(stat in 1:length(Stats)){#
			TempoVecDiff <- get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat] - get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat]#
			# StatTable[vari,ye,stat] <- length(which(TempoVecDiff>0))/length(TempoVecDiff)#
			# StatTable[vari,ye,stat] <- sum(TempoVecDiff[which(TempoVecDiff>0)]) / -sum(TempoVecDiff[which(TempoVecDiff<0)])#
			StatTable[vari,ye,stat] <- sum(get(paste("SS_R",ye_s[ye],vari_s[vari], sep=""))[,stat]) / sum(get(paste("SS_L",ye_s[ye],vari_s[vari], sep=""))[,stat])#
		}#
		#
		#
	}#
	#
}
StatTable
as.POSIXct("2010-08-20")
format(as.POSIXct("2010-08-20"), "%j")
format(as.POSIXct("2010-08-18"), "%j")
length(xout08)
length(Days08)
length(Days09)
length(Days10)
length(Days11)
?cor
cor(1:10, ((1:10)+rnorm(n=10)))
cor.test(1:10, ((1:10)+rnorm(n=10)))
#Ryan Batt! 8-Oct-09#
#Calculating the area and volume between each contour on Ward Lake Bathymetric Map.  #
#The volumes are calculated in terms of a)"volume that is <= 2 meters" b)"volume that is between 3 meters and 5 meters"#
#Taking these known areas/volumes to transform volumetric metabolism data into absolute metabolism data for the 0-2m layer, and the 3-5m layer.#
#
#
#***Other Notes****#
#0-2m is the epilimnion, and is referred to as "shallow"#
#3-5m is a portion of the metalimnion, and is referred to as "deep"#
#Metabolism estimates are from simultaneously deployed sondes at 4m and 1m; deployment length was 12 days.#
#1m sonde sampled temp/DO every 5 minutes#
#4m sonde sampled temp/DO ever 10 minutes (should have been 5)#
#There was a strong oxygen and chl-a maximum at 4m when the sonde data was collected#
#
rm.list=ls()#
graphics.off()#
#
#Convert pixels to hectares#
#List of pixels between each set of contours#
PixPart <- c(66, 6598, 17408, 24901, 87470, 28071, 24258, 17435, 24731, 44946)#
#
#
#
#Total area of Ward Lake in Pixels#
PixTot <- sum(PixPart)#
#
#Total area of Ward Lake in hectares#
HectTot <- 2.74#
#
#
#
#List of areas between each set of contours in hectares#
HectPart <- rep(0, 10)#
for (i in 1:10) {#
	HectPart[i] <- (PixPart[i]*HectTot)/PixTot#
	}#
#Set sequence to outer-inner#
HP <- rev(HectPart)#
#
#Convert area to square meters (SMP = square meter part)#
SMP <- HP * 10000 #
#
#
ContsFt <- c(0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 27)#
ContsMet <- ContsFt*.305#
ContsMet#
length(ContsMet)#
#
#Shorten object names (aids in laziness)#
HT <- HectTot#
CM <- ContsMet#
#
#Calc total volume that is <= 2m#
ShalVols <- rep(0, 10) #create empty vector for shallow volumes#
SVs <- ShalVols #just so I can be lazy#
#
#
#
for(i in 1:10) {#
	if(CM[i+1] <= 2) {#
		SVs[i] <- ((CM[i+1] + CM[i])/2) * SMP[i]#
		} else {#
			if(CM[i] >= 2) {#
				SVs[i] <- SMP[i] * 2#
				} else {#
					SVs[i] <- ((((CM[i+1]-2)/(CM[i+1]-CM[i])) * 2) + (((2-CM[i])/(CM[i+1]-CM[i])) * (.5*(2+CM[i])))) * SMP[i]#
					}#
					}#
			}#
TotalShallowVolume <- sum(SVs)#
#TotalShallowVolume #in Meters Cubed#
#
#Calc total volume between 3m and 5m; I am cheating here and just doing the calculations. They are still accurate, but not applicable to other contour series.#
#
#First 3 are 0#
#Second 3 are lame#
#Last 4 are 2#
#
#Set up the vector to store the deep volumes#
DVs <- rep(0, 10)#
#
DVs[4] <- ((0+.66)/2) * SMP[4]#
DVs[5] <- ((.66+1.575)/2) * SMP[5]#
DVs[6] <- (((.490/.915)*2) + ((.425/.915)*(.5*(1.575+2))))*SMP[6]#
DVs[7:10] <- 2*SMP[7:10]#
#
#
TotalDeepVolume <- sum(DVs)#
#
TotalShallowVolume#
TotalDeepVolume#
#
TotalVolumeMeasured <- TotalShallowVolume + TotalDeepVolume#
TotalVolumeMeasured#
TotalDeepVolume/TotalShallowVolume#
TotalDeepVolume/TotalVolumeMeasured#
#
DeepGPPVol <- 42.22#
DeepRVol <- -53.79#
DeepNEPVol <- -11.57#
DeepVolEst <- c(42.22, -53.79, -11.57) #GPP, R, NEP#
#
ShalGPPVol <- 24.37#
ShalRVol <- -28.73#
ShalNEPVol <- -4.361#
ShalVolEst <- c(24.37, -28.73, -4.361) #GPP, R, NEP#
#
ShalTotEst <- TotalShallowVolume * ShalVolEst#
DeepTotEst <- TotalDeepVolume * DeepVolEst #
#
ShalTotEst #Shallow GPP, R, NEP in mmol C/day#
DeepTotEst #Deep GPP, R, NEP in mmol C/day#
#
TotalEst <- ShalTotEst + DeepTotEst#
#
ShalTotEst/TotalEst #%GPP, R, NEP that occured in Shallow#
DeepTotEst/TotalEst #%GPP, R, NEP that occured in Deep#
#
(DeepTotEst-ShalTotEst)/TotalEst#
#
sum(PixPart[7:10])/PixTot#
#
AvgDepthPerCont <- c(27, 25.5, 22.5, 19.5, 16.5, 13.5, 10.5, 7.5, 4.5, 1.5)#
#VolumeInfected in units of m^3#
VolumeInfected <- sum((AvgDepthPerCont[7:10]*0.305 * HectPart[7:10]) * 0.38 *10000) #38% macrophytes in this region of Ward Lake (supposed to be within 30 m of shore, so I guessed this tends to be at the 12 ft contour)#
PVI <- VolumeInfected / sum(AvgDepthPerCont * HectPart *0.305 *10000) *100#
MeanDepthWard <- sum(AvgDepthPerCont*0.305 * HectPart*10000 /(HectTot*10000))
MeanDepthWard
AvgDepthPerCont
HectPart
MeanDepthWard <- sum(AvgDepthPerCont*0.305 * (HectPart*10000 /(HectTot*10000)))
MeanDepthWard
(HectPart*10000 /(HectTot*10000))
HectTot
AvgDepthPerCont*0.305 * (HectPart*10000 /(HectTot*10000))
sum(HectPart*10000 /(HectTot*10000))
MeanDepthWard <- sum(AvgDepthPerCont*0.305 * (HectPart*10000 /(HectTot*10000)))
MeanDepthWard
AvgDepthPerCont
Pre_AvgDepthPerCont <- c(AvgDepthPerCont[-1],0)
Pre_AvgDepthPerCont
(Pre_AvgDepthPerCont + AvgDepthPerCont)/2
Avg_AvgDepthPerCont <- (Pre_AvgDepthPerCont + AvgDepthPerCont)/2
MeanDepthWard <- sum(Avg_AvgDepthPerCont*0.305 * (HectPart*10000 /(HectTot*10000)))
MeanDepthWard
plot(1:10, exp(1:10))
plot(1:10, 1:10)
plot(exp(1:10), 1:10)
rm(list=ls())#
graphics.off()#
library("zoo")#
library("ggplot2")#
#
# ====================#
# = Set some options =#
# ====================#
kQuse <- 0 #0.4 #0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
hQuse <- 0.5 #Handling time on colonial algae at kQ = 0, day#
Kstart <- 5#
Kstop <- 10#
K2graph <- c(5, 8.3)#
ForBac <- c(TRUE, FALSE)[2] #Plot state variables when K is increasing as well as when K is decreasing?  FALSE is just increasing.#
Days <- 100 #Number of days over which to simulate#
DailySteps <- 20 #Number of steps per day (this is essentially dt)#
# DaysPerK <- 1 #"Days" has to be a multiple of DaysPerK. For each rate of carrying capacity (nutrient loading) (k), how many days should that rate be maintained (e.g., if 7, k will only change once per week)#
nBurn <- 10#
nBurnSave <- 1#
xNaught <- c(0.0065, 1.33, 1.4) #c(0.025, 1.75, 0.75) #c(0.01, 2.56, 1.9) #When k is increasing over the simulation, these are the starting values for unicell, colonial, and zoops (g/m^3)#
revxNaught <-  xNaught #c(0.8, 4.5, 0.25) #c(0.01, 3.4, 2) #When k is decreasing over the simulation, these are the starting values for unicell, colonial, and zoops (g/m^3)#
SigmaPQZ <- c(0.0001, 0.00256, 0.0019)*0.5  #c(0.000001, 0.000256, 0.00019) #
AddNoise <- c(TRUE, FALSE)[1] #Will be used as a coefficient in the noise simulations.  In multiplication, R interprets TRUE as 1, and FALSE as 0.#
AddKnoise <- c(TRUE, FALSE)[2]#
Ksd <- 0.25#
AddCata <- c(TRUE, FALSE)[2]#
CataAmp <- 100#
ProbCata <- 0.005#
nvec <- 5#
ExpStability <- c(TRUE, FALSE)[1]#
#
WinSize=100#
#
Kh <- (r/(r-mQ))*(1/vQ)*(((2*mZ)/(nu-mZ*hQuse))+(1/hQuse))#
#
# ================================================#
# = Main function to calculate dXdt at each step =#
# ================================================#
xRates <- function(x0, K, hQ=0.5, kQ=0.565, Exp=FALSE){#
	# ==============#
	# = Parameters =#
	# ==============#
	# K <- 5.0 #Carrying capacity, g/m^3#
	r <- 1.0 #Maximum growth rate of algae, day^-1#
	c <- 1.0 #scaling parameter for inducible effect, day^-1#
	g <- 0.1 #half-saturation constant for inducible effect, g/m^3#
	vP <- 0.5 #search rate on unicellular algae, m^2 g^-1 day^-1#
	hP <- 0.5 #handling time on unicellular algae, day#
	mP <- 0.2 #Mortality rate of unicellular algae, day^-1#
	vQ <- 0.5 #Search rate on colonial algae, m^3 g^-1 day^-1#
	# hQ <- 0.5 #Handling time on colonial algae at kQ = 0, day#
	# kQ <- 0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
	mQ <- 0.2 #Mortality rate of colonial algae, day^-1#
	nu <- 0.4 #assimilation coefficient on algae#
	mZ <- 0.2 #Mortality rate of zooplankton, day^-1 #Changing mortality to 0.15 under the conditions of Fig. 5 in Serizawa 2007 produces weird oscillations at K>4.71#
	# =========================#
	# = State variable values =#
	# =========================#
	if(Exp){#
		P <- exp(x0[1])#
		Q <- exp(x0[2])#
		Z <- exp(x0[3])#
	}else{#
		P <- x0[1]#
		Q <- x0[2]#
		Z <- x0[3]#
	}#
	# =========#
	# = Rates =#
	# =========#
	#First define convenient, repeatable parts to the equations#
	Logis <- r*(1 - (P+Q)/K)#
	PInduc <- P*(c*Z^2)/(Z^2+g^2)#
	QInduc <- Q*(c*g^2)/(Z^2+g^2)#
	ConsP <- vP*hP*P#
	ConsQ <- vQ*hQ*Q*(1+kQ*Q)#
	#Simulate each dimension#
	dPdt <- P*Logis - PInduc + QInduc - (vP*P*Z)/(1 + ConsP + ConsQ) - mP*P#
	dQdt <- Q*Logis + PInduc - QInduc - (vQ*Q*Z)/(1 + ConsP + ConsQ) - mQ*Q#
	dZdt <- (nu*(vP*P + vQ*Q)*Z)/(1 + ConsP + ConsQ) - mZ*Z#
	#Save dXdt's as a vector for P, Q, and Z#
	dXdt <- c(dPdt, dQdt, dZdt)#
	return(dXdt)#
}#
#
# ================================================#
# = Main function to calculate dXdt at each step =#
# ================================================#
xRates_jac <- function(t, x0, parms, K, hQ=0.5, kQ=0.565, Exp=FALSE){#
	# ==============#
	# = Parameters =#
	# ==============#
	# K <- 5.0 #Carrying capacity, g/m^3#
	r <- 1.0 #Maximum growth rate of algae, day^-1#
	c <- 1.0 #scaling parameter for inducible effect, day^-1#
	g <- 0.1 #half-saturation constant for inducible effect, g/m^3#
	vP <- 0.5 #search rate on unicellular algae, m^2 g^-1 day^-1#
	hP <- 0.5 #handling time on unicellular algae, day#
	mP <- 0.2 #Mortality rate of unicellular algae, day^-1#
	vQ <- 0.5 #Search rate on colonial algae, m^3 g^-1 day^-1#
	# hQ <- 0.5 #Handling time on colonial algae at kQ = 0, day#
	# kQ <- 0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
	mQ <- 0.2 #Mortality rate of colonial algae, day^-1#
	nu <- 0.4 #assimilation coefficient on algae#
	mZ <- 0.2 #Mortality rate of zooplankton, day^-1 #Changing mortality to 0.15 under the conditions of Fig. 5 in Serizawa 2007 produces weird oscillations at K>4.71#
	# =========================#
	# = State variable values =#
	# =========================#
	if(Exp){#
		P <- exp(x0[1])#
		Q <- exp(x0[2])#
		Z <- exp(x0[3])#
	}else{#
		P <- x0[1]#
		Q <- x0[2]#
		Z <- x0[3]#
	}#
	# =========#
	# = Rates =#
	# =========#
	#First define convenient, repeatable parts to the equations#
	Logis <- r*(1 - (P+Q)/K)#
	PInduc <- P*(c*Z^2)/(Z^2+g^2)#
	QInduc <- Q*(c*g^2)/(Z^2+g^2)#
	ConsP <- vP*hP*P#
	ConsQ <- vQ*hQ*Q*(1+kQ*Q)#
	#Simulate each dimension#
	dPdt <- P*Logis - PInduc + QInduc - (vP*P*Z)/(1 + ConsP + ConsQ) - mP*P#
	dQdt <- Q*Logis + PInduc - QInduc - (vQ*Q*Z)/(1 + ConsP + ConsQ) - mQ*Q#
	dZdt <- (nu*(vP*P + vQ*Q)*Z)/(1 + ConsP + ConsQ) - mZ*Z#
	#Save dXdt's as a vector for P, Q, and Z#
	dXdt <- c(dPdt, dQdt, dZdt)#
	return(dXdt)#
}#
#
Ar1 <-function(x){#
	# ac <- cor(x[-1],x[-length(x)])#
	ac <- ar.ols(x, order.max=1)$ar#
	# Nrmlzd <- x-mean(x)#
	# Y <- (x-mean(x))[-1]#
	# return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
	#return(arima(x, order=c(1,0,0))$coef[[1]])#
	return(ac)#
}#
#
Ar1 <-function(x){#
	ac <- cor(x[-1],x[-length(x)])#
	# Nrmlzd <- x-mean(x)#
	# Y <- (x-mean(x))[-1]#
	# return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
	#return(arima(x, order=c(1,0,0))$coef[[1]])#
	return(ac)#
}#
#
CH <- function(X){#
	nobs <- length(X)#
	Xt0 <- X[-c(1:4)]#
	Xt1 <- X[-c(1:3, nobs)]#
	Xt2 <- X[-c(1:2, (nobs-1):nobs)]#
	Xt3 <- X[-c(1, (nobs-2):nobs)]#
	Xt4 <- X[-c((nobs-3):nobs)]#
	ModelAR <- lm(Xt0~Xt1+Xt2+Xt3+Xt3+Xt4)#
	Res <- as.numeric(ModelAR$resid)#
	Res2 <- Res^2#
	Res2t0 <- Res2[-1]#
	Res2t1 <- Res2[-length(Res2)]#
	ModelCH <- lm(Res2t0~Res2t1)#
	R2 <- summary(ModelCH)$r.squared#
	# PosResult <- ifelse(Pvalue<=0.05,1,0)#
	return(R2)#
}#
#
SquealStats <- function(Data, WinSize){#
	StatNames <- c("Var", "AR1")#
	ReturnStats0 <- rbind(apply(Data, 2, rollapplyr, width=WinSize, var), apply(Data, 2, rollapplyr, width=WinSize, Ar1))#
	colnames(ReturnStats0) <- colnames(Data)#
	nstatsPer <- nrow(ReturnStats0)/length(StatNames)#
	ReturnStats1 <- data.frame(ReturnStats0, "Stat"=c(rep(StatNames[1],nstatsPer), rep(StatNames[2], nstatsPer)))#
	return(ReturnStats1)#
}#
# test <- SquealStats(Xobs, 5)#
# head(test)#
# tail(test)#
#
# SquealStats <- function(Data, WinSize){	#
	# ReturnStats <- data.frame("Var"=rollapplyr(Data, width=WinSize, FUN=var), "AR1"=rollapplyr(Data, width=WinSize, FUN=Ar1))#
	# return(ReturnStats)#
# }#
# , "CH"=rollapplyr(Data, width=WinSize, FUN=CH)#
#
#
# ===========================================================================================================#
# = Set up the simulation (given the options chosen at top of script, define duration, frequency, dt, etc.) =#
# ===========================================================================================================#
Nobs <- Days*DailySteps*nBurnSave #number of observations to be simulated#
Time <- seq(1,Days*nBurnSave+(1-1/DailySteps), by=1/DailySteps)#
dt <- 1/DailySteps #the size of the time step in units=days#
Kgrad <- rep(seq(Kstart, Kstop, length.out=Days), each=DailySteps*nBurnSave) #changes in carrying capacity for each Euler iteration, but K only changes between days, not within a day#
KgradDaily <- seq(Kstart, Kstop, length.out=Days)  #rep(seq(Kstart, Kstop, length.out=Days), each=nBurnSave) #changes in carrying capacity for each Euler iteration, but K only changes between days, not within a day#
Xobs <- matrix(data=NA, nrow=Nobs, ncol=3, dimnames=list(NULL,c("P","Q","Z"))) #To store the simulated state variables#
Xobs[1,] <- xNaught#
revXobs <- matrix(data=NA, nrow=Nobs, ncol=3, dimnames=list(NULL,c("P","Q","Z"))) #To store the simulated state variables#
revXobs[1,] <- revxNaught #Xobs[Nobs,] #Xobs[Nobs,]#*2#
#
# Noise <- matrix(rnorm(n=Nobs*3, mean=0, sd=0.001), nrow=Nobs, ncol=3)#
# AddNoise <- c(TRUE, FALSE)[2]#
#
# =====================================#
# = Simulate time series of P, Q, & Z =#
# =====================================#
Noise1 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]), rnorm(n=Nobs, sd=SigmaPQZ[2]), rnorm(n=Nobs, sd=SigmaPQZ[3])), ncol=3) * AddNoise#
Noise2 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]), rnorm(n=Nobs, sd=SigmaPQZ[2]), rnorm(n=Nobs, sd=SigmaPQZ[3])), ncol=3) * AddNoise#
#
KgradSim <- Kgrad + (rnorm(n=Nobs, sd=Ksd)*AddKnoise)#
# Knoise2 <- rnorm(n=Nobs, sd=Ksd)*AddKnoise#
#
CataNoise1 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[2]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[3]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata)), ncol=3) * AddCata#
CataNoise2 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[2]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[3]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata)), ncol=3) * AddCata#
#
#Simulate while increasing k#
# Burnt <- array(dim=c(nBurn*DailySteps, ncol(Xobs), Days*nBurnSave), dimnames=list("BurnIn"=seq_len(nBurn*DailySteps), "State"=c("P","Q","Z"), "K"=rep(round(seq(Kstart, Kstop, length.out=Days),3),nBurnSave)))#
Burnt <- array(dim=c(nBurn*DailySteps, ncol(Xobs), Days), dimnames=list("BurnIn"=seq_len(nBurn*DailySteps), "State"=c("P","Q","Z"), "K"=round(seq(Kstart, Kstop, length.out=Days),3)))#
# plot(seq_len(Days), round(seq(Kstart, Kstop, length.out=Days),3))#
#
Burnt[1,,1] <- xNaught#
Last <- xNaught#
# iCountRoot <- 1#
iCount <- 1#
for(d in 1:Days){#
	Know <- KgradDaily[d]#
	for(b in seq_len(nBurn)){#
		# if(b<=(nBurn-nBurnSave)){#
			# iCount <- iCountRoot #reset the iCount value to what it would be if there was no burn-in period#
		# }#
		for(delT in 1:DailySteps){#
			if(d==1&b==1&delT==1){#
				next#
			}#
			bCount <- (b-1)*DailySteps + delT#
			# iCount <- (d-1)*DailySteps + delT#
			Burnt[bCount,,d] <- xRates(x0=Last, K=Know, kQ=kQuse)*dt + Last + (Noise1[iCount,] + CataNoise1[iCount,])*sqrt(dt)#
			Last <- Burnt[bCount,,d]#
			if(b>=(nBurn-nBurnSave+1)){#
				Xobs[iCount,] <- Last #xRates(x0=Xobs[iCount-1,], K=Know, kQ=kQuse)*dt + Xobs[iCount-1,] + (Noise1[iCount,] + CataNoise1[iCount,])*sqrt(dt)#
				iCount <- iCount+1#
			}#
		}#
	}#
}#
#
#
if(ForBac){#
	#Simulate while decreasing k#
	for(i in 2:Nobs){#
		revXobs[i,] <- xRates(x0=revXobs[i-1,], K=KgradSim[Nobs-i], kQ=kQuse)*dt + revXobs[i-1,] + Noise2[i,]*sqrt(dt)#
	}#
}#
#
#
# qui <- function(x) ma#
#
#
#Stability analysis#
Pvec <- seq(0.001, 1, length.out=nvec)#
Qvec <- seq(2, 5, length.out=nvec)#
Zvec <- seq(0.001, 2, length.out=nvec)#
Kvec <- seq(5, 7, length.out=nvec)#
StabilityStarts0 <- as.matrix(expand.grid(list("Pvec"=Pvec, "Qvec"=Qvec, "Zvec"=Zvec, "Kvec"=Kvec)))#
if(ExpStability){StabilityStarts <- log(StabilityStarts0)}#
# for(i in seq_len(nvec)){#
	# Roots0 <- multiroot(xRates, start=StabilityStarts[i,1:3], K=StabilityStarts[i,4], Exp=ExpStability)$root#
	# if(ExpStability){Roots <- exp(Roots0)}else{Roots <- Roots0}#
	# names(Roots) <- NULL#
	# JacMat <- jacobian.full(Roots, xRates_jac, K=StabilityStarts[i,4])#
	# Lambda <- eigen(JacMat, only.values=TRUE)#
	#
	# Pos <- ifelse(Roots[1]>0 & Roots[2]>0 & Roots[3],1,0) # is it positive?#
	# Stab <- ifelse(Re(Lamda$values[1])<0 & Re(Lamda$values[2])<0 & Re(Lamda$values[3])<0,1,0) # is it stable?#
	#
	# if(Im(Lamda$values[1])==0#
	#
	# Osc <- ifelse(Im(Lamda$values[1])!=0,1,0) # does it oscillate?\#
	#
	# Alogic <- matrix(c(0,0,0, 1,1,1#
	#
	# Atype <- 0 # Attractor type#
	# Atype <- ifelse(Pos==1 && Stab==1,1,0) # Stable point has Atype = 1#
	# Atype <- ifelse(Atype==0 && Osc==1,2,Atype ) # Limit cycle has Atype = 2#
# }#
#
#
#
#Calculate and plot Squeal Stats#
Xobs_daily <- apply(Xobs, 2, rollapply, width=DailySteps, mean, by=DailySteps)#
Time_daily <- rollapply(Time, width=DailySteps, mean, by=DailySteps)#
Kgrad_daily <- rollapply(Kgrad, width=DailySteps, mean, by=DailySteps)#
Stats_Xobs <- data.frame("Time"=rollapplyr(Time_daily, width=WinSize, max), "K"=rollapplyr(Kgrad_daily, width=WinSize, max), SquealStats(Xobs_daily, WinSize=WinSize))#
# Stats_Xobs <- data.frame("Time"=rollapplyr(Time, width=WinSize, max), SquealStats(Xobs, WinSize=WinSize))#
# head(Stats_Xobs); tail(Stats_Xobs)#
#
#next use ggplot and ddply to make a multi-panel graph in one step.  this is going to be sick when it works.#
#
K2index <- which(Stats_Xobs[,"K"] >= K2graph[1] & Stats_Xobs[,"K"] <= K2graph[2])#
PQZ <- c("P", "Q", "Z")#
Statters <- unique(Stats_Xobs[,"Stat"])#
dev.new(width=8, height=8)#
par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
for(i in seq_along(PQZ)){#
	i_Xobs <- Stats_Xobs[K2index,c("Time", "K", PQZ[i],"Stat")]#
	for(j in seq_along(Statters)){#
		j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
		if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
		plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
		Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
		if(i!=3){axis(side=1, labels=FALSE)}#
		if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
		if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
		if(i==1){mtext("K", side=3, line=2.5, font=3)}#
		if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
		if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
		if(i==1){#
			Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
		}#
		# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
		#
	}#
	#
}#
# axis(side=1, labels=TRUE, at=pretty(Kgrad), line=3)#
#
if(ForBac){#
	pYlim <- range(c(range(Xobs[,"P"]), range(revXobs[,"P"])))#
	qYlim <- range(c(range(Xobs[,"Q"]), range(revXobs[,"Q"])))#
	zYlim <- range(c(range(Xobs[,"Z"]), range(revXobs[,"Z"])))#
}else{#
	pYlim <- range(Xobs[,"P"])#
	qYlim <- range(Xobs[,"Q"])#
	zYlim <- range(Xobs[,"Z"])#
}#
#
#
dev.new(height=7, width=5)#
par(mfrow=c(3,1), mar=c(1,3,1,1), cex=1.25, oma=c(3,0,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"P"], lwd=2, col="green")}#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Q"], lwd=2, col="cyan")}#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Z"], lwd=2, col="magenta")}#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
if(ForBac){mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=3, cex=1.25)}else{mtext("K \n Dark = Increasing", side=1, line=3, cex=1.25)}#
#
#
# save.image("/Users/Battrd/Documents/School&Work/WiscResearch/BloomModel/Batt_Bloom_Seri08_v2_27Sept2012.RData")#
#
dev.new()#
par(mfrow=c(5,5), mar=c(2,2,0.5,0.5))#
for(i in c(trunc(seq(1,667,length.out=13)), trunc(seq(675,1000,length.out=12)))){#
	Color <- ifelse(round(KgradDaily[i],1)==8.3, "blue", "black")#
	plot(Burnt[,2,i], type="o", ylab="", xlab="", col=Color)#
}#
#
# plot(1:20000, Noise1[,2])#
#
# save.image("/Users/Battrd/Documents/School&Work/WiscResearch/BloomModel/Batt_Bloom_Seri08_v2_27Sept2012_longer.RData")
i
#
dev.new(height=7, width=5)#
par(mfrow=c(3,1), mar=c(1,3,1,1), cex=1.25, oma=c(3,0,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"P"], lwd=2, col="green")}#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Q"], lwd=2, col="cyan")}#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Z"], lwd=2, col="magenta")}#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
if(ForBac){mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=3, cex=1.25)}else{mtext("K \n Dark = Increasing", side=1, line=3, cex=1.25)}
dev.new(width=8, height=8)#
par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
for(i in seq_along(PQZ)){#
	i_Xobs <- Stats_Xobs[K2index,c("Time", "K", PQZ[i],"Stat")]#
	for(j in seq_along(Statters)){#
		j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
		if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
		plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
		Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
		if(i!=3){axis(side=1, labels=FALSE)}#
		if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
		if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
		if(i==1){mtext("K", side=3, line=2.5, font=3)}#
		if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
		if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
		if(i==1){#
			Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
		}#
		# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
		#
	}#
	#
}
Statters
rm(list=ls())#
graphics.off()#
library("zoo")#
library("ggplot2")#
#
# ====================#
# = Set some options =#
# ====================#
kQuse <- 0 #0.4 #0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
hQuse <- 0.5 #Handling time on colonial algae at kQ = 0, day#
Kstart <- 5#
Kstop <- 10#
K2graph <- c(5, 8.3)#
ForBac <- c(TRUE, FALSE)[2] #Plot state variables when K is increasing as well as when K is decreasing?  FALSE is just increasing.#
Days <- 1000 #Number of days over which to simulate#
DailySteps <- 20 #Number of steps per day (this is essentially dt)#
# DaysPerK <- 1 #"Days" has to be a multiple of DaysPerK. For each rate of carrying capacity (nutrient loading) (k), how many days should that rate be maintained (e.g., if 7, k will only change once per week)#
nBurn <- 10#
nBurnSave <- 1#
xNaught <- c(0.0065, 1.33, 1.4) #c(0.025, 1.75, 0.75) #c(0.01, 2.56, 1.9) #When k is increasing over the simulation, these are the starting values for unicell, colonial, and zoops (g/m^3)#
revxNaught <-  xNaught #c(0.8, 4.5, 0.25) #c(0.01, 3.4, 2) #When k is decreasing over the simulation, these are the starting values for unicell, colonial, and zoops (g/m^3)#
SigmaPQZ <- c(0.0001, 0.00256, 0.0019)*0.5  #c(0.000001, 0.000256, 0.00019) #
AddNoise <- c(TRUE, FALSE)[1] #Will be used as a coefficient in the noise simulations.  In multiplication, R interprets TRUE as 1, and FALSE as 0.#
AddKnoise <- c(TRUE, FALSE)[2]#
Ksd <- 0.25#
AddCata <- c(TRUE, FALSE)[2]#
CataAmp <- 100#
ProbCata <- 0.005#
nvec <- 5#
ExpStability <- c(TRUE, FALSE)[1]#
#
WinSize=100#
#
Kh <- (r/(r-mQ))*(1/vQ)*(((2*mZ)/(nu-mZ*hQuse))+(1/hQuse))#
#
# ================================================#
# = Main function to calculate dXdt at each step =#
# ================================================#
xRates <- function(x0, K, hQ=0.5, kQ=0.565, Exp=FALSE){#
	# ==============#
	# = Parameters =#
	# ==============#
	# K <- 5.0 #Carrying capacity, g/m^3#
	r <- 1.0 #Maximum growth rate of algae, day^-1#
	c <- 1.0 #scaling parameter for inducible effect, day^-1#
	g <- 0.1 #half-saturation constant for inducible effect, g/m^3#
	vP <- 0.5 #search rate on unicellular algae, m^2 g^-1 day^-1#
	hP <- 0.5 #handling time on unicellular algae, day#
	mP <- 0.2 #Mortality rate of unicellular algae, day^-1#
	vQ <- 0.5 #Search rate on colonial algae, m^3 g^-1 day^-1#
	# hQ <- 0.5 #Handling time on colonial algae at kQ = 0, day#
	# kQ <- 0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
	mQ <- 0.2 #Mortality rate of colonial algae, day^-1#
	nu <- 0.4 #assimilation coefficient on algae#
	mZ <- 0.2 #Mortality rate of zooplankton, day^-1 #Changing mortality to 0.15 under the conditions of Fig. 5 in Serizawa 2007 produces weird oscillations at K>4.71#
	# =========================#
	# = State variable values =#
	# =========================#
	if(Exp){#
		P <- exp(x0[1])#
		Q <- exp(x0[2])#
		Z <- exp(x0[3])#
	}else{#
		P <- x0[1]#
		Q <- x0[2]#
		Z <- x0[3]#
	}#
	# =========#
	# = Rates =#
	# =========#
	#First define convenient, repeatable parts to the equations#
	Logis <- r*(1 - (P+Q)/K)#
	PInduc <- P*(c*Z^2)/(Z^2+g^2)#
	QInduc <- Q*(c*g^2)/(Z^2+g^2)#
	ConsP <- vP*hP*P#
	ConsQ <- vQ*hQ*Q*(1+kQ*Q)#
	#Simulate each dimension#
	dPdt <- P*Logis - PInduc + QInduc - (vP*P*Z)/(1 + ConsP + ConsQ) - mP*P#
	dQdt <- Q*Logis + PInduc - QInduc - (vQ*Q*Z)/(1 + ConsP + ConsQ) - mQ*Q#
	dZdt <- (nu*(vP*P + vQ*Q)*Z)/(1 + ConsP + ConsQ) - mZ*Z#
	#Save dXdt's as a vector for P, Q, and Z#
	dXdt <- c(dPdt, dQdt, dZdt)#
	return(dXdt)#
}#
#
# ================================================#
# = Main function to calculate dXdt at each step =#
# ================================================#
xRates_jac <- function(t, x0, parms, K, hQ=0.5, kQ=0.565, Exp=FALSE){#
	# ==============#
	# = Parameters =#
	# ==============#
	# K <- 5.0 #Carrying capacity, g/m^3#
	r <- 1.0 #Maximum growth rate of algae, day^-1#
	c <- 1.0 #scaling parameter for inducible effect, day^-1#
	g <- 0.1 #half-saturation constant for inducible effect, g/m^3#
	vP <- 0.5 #search rate on unicellular algae, m^2 g^-1 day^-1#
	hP <- 0.5 #handling time on unicellular algae, day#
	mP <- 0.2 #Mortality rate of unicellular algae, day^-1#
	vQ <- 0.5 #Search rate on colonial algae, m^3 g^-1 day^-1#
	# hQ <- 0.5 #Handling time on colonial algae at kQ = 0, day#
	# kQ <- 0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
	mQ <- 0.2 #Mortality rate of colonial algae, day^-1#
	nu <- 0.4 #assimilation coefficient on algae#
	mZ <- 0.2 #Mortality rate of zooplankton, day^-1 #Changing mortality to 0.15 under the conditions of Fig. 5 in Serizawa 2007 produces weird oscillations at K>4.71#
	# =========================#
	# = State variable values =#
	# =========================#
	if(Exp){#
		P <- exp(x0[1])#
		Q <- exp(x0[2])#
		Z <- exp(x0[3])#
	}else{#
		P <- x0[1]#
		Q <- x0[2]#
		Z <- x0[3]#
	}#
	# =========#
	# = Rates =#
	# =========#
	#First define convenient, repeatable parts to the equations#
	Logis <- r*(1 - (P+Q)/K)#
	PInduc <- P*(c*Z^2)/(Z^2+g^2)#
	QInduc <- Q*(c*g^2)/(Z^2+g^2)#
	ConsP <- vP*hP*P#
	ConsQ <- vQ*hQ*Q*(1+kQ*Q)#
	#Simulate each dimension#
	dPdt <- P*Logis - PInduc + QInduc - (vP*P*Z)/(1 + ConsP + ConsQ) - mP*P#
	dQdt <- Q*Logis + PInduc - QInduc - (vQ*Q*Z)/(1 + ConsP + ConsQ) - mQ*Q#
	dZdt <- (nu*(vP*P + vQ*Q)*Z)/(1 + ConsP + ConsQ) - mZ*Z#
	#Save dXdt's as a vector for P, Q, and Z#
	dXdt <- c(dPdt, dQdt, dZdt)#
	return(dXdt)#
}#
#
Ar1 <-function(x){#
	# ac <- cor(x[-1],x[-length(x)])#
	ac <- ar.ols(x, order.max=1)$ar#
	# Nrmlzd <- x-mean(x)#
	# Y <- (x-mean(x))[-1]#
	# return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
	#return(arima(x, order=c(1,0,0))$coef[[1]])#
	return(ac)#
}#
#
Ar1 <-function(x){#
	ac <- cor(x[-1],x[-length(x)])#
	# Nrmlzd <- x-mean(x)#
	# Y <- (x-mean(x))[-1]#
	# return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
	#return(arima(x, order=c(1,0,0))$coef[[1]])#
	return(ac)#
}#
#
CH <- function(X){#
	nobs <- length(X)#
	Xt0 <- X[-c(1:4)]#
	Xt1 <- X[-c(1:3, nobs)]#
	Xt2 <- X[-c(1:2, (nobs-1):nobs)]#
	Xt3 <- X[-c(1, (nobs-2):nobs)]#
	Xt4 <- X[-c((nobs-3):nobs)]#
	ModelAR <- lm(Xt0~Xt1+Xt2+Xt3+Xt3+Xt4)#
	Res <- as.numeric(ModelAR$resid)#
	Res2 <- Res^2#
	Res2t0 <- Res2[-1]#
	Res2t1 <- Res2[-length(Res2)]#
	ModelCH <- lm(Res2t0~Res2t1)#
	R2 <- summary(ModelCH)$r.squared#
	# PosResult <- ifelse(Pvalue<=0.05,1,0)#
	return(R2)#
}#
#
SquealStats <- function(Data, WinSize){#
	StatNames <- c("Var", "AR1")#
	ReturnStats0 <- rbind(apply(Data, 2, rollapplyr, width=WinSize, var), apply(Data, 2, rollapplyr, width=WinSize, Ar1))#
	colnames(ReturnStats0) <- colnames(Data)#
	nstatsPer <- nrow(ReturnStats0)/length(StatNames)#
	ReturnStats1 <- data.frame(ReturnStats0, "Stat"=c(rep(StatNames[1],nstatsPer), rep(StatNames[2], nstatsPer)))#
	return(ReturnStats1)#
}#
# test <- SquealStats(Xobs, 5)#
# head(test)#
# tail(test)#
#
# SquealStats <- function(Data, WinSize){	#
	# ReturnStats <- data.frame("Var"=rollapplyr(Data, width=WinSize, FUN=var), "AR1"=rollapplyr(Data, width=WinSize, FUN=Ar1))#
	# return(ReturnStats)#
# }#
# , "CH"=rollapplyr(Data, width=WinSize, FUN=CH)#
#
#
# ===========================================================================================================#
# = Set up the simulation (given the options chosen at top of script, define duration, frequency, dt, etc.) =#
# ===========================================================================================================#
Nobs <- Days*DailySteps*nBurnSave #number of observations to be simulated#
Time <- seq(1,Days*nBurnSave+(1-1/DailySteps), by=1/DailySteps)#
dt <- 1/DailySteps #the size of the time step in units=days#
Kgrad <- rep(seq(Kstart, Kstop, length.out=Days), each=DailySteps*nBurnSave) #changes in carrying capacity for each Euler iteration, but K only changes between days, not within a day#
KgradDaily <- seq(Kstart, Kstop, length.out=Days)  #rep(seq(Kstart, Kstop, length.out=Days), each=nBurnSave) #changes in carrying capacity for each Euler iteration, but K only changes between days, not within a day#
Xobs <- matrix(data=NA, nrow=Nobs, ncol=3, dimnames=list(NULL,c("P","Q","Z"))) #To store the simulated state variables#
Xobs[1,] <- xNaught#
revXobs <- matrix(data=NA, nrow=Nobs, ncol=3, dimnames=list(NULL,c("P","Q","Z"))) #To store the simulated state variables#
revXobs[1,] <- revxNaught #Xobs[Nobs,] #Xobs[Nobs,]#*2#
#
# Noise <- matrix(rnorm(n=Nobs*3, mean=0, sd=0.001), nrow=Nobs, ncol=3)#
# AddNoise <- c(TRUE, FALSE)[2]#
#
# =====================================#
# = Simulate time series of P, Q, & Z =#
# =====================================#
Noise1 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]), rnorm(n=Nobs, sd=SigmaPQZ[2]), rnorm(n=Nobs, sd=SigmaPQZ[3])), ncol=3) * AddNoise#
Noise2 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]), rnorm(n=Nobs, sd=SigmaPQZ[2]), rnorm(n=Nobs, sd=SigmaPQZ[3])), ncol=3) * AddNoise#
#
KgradSim <- Kgrad + (rnorm(n=Nobs, sd=Ksd)*AddKnoise)#
# Knoise2 <- rnorm(n=Nobs, sd=Ksd)*AddKnoise#
#
CataNoise1 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[2]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[3]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata)), ncol=3) * AddCata#
CataNoise2 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[2]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[3]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata)), ncol=3) * AddCata#
#
#Simulate while increasing k#
# Burnt <- array(dim=c(nBurn*DailySteps, ncol(Xobs), Days*nBurnSave), dimnames=list("BurnIn"=seq_len(nBurn*DailySteps), "State"=c("P","Q","Z"), "K"=rep(round(seq(Kstart, Kstop, length.out=Days),3),nBurnSave)))#
Burnt <- array(dim=c(nBurn*DailySteps, ncol(Xobs), Days), dimnames=list("BurnIn"=seq_len(nBurn*DailySteps), "State"=c("P","Q","Z"), "K"=round(seq(Kstart, Kstop, length.out=Days),3)))#
# plot(seq_len(Days), round(seq(Kstart, Kstop, length.out=Days),3))#
#
Burnt[1,,1] <- xNaught#
Last <- xNaught#
# iCountRoot <- 1#
iCount <- 1#
for(d in 1:Days){#
	Know <- KgradDaily[d]#
	for(b in seq_len(nBurn)){#
		# if(b<=(nBurn-nBurnSave)){#
			# iCount <- iCountRoot #reset the iCount value to what it would be if there was no burn-in period#
		# }#
		for(delT in 1:DailySteps){#
			if(d==1&b==1&delT==1){#
				next#
			}#
			bCount <- (b-1)*DailySteps + delT#
			# iCount <- (d-1)*DailySteps + delT#
			Burnt[bCount,,d] <- xRates(x0=Last, K=Know, kQ=kQuse)*dt + Last + (Noise1[iCount,] + CataNoise1[iCount,])*sqrt(dt)#
			Last <- Burnt[bCount,,d]#
			if(b>=(nBurn-nBurnSave+1)){#
				Xobs[iCount,] <- Last #xRates(x0=Xobs[iCount-1,], K=Know, kQ=kQuse)*dt + Xobs[iCount-1,] + (Noise1[iCount,] + CataNoise1[iCount,])*sqrt(dt)#
				iCount <- iCount+1#
			}#
		}#
	}#
}#
#
#
if(ForBac){#
	#Simulate while decreasing k#
	for(i in 2:Nobs){#
		revXobs[i,] <- xRates(x0=revXobs[i-1,], K=KgradSim[Nobs-i], kQ=kQuse)*dt + revXobs[i-1,] + Noise2[i,]*sqrt(dt)#
	}#
}#
#
#
# qui <- function(x) ma#
#
#
#Stability analysis#
Pvec <- seq(0.001, 1, length.out=nvec)#
Qvec <- seq(2, 5, length.out=nvec)#
Zvec <- seq(0.001, 2, length.out=nvec)#
Kvec <- seq(5, 7, length.out=nvec)#
StabilityStarts0 <- as.matrix(expand.grid(list("Pvec"=Pvec, "Qvec"=Qvec, "Zvec"=Zvec, "Kvec"=Kvec)))#
if(ExpStability){StabilityStarts <- log(StabilityStarts0)}#
# for(i in seq_len(nvec)){#
	# Roots0 <- multiroot(xRates, start=StabilityStarts[i,1:3], K=StabilityStarts[i,4], Exp=ExpStability)$root#
	# if(ExpStability){Roots <- exp(Roots0)}else{Roots <- Roots0}#
	# names(Roots) <- NULL#
	# JacMat <- jacobian.full(Roots, xRates_jac, K=StabilityStarts[i,4])#
	# Lambda <- eigen(JacMat, only.values=TRUE)#
	#
	# Pos <- ifelse(Roots[1]>0 & Roots[2]>0 & Roots[3],1,0) # is it positive?#
	# Stab <- ifelse(Re(Lamda$values[1])<0 & Re(Lamda$values[2])<0 & Re(Lamda$values[3])<0,1,0) # is it stable?#
	#
	# if(Im(Lamda$values[1])==0#
	#
	# Osc <- ifelse(Im(Lamda$values[1])!=0,1,0) # does it oscillate?\#
	#
	# Alogic <- matrix(c(0,0,0, 1,1,1#
	#
	# Atype <- 0 # Attractor type#
	# Atype <- ifelse(Pos==1 && Stab==1,1,0) # Stable point has Atype = 1#
	# Atype <- ifelse(Atype==0 && Osc==1,2,Atype ) # Limit cycle has Atype = 2#
# }#
#
#
#
#Calculate and plot Squeal Stats#
Xobs_daily <- apply(Xobs, 2, rollapply, width=DailySteps, mean, by=DailySteps)#
Time_daily <- rollapply(Time, width=DailySteps, mean, by=DailySteps)#
Kgrad_daily <- rollapply(Kgrad, width=DailySteps, mean, by=DailySteps)#
Stats_Xobs <- data.frame("Time"=rollapplyr(Time_daily, width=WinSize, max), "K"=rollapplyr(Kgrad_daily, width=WinSize, max), SquealStats(Xobs_daily, WinSize=WinSize))#
# Stats_Xobs <- data.frame("Time"=rollapplyr(Time, width=WinSize, max), SquealStats(Xobs, WinSize=WinSize))#
# head(Stats_Xobs); tail(Stats_Xobs)#
#
#next use ggplot and ddply to make a multi-panel graph in one step.  this is going to be sick when it works.#
#
K2index <- which(Stats_Xobs[,"K"] >= K2graph[1] & Stats_Xobs[,"K"] <= K2graph[2])#
PQZ <- c("P", "Q", "Z")#
Statters <- unique(Stats_Xobs[,"Stat"])#
dev.new(width=8, height=8)#
par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
for(i in seq_along(PQZ)){#
	i_Xobs <- Stats_Xobs[K2index,c("Time", "K", PQZ[i],"Stat")]#
	for(j in seq_along(Statters)){#
		j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
		if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
		plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
		Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
		if(i!=3){axis(side=1, labels=FALSE)}#
		if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
		if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
		if(i==1){mtext("K", side=3, line=2.5, font=3)}#
		if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
		if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
		if(i==1){#
			Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
		}#
		# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
		#
	}#
	#
}#
# axis(side=1, labels=TRUE, at=pretty(Kgrad), line=3)#
#
if(ForBac){#
	pYlim <- range(c(range(Xobs[,"P"]), range(revXobs[,"P"])))#
	qYlim <- range(c(range(Xobs[,"Q"]), range(revXobs[,"Q"])))#
	zYlim <- range(c(range(Xobs[,"Z"]), range(revXobs[,"Z"])))#
}else{#
	pYlim <- range(Xobs[,"P"])#
	qYlim <- range(Xobs[,"Q"])#
	zYlim <- range(Xobs[,"Z"])#
}#
#
#
dev.new(height=7, width=5)#
par(mfrow=c(3,1), mar=c(1,3,1,1), cex=1.25, oma=c(3,0,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"P"], lwd=2, col="green")}#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Q"], lwd=2, col="cyan")}#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Z"], lwd=2, col="magenta")}#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
if(ForBac){mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=3, cex=1.25)}else{mtext("K \n Dark = Increasing", side=1, line=3, cex=1.25)}#
#
#
# save.image("/Users/Battrd/Documents/School&Work/WiscResearch/BloomModel/Batt_Bloom_Seri08_v2_27Sept2012.RData")#
#
dev.new()#
par(mfrow=c(5,5), mar=c(2,2,0.5,0.5))#
for(i in c(trunc(seq(1,667,length.out=13)), trunc(seq(675,1000,length.out=12)))){#
	Color <- ifelse(round(KgradDaily[i],1)==8.3, "blue", "black")#
	plot(Burnt[,2,i], type="o", ylab="", xlab="", col=Color)#
}#
#
# plot(1:20000, Noise1[,2])#
#
# save.image("/Users/Battrd/Documents/School&Work/WiscResearch/BloomModel/Batt_Bloom_Seri08_v2_27Sept2012_longer.RData")
ForBac
K2graph
for(i in 2:Nobs){#
		revXobs[i,] <- xRates(x0=revXobs[i-1,], K=KgradSim[Nobs-i], kQ=kQuse)*dt + revXobs[i-1,] + Noise2[i,]*sqrt(dt)#
	}
Kgrad
AddKnoise
Kgrad[length(Kgrad):1]
Xobs_daily_rev <- apply(revXobs, 2, rollapply, width=DailySteps, mean, by=DailySteps)
Time_daily_rev <- rollapply(Time, width=DailySteps, mean, by=DailySteps)
Kgrad_daily_rev <- rollapply(Kgrad[length(Kgrad):1], width=DailySteps, mean, by=DailySteps)
Stats_Xobs_rev <- data.frame("Time"=rollapplyr(Time_daily_rev, width=WinSize, max), "K"=rollapplyr(Kgrad_daily_rev, width=WinSize, max), SquealStats(Xobs_daily_rev, WinSize=WinSize))
Stats_Xobs_rev
Statters
pYlim <- range(c(range(Xobs[,"P"]), range(revXobs[,"P"])))#
	qYlim <- range(c(range(Xobs[,"Q"]), range(revXobs[,"Q"])))#
	zYlim <- range(c(range(Xobs[,"Z"]), range(revXobs[,"Z"])))
#
dev.new(height=7, width=5)#
par(mfrow=c(3,1), mar=c(1,3,1,1), cex=1.25, oma=c(3,0,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"P"], lwd=2, col="green")}#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Q"], lwd=2, col="cyan")}#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Z"], lwd=2, col="magenta")}#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
if(ForBac){mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=3, cex=1.25)}else{mtext("K \n Dark = Increasing", side=1, line=3, cex=1.25)}
ForBac
ForBac=TRUE
#
dev.new(height=7, width=5)#
par(mfrow=c(3,1), mar=c(1,3,1,1), cex=1.25, oma=c(3,0,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"P"], lwd=2, col="green")}#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Q"], lwd=2, col="cyan")}#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Z"], lwd=2, col="magenta")}#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
if(ForBac){mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=3, cex=1.25)}else{mtext("K \n Dark = Increasing", side=1, line=3, cex=1.25)}
K2graph
#
if(ForBac){#
	#
	#
	K2index <- which(Stats_Xobs_rev[,"K"] >= K2graph_rev[1] & Stats_Xobs_rev[,"K"] <= K2graph_rev[2])#
	PQZ <- c("P", "Q", "Z")#
	Statters <- unique(Stats_Xobs_rev[,"Stat"])#
	dev.new(width=8, height=8)#
	par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
	for(i in seq_along(PQZ)){#
		i_Xobs <- Stats_Xobs_rev[K2index,c("Time", "K", PQZ[i],"Stat")]#
		for(j in seq_along(Statters)){#
			j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
			if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
			plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
			Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
			if(i!=3){axis(side=1, labels=FALSE)}#
			if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
			if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
			if(i==1){mtext("K", side=3, line=2.5, font=3)}#
			if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
			if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
			if(i==1){#
				Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
			}#
			# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
#
		}#
#
	}#
	#
}
K2graph_rev <- c(6, 10)
#
if(ForBac){#
	#
	#
	K2index <- which(Stats_Xobs_rev[,"K"] >= K2graph_rev[1] & Stats_Xobs_rev[,"K"] <= K2graph_rev[2])#
	PQZ <- c("P", "Q", "Z")#
	Statters <- unique(Stats_Xobs_rev[,"Stat"])#
	dev.new(width=8, height=8)#
	par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
	for(i in seq_along(PQZ)){#
		i_Xobs <- Stats_Xobs_rev[K2index,c("Time", "K", PQZ[i],"Stat")]#
		for(j in seq_along(Statters)){#
			j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
			if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
			plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
			Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
			if(i!=3){axis(side=1, labels=FALSE)}#
			if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
			if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
			if(i==1){mtext("K", side=3, line=2.5, font=3)}#
			if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
			if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
			if(i==1){#
				Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
			}#
			# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
#
		}#
#
	}#
	#
}
head(j_Xobs)
Kaxis
j_Xobs[,"Time"]
j_Xobs[,"K"]
Kaxis
#
if(ForBac){#
	#
	#
	K2index <- which(Stats_Xobs_rev[,"K"] >= K2graph_rev[1] & Stats_Xobs_rev[,"K"] <= K2graph_rev[2])#
	PQZ <- c("P", "Q", "Z")#
	Statters <- unique(Stats_Xobs_rev[,"Stat"])#
	dev.new(width=8, height=8)#
	par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
	for(i in seq_along(PQZ)){#
		i_Xobs <- Stats_Xobs_rev[K2index,c("Time", "K", PQZ[i],"Stat")]#
		for(j in seq_along(Statters)){#
			j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
			if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
			plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
			Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
			if(i!=3){axis(side=1, labels=FALSE)}#
			if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
			if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
			if(i==1){mtext("K", side=3, line=2.5, font=3)}#
			if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
			if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
			# if(i==1){#
			# 	Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
			# }#
			# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
#
		}#
#
	}#
	#
}
#
if(ForBac){#
	#
	#
	K2index <- which(Stats_Xobs_rev[,"K"] >= K2graph_rev[1] & Stats_Xobs_rev[,"K"] <= K2graph_rev[2])#
	PQZ <- c("P", "Q", "Z")#
	Statters <- unique(Stats_Xobs_rev[,"Stat"])#
	dev.new(width=8, height=8)#
	par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
	for(i in seq_along(PQZ)){#
		i_Xobs <- Stats_Xobs_rev[K2index,c("Time", "K", PQZ[i],"Stat")]#
		for(j in seq_along(Statters)){#
			j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
			if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
			plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
			Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
			if(i!=3){axis(side=1, labels=FALSE)}#
			if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
			if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
			if(i==1){mtext("K", side=3, line=2.5, font=3)}#
			if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
			if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
			if(i==1){#
				Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
			}#
			# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
#
		}#
#
	}#
	#
}
seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6)
round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2)
#
if(ForBac){#
	#
	#
	K2index <- which(Stats_Xobs_rev[,"K"] >= K2graph_rev[1] & Stats_Xobs_rev[,"K"] <= K2graph_rev[2])#
	PQZ <- c("P", "Q", "Z")#
	Statters <- unique(Stats_Xobs_rev[,"Stat"])#
	dev.new(width=8, height=8)#
	par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
	for(i in seq_along(PQZ)){#
		i_Xobs <- Stats_Xobs_rev[K2index,c("Time", "K", PQZ[i],"Stat")]#
		for(j in seq_along(Statters)){#
			j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
			if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
			plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
			Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
			if(i!=3){axis(side=1, labels=FALSE)}#
			if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
			if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
			if(i==1){mtext("K", side=3, line=2.5, font=3)}#
			if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
			if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
			if(i==1){#
				Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(max(j_Xobs[,"K"]), min(j_Xobs[,"K"]), length.out=6),2))#
			}#
			# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
#
		}#
#
	}#
	#
}
range(rev(Kgrad))[c(2,1)])
range(rev(Kgrad))[c(2,1)]
#
# ==================================================================================#
# = Basically same plot as above, but in separate panels for fowards and backwards =#
# ==================================================================================#
dev.new(height=7, width=5)#
par(mfrow=c(3,2), mar=c(1,3,1,1), cex=1.25, oma=c(3,0,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=0, cex=1.25, outer=TRUE)
dev.new(height=7, width=5)#
par(mfrow=c(3,2), mar=c(1,2,1,1), cex=1.25, oma=c(3,1,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=2, cex=1.25, outer=TRUE)
dev.new(height=7, width=5)#
par(mfrow=c(3,2), mar=c(1,2,1,1), cex=1.25, oma=c(3,1,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=c(1,2), labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=2, cex=1.25, outer=TRUE)
#
#
# ==================================================================================#
# = Basically same plot as above, but in separate panels for fowards and backwards =#
# ==================================================================================#
dev.new(height=7, width=5)#
par(mfrow=c(3,2), mar=c(1,2,1,1), cex=1.25, oma=c(3,1,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=c(1,2), labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=2, cex=1.25, outer=TRUE)
dev.new(height=7, width=5)#
par(mfrow=c(3,2), mar=c(1,2,1,1), cex=1.25, oma=c(3,1,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
axis(side=2, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=2, cex=1.25, outer=TRUE)
#
# ==================================================================================#
# = Basically same plot as above, but in separate panels for fowards and backwards =#
# ==================================================================================#
dev.new(height=7, width=5)#
par(mfrow=c(3,2), mar=c(1,2,1,1), cex=1.25, oma=c(3,1,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
axis(side=2, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
axis(side=2, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", yaxt="n" lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=2, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=2, cex=1.25, outer=TRUE)
#
# ==================================================================================#
# = Basically same plot as above, but in separate panels for fowards and backwards =#
# ==================================================================================#
dev.new(height=7, width=5)#
par(mfrow=c(3,2), mar=c(1,1,1,1), cex=1.25, oma=c(3,2,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
axis(side=2, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=1, labels=FALSE)#
axis(side=2, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", yaxt="n", lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
axis(side=2, labels=FALSE)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=2, cex=1.25, outer=TRUE)
K2graph_rev
K2graph
rm(list=ls())#
graphics.off()#
library("zoo")#
library("ggplot2")#
#
# ====================#
# = Set some options =#
# ====================#
kQuse <- 0 #0.4 #0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
hQuse <- 0.5 #Handling time on colonial algae at kQ = 0, day#
Kstart <- 5#
Kstop <- 10#
K2graph <- c(5, 8.3)#
K2graph_rev <- c(6, 10)#
ForBac <- c(TRUE, FALSE)[2] #Plot state variables when K is increasing as well as when K is decreasing?  FALSE is just increasing.#
Days <- 1000 #Number of days over which to simulate#
DailySteps <- 20 #Number of steps per day (this is essentially dt)#
# DaysPerK <- 1 #"Days" has to be a multiple of DaysPerK. For each rate of carrying capacity (nutrient loading) (k), how many days should that rate be maintained (e.g., if 7, k will only change once per week)#
nBurn <- 10#
nBurnSave <- 1#
xNaught <- c(0.0065, 1.33, 1.4) #c(0.025, 1.75, 0.75) #c(0.01, 2.56, 1.9) #When k is increasing over the simulation, these are the starting values for unicell, colonial, and zoops (g/m^3)#
revxNaught <-  xNaught #c(0.8, 4.5, 0.25) #c(0.01, 3.4, 2) #When k is decreasing over the simulation, these are the starting values for unicell, colonial, and zoops (g/m^3)#
SigmaPQZ <- c(0.0001, 0.00256, 0.0019)*0.05  #c(0.000001, 0.000256, 0.00019) #
AddNoise <- c(TRUE, FALSE)[1] #Will be used as a coefficient in the noise simulations.  In multiplication, R interprets TRUE as 1, and FALSE as 0.#
AddKnoise <- c(TRUE, FALSE)[2]#
Ksd <- 0.25#
AddCata <- c(TRUE, FALSE)[2]#
CataAmp <- 100#
ProbCata <- 0.005#
nvec <- 5#
ExpStability <- c(TRUE, FALSE)[1]#
#
WinSize=100#
#
Kh <- (r/(r-mQ))*(1/vQ)*(((2*mZ)/(nu-mZ*hQuse))+(1/hQuse))#
#
# ================================================#
# = Main function to calculate dXdt at each step =#
# ================================================#
xRates <- function(x0, K, hQ=0.5, kQ=0.565, Exp=FALSE){#
	# ==============#
	# = Parameters =#
	# ==============#
	# K <- 5.0 #Carrying capacity, g/m^3#
	r <- 1.0 #Maximum growth rate of algae, day^-1#
	c <- 1.0 #scaling parameter for inducible effect, day^-1#
	g <- 0.1 #half-saturation constant for inducible effect, g/m^3#
	vP <- 0.5 #search rate on unicellular algae, m^2 g^-1 day^-1#
	hP <- 0.5 #handling time on unicellular algae, day#
	mP <- 0.2 #Mortality rate of unicellular algae, day^-1#
	vQ <- 0.5 #Search rate on colonial algae, m^3 g^-1 day^-1#
	# hQ <- 0.5 #Handling time on colonial algae at kQ = 0, day#
	# kQ <- 0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
	mQ <- 0.2 #Mortality rate of colonial algae, day^-1#
	nu <- 0.4 #assimilation coefficient on algae#
	mZ <- 0.2 #Mortality rate of zooplankton, day^-1 #Changing mortality to 0.15 under the conditions of Fig. 5 in Serizawa 2007 produces weird oscillations at K>4.71#
	# =========================#
	# = State variable values =#
	# =========================#
	if(Exp){#
		P <- exp(x0[1])#
		Q <- exp(x0[2])#
		Z <- exp(x0[3])#
	}else{#
		P <- x0[1]#
		Q <- x0[2]#
		Z <- x0[3]#
	}#
	# =========#
	# = Rates =#
	# =========#
	#First define convenient, repeatable parts to the equations#
	Logis <- r*(1 - (P+Q)/K)#
	PInduc <- P*(c*Z^2)/(Z^2+g^2)#
	QInduc <- Q*(c*g^2)/(Z^2+g^2)#
	ConsP <- vP*hP*P#
	ConsQ <- vQ*hQ*Q*(1+kQ*Q)#
	#Simulate each dimension#
	dPdt <- P*Logis - PInduc + QInduc - (vP*P*Z)/(1 + ConsP + ConsQ) - mP*P#
	dQdt <- Q*Logis + PInduc - QInduc - (vQ*Q*Z)/(1 + ConsP + ConsQ) - mQ*Q#
	dZdt <- (nu*(vP*P + vQ*Q)*Z)/(1 + ConsP + ConsQ) - mZ*Z#
	#Save dXdt's as a vector for P, Q, and Z#
	dXdt <- c(dPdt, dQdt, dZdt)#
	return(dXdt)#
}#
#
# ================================================#
# = Main function to calculate dXdt at each step =#
# ================================================#
xRates_jac <- function(t, x0, parms, K, hQ=0.5, kQ=0.565, Exp=FALSE){#
	# ==============#
	# = Parameters =#
	# ==============#
	# K <- 5.0 #Carrying capacity, g/m^3#
	r <- 1.0 #Maximum growth rate of algae, day^-1#
	c <- 1.0 #scaling parameter for inducible effect, day^-1#
	g <- 0.1 #half-saturation constant for inducible effect, g/m^3#
	vP <- 0.5 #search rate on unicellular algae, m^2 g^-1 day^-1#
	hP <- 0.5 #handling time on unicellular algae, day#
	mP <- 0.2 #Mortality rate of unicellular algae, day^-1#
	vQ <- 0.5 #Search rate on colonial algae, m^3 g^-1 day^-1#
	# hQ <- 0.5 #Handling time on colonial algae at kQ = 0, day#
	# kQ <- 0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
	mQ <- 0.2 #Mortality rate of colonial algae, day^-1#
	nu <- 0.4 #assimilation coefficient on algae#
	mZ <- 0.2 #Mortality rate of zooplankton, day^-1 #Changing mortality to 0.15 under the conditions of Fig. 5 in Serizawa 2007 produces weird oscillations at K>4.71#
	# =========================#
	# = State variable values =#
	# =========================#
	if(Exp){#
		P <- exp(x0[1])#
		Q <- exp(x0[2])#
		Z <- exp(x0[3])#
	}else{#
		P <- x0[1]#
		Q <- x0[2]#
		Z <- x0[3]#
	}#
	# =========#
	# = Rates =#
	# =========#
	#First define convenient, repeatable parts to the equations#
	Logis <- r*(1 - (P+Q)/K)#
	PInduc <- P*(c*Z^2)/(Z^2+g^2)#
	QInduc <- Q*(c*g^2)/(Z^2+g^2)#
	ConsP <- vP*hP*P#
	ConsQ <- vQ*hQ*Q*(1+kQ*Q)#
	#Simulate each dimension#
	dPdt <- P*Logis - PInduc + QInduc - (vP*P*Z)/(1 + ConsP + ConsQ) - mP*P#
	dQdt <- Q*Logis + PInduc - QInduc - (vQ*Q*Z)/(1 + ConsP + ConsQ) - mQ*Q#
	dZdt <- (nu*(vP*P + vQ*Q)*Z)/(1 + ConsP + ConsQ) - mZ*Z#
	#Save dXdt's as a vector for P, Q, and Z#
	dXdt <- c(dPdt, dQdt, dZdt)#
	return(dXdt)#
}#
#
Ar1 <-function(x){#
	# ac <- cor(x[-1],x[-length(x)])#
	ac <- ar.ols(x, order.max=1)$ar#
	# Nrmlzd <- x-mean(x)#
	# Y <- (x-mean(x))[-1]#
	# return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
	#return(arima(x, order=c(1,0,0))$coef[[1]])#
	return(ac)#
}#
#
Ar1 <-function(x){#
	ac <- cor(x[-1],x[-length(x)])#
	# Nrmlzd <- x-mean(x)#
	# Y <- (x-mean(x))[-1]#
	# return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
	#return(arima(x, order=c(1,0,0))$coef[[1]])#
	return(ac)#
}#
#
CH <- function(X){#
	nobs <- length(X)#
	Xt0 <- X[-c(1:4)]#
	Xt1 <- X[-c(1:3, nobs)]#
	Xt2 <- X[-c(1:2, (nobs-1):nobs)]#
	Xt3 <- X[-c(1, (nobs-2):nobs)]#
	Xt4 <- X[-c((nobs-3):nobs)]#
	ModelAR <- lm(Xt0~Xt1+Xt2+Xt3+Xt3+Xt4)#
	Res <- as.numeric(ModelAR$resid)#
	Res2 <- Res^2#
	Res2t0 <- Res2[-1]#
	Res2t1 <- Res2[-length(Res2)]#
	ModelCH <- lm(Res2t0~Res2t1)#
	R2 <- summary(ModelCH)$r.squared#
	# PosResult <- ifelse(Pvalue<=0.05,1,0)#
	return(R2)#
}#
#
SquealStats <- function(Data, WinSize){#
	StatNames <- c("Var", "AR1")#
	ReturnStats0 <- rbind(apply(Data, 2, rollapplyr, width=WinSize, var), apply(Data, 2, rollapplyr, width=WinSize, Ar1))#
	colnames(ReturnStats0) <- colnames(Data)#
	nstatsPer <- nrow(ReturnStats0)/length(StatNames)#
	ReturnStats1 <- data.frame(ReturnStats0, "Stat"=c(rep(StatNames[1],nstatsPer), rep(StatNames[2], nstatsPer)))#
	return(ReturnStats1)#
}#
# test <- SquealStats(Xobs, 5)#
# head(test)#
# tail(test)#
#
# SquealStats <- function(Data, WinSize){	#
	# ReturnStats <- data.frame("Var"=rollapplyr(Data, width=WinSize, FUN=var), "AR1"=rollapplyr(Data, width=WinSize, FUN=Ar1))#
	# return(ReturnStats)#
# }#
# , "CH"=rollapplyr(Data, width=WinSize, FUN=CH)#
#
#
# ===========================================================================================================#
# = Set up the simulation (given the options chosen at top of script, define duration, frequency, dt, etc.) =#
# ===========================================================================================================#
Nobs <- Days*DailySteps*nBurnSave #number of observations to be simulated#
Time <- seq(1,Days*nBurnSave+(1-1/DailySteps), by=1/DailySteps)#
dt <- 1/DailySteps #the size of the time step in units=days#
Kgrad <- rep(seq(Kstart, Kstop, length.out=Days), each=DailySteps*nBurnSave) #changes in carrying capacity for each Euler iteration, but K only changes between days, not within a day#
KgradDaily <- seq(Kstart, Kstop, length.out=Days)  #rep(seq(Kstart, Kstop, length.out=Days), each=nBurnSave) #changes in carrying capacity for each Euler iteration, but K only changes between days, not within a day#
Xobs <- matrix(data=NA, nrow=Nobs, ncol=3, dimnames=list(NULL,c("P","Q","Z"))) #To store the simulated state variables#
Xobs[1,] <- xNaught#
revXobs <- matrix(data=NA, nrow=Nobs, ncol=3, dimnames=list(NULL,c("P","Q","Z"))) #To store the simulated state variables#
revXobs[1,] <- revxNaught #Xobs[Nobs,] #Xobs[Nobs,]#*2#
#
# Noise <- matrix(rnorm(n=Nobs*3, mean=0, sd=0.001), nrow=Nobs, ncol=3)#
# AddNoise <- c(TRUE, FALSE)[2]#
#
# =====================================#
# = Simulate time series of P, Q, & Z =#
# =====================================#
Noise1 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]), rnorm(n=Nobs, sd=SigmaPQZ[2]), rnorm(n=Nobs, sd=SigmaPQZ[3])), ncol=3) * AddNoise#
Noise2 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]), rnorm(n=Nobs, sd=SigmaPQZ[2]), rnorm(n=Nobs, sd=SigmaPQZ[3])), ncol=3) * AddNoise#
#
KgradSim <- Kgrad + (rnorm(n=Nobs, sd=Ksd)*AddKnoise)#
# Knoise2 <- rnorm(n=Nobs, sd=Ksd)*AddKnoise#
#
CataNoise1 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[2]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[3]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata)), ncol=3) * AddCata#
CataNoise2 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[2]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[3]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata)), ncol=3) * AddCata#
#
#Simulate while increasing k#
# Burnt <- array(dim=c(nBurn*DailySteps, ncol(Xobs), Days*nBurnSave), dimnames=list("BurnIn"=seq_len(nBurn*DailySteps), "State"=c("P","Q","Z"), "K"=rep(round(seq(Kstart, Kstop, length.out=Days),3),nBurnSave)))#
Burnt <- array(dim=c(nBurn*DailySteps, ncol(Xobs), Days), dimnames=list("BurnIn"=seq_len(nBurn*DailySteps), "State"=c("P","Q","Z"), "K"=round(seq(Kstart, Kstop, length.out=Days),3)))#
# plot(seq_len(Days), round(seq(Kstart, Kstop, length.out=Days),3))#
#
Burnt[1,,1] <- xNaught#
Last <- xNaught#
# iCountRoot <- 1#
iCount <- 1#
for(d in 1:Days){#
	Know <- KgradDaily[d]#
	for(b in seq_len(nBurn)){#
		# if(b<=(nBurn-nBurnSave)){#
			# iCount <- iCountRoot #reset the iCount value to what it would be if there was no burn-in period#
		# }#
		for(delT in 1:DailySteps){#
			if(d==1&b==1&delT==1){#
				next#
			}#
			bCount <- (b-1)*DailySteps + delT#
			# iCount <- (d-1)*DailySteps + delT#
			Burnt[bCount,,d] <- xRates(x0=Last, K=Know, kQ=kQuse)*dt + Last + (Noise1[iCount,] + CataNoise1[iCount,])*sqrt(dt)#
			Last <- Burnt[bCount,,d]#
			if(b>=(nBurn-nBurnSave+1)){#
				Xobs[iCount,] <- Last #xRates(x0=Xobs[iCount-1,], K=Know, kQ=kQuse)*dt + Xobs[iCount-1,] + (Noise1[iCount,] + CataNoise1[iCount,])*sqrt(dt)#
				iCount <- iCount+1#
			}#
		}#
	}#
}#
#
#
if(ForBac){#
	#Simulate while decreasing k#
	for(i in 2:Nobs){#
		revXobs[i,] <- xRates(x0=revXobs[i-1,], K=KgradSim[Nobs-i], kQ=kQuse)*dt + revXobs[i-1,] + Noise2[i,]*sqrt(dt)#
	}#
}#
#
#
# qui <- function(x) ma#
#
#
#Stability analysis#
Pvec <- seq(0.001, 1, length.out=nvec)#
Qvec <- seq(2, 5, length.out=nvec)#
Zvec <- seq(0.001, 2, length.out=nvec)#
Kvec <- seq(5, 7, length.out=nvec)#
StabilityStarts0 <- as.matrix(expand.grid(list("Pvec"=Pvec, "Qvec"=Qvec, "Zvec"=Zvec, "Kvec"=Kvec)))#
if(ExpStability){StabilityStarts <- log(StabilityStarts0)}#
# for(i in seq_len(nvec)){#
	# Roots0 <- multiroot(xRates, start=StabilityStarts[i,1:3], K=StabilityStarts[i,4], Exp=ExpStability)$root#
	# if(ExpStability){Roots <- exp(Roots0)}else{Roots <- Roots0}#
	# names(Roots) <- NULL#
	# JacMat <- jacobian.full(Roots, xRates_jac, K=StabilityStarts[i,4])#
	# Lambda <- eigen(JacMat, only.values=TRUE)#
	#
	# Pos <- ifelse(Roots[1]>0 & Roots[2]>0 & Roots[3],1,0) # is it positive?#
	# Stab <- ifelse(Re(Lamda$values[1])<0 & Re(Lamda$values[2])<0 & Re(Lamda$values[3])<0,1,0) # is it stable?#
	#
	# if(Im(Lamda$values[1])==0#
	#
	# Osc <- ifelse(Im(Lamda$values[1])!=0,1,0) # does it oscillate?\#
	#
	# Alogic <- matrix(c(0,0,0, 1,1,1#
	#
	# Atype <- 0 # Attractor type#
	# Atype <- ifelse(Pos==1 && Stab==1,1,0) # Stable point has Atype = 1#
	# Atype <- ifelse(Atype==0 && Osc==1,2,Atype ) # Limit cycle has Atype = 2#
# }#
#
#
#
#Calculate and plot Squeal Stats#
Xobs_daily <- apply(Xobs, 2, rollapply, width=DailySteps, mean, by=DailySteps)#
Time_daily <- rollapply(Time, width=DailySteps, mean, by=DailySteps)#
Kgrad_daily <- rollapply(Kgrad, width=DailySteps, mean, by=DailySteps)#
Stats_Xobs <- data.frame("Time"=rollapplyr(Time_daily, width=WinSize, max), "K"=rollapplyr(Kgrad_daily, width=WinSize, max), SquealStats(Xobs_daily, WinSize=WinSize))#
# Stats_Xobs <- data.frame("Time"=rollapplyr(Time, width=WinSize, max), SquealStats(Xobs, WinSize=WinSize))#
# head(Stats_Xobs); tail(Stats_Xobs)#
#
Xobs_daily_rev <- apply(revXobs, 2, rollapply, width=DailySteps, mean, by=DailySteps)#
Time_daily_rev <- rollapply(Time, width=DailySteps, mean, by=DailySteps)#
Kgrad_daily_rev <- rollapply(Kgrad[length(Kgrad):1], width=DailySteps, mean, by=DailySteps)#
Stats_Xobs_rev <- data.frame("Time"=rollapplyr(Time_daily_rev, width=WinSize, max), "K"=rollapplyr(Kgrad_daily_rev, width=WinSize, max), SquealStats(Xobs_daily_rev, WinSize=WinSize))#
#
#next use ggplot and ddply to make a multi-panel graph in one step.  this is going to be sick when it works.#
#
K2index <- which(Stats_Xobs[,"K"] >= K2graph[1] & Stats_Xobs[,"K"] <= K2graph[2])#
PQZ <- c("P", "Q", "Z")#
Statters <- unique(Stats_Xobs[,"Stat"])#
dev.new(width=8, height=8)#
par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
for(i in seq_along(PQZ)){#
	i_Xobs <- Stats_Xobs[K2index,c("Time", "K", PQZ[i],"Stat")]#
	for(j in seq_along(Statters)){#
		j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
		if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
		plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
		Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
		if(i!=3){axis(side=1, labels=FALSE)}#
		if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
		if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
		if(i==1){mtext("K", side=3, line=2.5, font=3)}#
		if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
		if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
		if(i==1){#
			Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
		}#
		# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
		#
	}#
	#
}#
#
#
if(ForBac){#
	#
	#
	K2index <- which(Stats_Xobs_rev[,"K"] >= K2graph_rev[1] & Stats_Xobs_rev[,"K"] <= K2graph_rev[2])#
	PQZ <- c("P", "Q", "Z")#
	Statters <- unique(Stats_Xobs_rev[,"Stat"])#
	dev.new(width=8, height=8)#
	par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
	for(i in seq_along(PQZ)){#
		i_Xobs <- Stats_Xobs_rev[K2index,c("Time", "K", PQZ[i],"Stat")]#
		for(j in seq_along(Statters)){#
			j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
			if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
			plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
			Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
			if(i!=3){axis(side=1, labels=FALSE)}#
			if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
			if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
			if(i==1){mtext("K", side=3, line=2.5, font=3)}#
			if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
			if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
			if(i==1){#
				Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(max(j_Xobs[,"K"]), min(j_Xobs[,"K"]), length.out=6),2))#
			}#
			# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
#
		}#
#
	}#
	#
}#
#
#
#
# axis(side=1, labels=TRUE, at=pretty(Kgrad), line=3)#
#
if(ForBac){#
	pYlim <- range(c(range(Xobs[,"P"]), range(revXobs[,"P"])))#
	qYlim <- range(c(range(Xobs[,"Q"]), range(revXobs[,"Q"])))#
	zYlim <- range(c(range(Xobs[,"Z"]), range(revXobs[,"Z"])))#
}else{#
	pYlim <- range(Xobs[,"P"])#
	qYlim <- range(Xobs[,"Q"])#
	zYlim <- range(Xobs[,"Z"])#
}#
#
#
dev.new(height=7, width=5)#
par(mfrow=c(3,1), mar=c(1,3,1,1), cex=1.25, oma=c(3,0,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"P"], lwd=2, col="green")}#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Q"], lwd=2, col="cyan")}#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Z"], lwd=2, col="magenta")}#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
if(ForBac){mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=3, cex=1.25)}else{mtext("K \n Dark = Increasing", side=1, line=3, cex=1.25)}#
#
#
#
# ==================================================================================#
# = Basically same plot as above, but in separate panels for fowards and backwards =#
# ==================================================================================#
if(ForBac){#
	dev.new(height=7, width=5)#
	par(mfrow=c(3,2), mar=c(1,1,1,1), cex=1.25, oma=c(3,2,0,0))#
#
	plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
	axis(side=1, labels=FALSE)#
	mtext("Unicell", side=2, line=2, cex=1.25)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
	plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
	axis(side=1, labels=FALSE)#
	axis(side=2, labels=FALSE)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
	plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
	axis(side=1, labels=FALSE)#
	mtext("Colonial", side=2, line=2, cex=1.25)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
	plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
	axis(side=1, labels=FALSE)#
	axis(side=2, labels=FALSE)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
	plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
	mtext("Zooplankton", side=2, line=2, cex=1.25)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
	plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", yaxt="n", lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
	axis(side=2, labels=FALSE)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
	mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=2, cex=1.25, outer=TRUE)#
}#
#
#
# save.image("/Users/Battrd/Documents/School&Work/WiscResearch/BloomModel/Batt_Bloom_Seri08_v2_27Sept2012.RData")#
#
dev.new()#
par(mfrow=c(5,5), mar=c(2,2,0.5,0.5))#
for(i in c(trunc(seq(1,667,length.out=13)), trunc(seq(675,1000,length.out=12)))){#
	Color <- ifelse(round(KgradDaily[i],1)==8.3, "blue", "black")#
	plot(Burnt[,2,i], type="o", ylab="", xlab="", col=Color)#
}#
#
# plot(1:20000, Noise1[,2])#
#
# save.image("/Users/Battrd/Documents/School&Work/WiscResearch/BloomModel/Batt_Bloom_Seri08_v2_27Sept2012_longer.RData")
rm(list=ls())#
graphics.off()#
library("zoo")#
library("ggplot2")#
#
# ====================#
# = Set some options =#
# ====================#
kQuse <- 0 #0.4 #0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
hQuse <- 0.5 #Handling time on colonial algae at kQ = 0, day#
Kstart <- 5#
Kstop <- 10#
K2graph <- c(5, 8.3)#
K2graph_rev <- c(6, 10)#
ForBac <- c(TRUE, FALSE)[1] #Plot state variables when K is increasing as well as when K is decreasing?  FALSE is just increasing.#
Days <- 1000 #Number of days over which to simulate#
DailySteps <- 20 #Number of steps per day (this is essentially dt)#
# DaysPerK <- 1 #"Days" has to be a multiple of DaysPerK. For each rate of carrying capacity (nutrient loading) (k), how many days should that rate be maintained (e.g., if 7, k will only change once per week)#
nBurn <- 100#
nBurnSave <- 1#
xNaught <- c(0.0065, 1.33, 1.4) #c(0.025, 1.75, 0.75) #c(0.01, 2.56, 1.9) #When k is increasing over the simulation, these are the starting values for unicell, colonial, and zoops (g/m^3)#
revxNaught <-  xNaught #c(0.8, 4.5, 0.25) #c(0.01, 3.4, 2) #When k is decreasing over the simulation, these are the starting values for unicell, colonial, and zoops (g/m^3)#
SigmaPQZ <- c(0.0001, 0.00256, 0.0019)*0.05  #c(0.000001, 0.000256, 0.00019) #
AddNoise <- c(TRUE, FALSE)[1] #Will be used as a coefficient in the noise simulations.  In multiplication, R interprets TRUE as 1, and FALSE as 0.#
AddKnoise <- c(TRUE, FALSE)[2]#
Ksd <- 0.25#
AddCata <- c(TRUE, FALSE)[2]#
CataAmp <- 100#
ProbCata <- 0.005#
nvec <- 5#
ExpStability <- c(TRUE, FALSE)[1]#
#
WinSize=100#
#
Kh <- (r/(r-mQ))*(1/vQ)*(((2*mZ)/(nu-mZ*hQuse))+(1/hQuse))#
#
# ================================================#
# = Main function to calculate dXdt at each step =#
# ================================================#
xRates <- function(x0, K, hQ=0.5, kQ=0.565, Exp=FALSE){#
	# ==============#
	# = Parameters =#
	# ==============#
	# K <- 5.0 #Carrying capacity, g/m^3#
	r <- 1.0 #Maximum growth rate of algae, day^-1#
	c <- 1.0 #scaling parameter for inducible effect, day^-1#
	g <- 0.1 #half-saturation constant for inducible effect, g/m^3#
	vP <- 0.5 #search rate on unicellular algae, m^2 g^-1 day^-1#
	hP <- 0.5 #handling time on unicellular algae, day#
	mP <- 0.2 #Mortality rate of unicellular algae, day^-1#
	vQ <- 0.5 #Search rate on colonial algae, m^3 g^-1 day^-1#
	# hQ <- 0.5 #Handling time on colonial algae at kQ = 0, day#
	# kQ <- 0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
	mQ <- 0.2 #Mortality rate of colonial algae, day^-1#
	nu <- 0.4 #assimilation coefficient on algae#
	mZ <- 0.2 #Mortality rate of zooplankton, day^-1 #Changing mortality to 0.15 under the conditions of Fig. 5 in Serizawa 2007 produces weird oscillations at K>4.71#
	# =========================#
	# = State variable values =#
	# =========================#
	if(Exp){#
		P <- exp(x0[1])#
		Q <- exp(x0[2])#
		Z <- exp(x0[3])#
	}else{#
		P <- x0[1]#
		Q <- x0[2]#
		Z <- x0[3]#
	}#
	# =========#
	# = Rates =#
	# =========#
	#First define convenient, repeatable parts to the equations#
	Logis <- r*(1 - (P+Q)/K)#
	PInduc <- P*(c*Z^2)/(Z^2+g^2)#
	QInduc <- Q*(c*g^2)/(Z^2+g^2)#
	ConsP <- vP*hP*P#
	ConsQ <- vQ*hQ*Q*(1+kQ*Q)#
	#Simulate each dimension#
	dPdt <- P*Logis - PInduc + QInduc - (vP*P*Z)/(1 + ConsP + ConsQ) - mP*P#
	dQdt <- Q*Logis + PInduc - QInduc - (vQ*Q*Z)/(1 + ConsP + ConsQ) - mQ*Q#
	dZdt <- (nu*(vP*P + vQ*Q)*Z)/(1 + ConsP + ConsQ) - mZ*Z#
	#Save dXdt's as a vector for P, Q, and Z#
	dXdt <- c(dPdt, dQdt, dZdt)#
	return(dXdt)#
}#
#
# ================================================#
# = Main function to calculate dXdt at each step =#
# ================================================#
xRates_jac <- function(t, x0, parms, K, hQ=0.5, kQ=0.565, Exp=FALSE){#
	# ==============#
	# = Parameters =#
	# ==============#
	# K <- 5.0 #Carrying capacity, g/m^3#
	r <- 1.0 #Maximum growth rate of algae, day^-1#
	c <- 1.0 #scaling parameter for inducible effect, day^-1#
	g <- 0.1 #half-saturation constant for inducible effect, g/m^3#
	vP <- 0.5 #search rate on unicellular algae, m^2 g^-1 day^-1#
	hP <- 0.5 #handling time on unicellular algae, day#
	mP <- 0.2 #Mortality rate of unicellular algae, day^-1#
	vQ <- 0.5 #Search rate on colonial algae, m^3 g^-1 day^-1#
	# hQ <- 0.5 #Handling time on colonial algae at kQ = 0, day#
	# kQ <- 0.565 #Increasing rate of handling time on colonial algae, m^3 g^-1#
	mQ <- 0.2 #Mortality rate of colonial algae, day^-1#
	nu <- 0.4 #assimilation coefficient on algae#
	mZ <- 0.2 #Mortality rate of zooplankton, day^-1 #Changing mortality to 0.15 under the conditions of Fig. 5 in Serizawa 2007 produces weird oscillations at K>4.71#
	# =========================#
	# = State variable values =#
	# =========================#
	if(Exp){#
		P <- exp(x0[1])#
		Q <- exp(x0[2])#
		Z <- exp(x0[3])#
	}else{#
		P <- x0[1]#
		Q <- x0[2]#
		Z <- x0[3]#
	}#
	# =========#
	# = Rates =#
	# =========#
	#First define convenient, repeatable parts to the equations#
	Logis <- r*(1 - (P+Q)/K)#
	PInduc <- P*(c*Z^2)/(Z^2+g^2)#
	QInduc <- Q*(c*g^2)/(Z^2+g^2)#
	ConsP <- vP*hP*P#
	ConsQ <- vQ*hQ*Q*(1+kQ*Q)#
	#Simulate each dimension#
	dPdt <- P*Logis - PInduc + QInduc - (vP*P*Z)/(1 + ConsP + ConsQ) - mP*P#
	dQdt <- Q*Logis + PInduc - QInduc - (vQ*Q*Z)/(1 + ConsP + ConsQ) - mQ*Q#
	dZdt <- (nu*(vP*P + vQ*Q)*Z)/(1 + ConsP + ConsQ) - mZ*Z#
	#Save dXdt's as a vector for P, Q, and Z#
	dXdt <- c(dPdt, dQdt, dZdt)#
	return(dXdt)#
}#
#
Ar1 <-function(x){#
	# ac <- cor(x[-1],x[-length(x)])#
	ac <- ar.ols(x, order.max=1)$ar#
	# Nrmlzd <- x-mean(x)#
	# Y <- (x-mean(x))[-1]#
	# return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
	#return(arima(x, order=c(1,0,0))$coef[[1]])#
	return(ac)#
}#
#
Ar1 <-function(x){#
	ac <- cor(x[-1],x[-length(x)])#
	# Nrmlzd <- x-mean(x)#
	# Y <- (x-mean(x))[-1]#
	# return(lm(Nrmlzd[-1] ~ Nrmlzd[-length(x)])$coef[[2]])#
	#return(arima(x, order=c(1,0,0))$coef[[1]])#
	return(ac)#
}#
#
CH <- function(X){#
	nobs <- length(X)#
	Xt0 <- X[-c(1:4)]#
	Xt1 <- X[-c(1:3, nobs)]#
	Xt2 <- X[-c(1:2, (nobs-1):nobs)]#
	Xt3 <- X[-c(1, (nobs-2):nobs)]#
	Xt4 <- X[-c((nobs-3):nobs)]#
	ModelAR <- lm(Xt0~Xt1+Xt2+Xt3+Xt3+Xt4)#
	Res <- as.numeric(ModelAR$resid)#
	Res2 <- Res^2#
	Res2t0 <- Res2[-1]#
	Res2t1 <- Res2[-length(Res2)]#
	ModelCH <- lm(Res2t0~Res2t1)#
	R2 <- summary(ModelCH)$r.squared#
	# PosResult <- ifelse(Pvalue<=0.05,1,0)#
	return(R2)#
}#
#
SquealStats <- function(Data, WinSize){#
	StatNames <- c("Var", "AR1")#
	ReturnStats0 <- rbind(apply(Data, 2, rollapplyr, width=WinSize, var), apply(Data, 2, rollapplyr, width=WinSize, Ar1))#
	colnames(ReturnStats0) <- colnames(Data)#
	nstatsPer <- nrow(ReturnStats0)/length(StatNames)#
	ReturnStats1 <- data.frame(ReturnStats0, "Stat"=c(rep(StatNames[1],nstatsPer), rep(StatNames[2], nstatsPer)))#
	return(ReturnStats1)#
}#
# test <- SquealStats(Xobs, 5)#
# head(test)#
# tail(test)#
#
# SquealStats <- function(Data, WinSize){	#
	# ReturnStats <- data.frame("Var"=rollapplyr(Data, width=WinSize, FUN=var), "AR1"=rollapplyr(Data, width=WinSize, FUN=Ar1))#
	# return(ReturnStats)#
# }#
# , "CH"=rollapplyr(Data, width=WinSize, FUN=CH)#
#
#
# ===========================================================================================================#
# = Set up the simulation (given the options chosen at top of script, define duration, frequency, dt, etc.) =#
# ===========================================================================================================#
Nobs <- Days*DailySteps*nBurnSave #number of observations to be simulated#
Time <- seq(1,Days*nBurnSave+(1-1/DailySteps), by=1/DailySteps)#
dt <- 1/DailySteps #the size of the time step in units=days#
Kgrad <- rep(seq(Kstart, Kstop, length.out=Days), each=DailySteps*nBurnSave) #changes in carrying capacity for each Euler iteration, but K only changes between days, not within a day#
KgradDaily <- seq(Kstart, Kstop, length.out=Days)  #rep(seq(Kstart, Kstop, length.out=Days), each=nBurnSave) #changes in carrying capacity for each Euler iteration, but K only changes between days, not within a day#
Xobs <- matrix(data=NA, nrow=Nobs, ncol=3, dimnames=list(NULL,c("P","Q","Z"))) #To store the simulated state variables#
Xobs[1,] <- xNaught#
revXobs <- matrix(data=NA, nrow=Nobs, ncol=3, dimnames=list(NULL,c("P","Q","Z"))) #To store the simulated state variables#
revXobs[1,] <- revxNaught #Xobs[Nobs,] #Xobs[Nobs,]#*2#
#
# Noise <- matrix(rnorm(n=Nobs*3, mean=0, sd=0.001), nrow=Nobs, ncol=3)#
# AddNoise <- c(TRUE, FALSE)[2]#
#
# =====================================#
# = Simulate time series of P, Q, & Z =#
# =====================================#
Noise1 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]), rnorm(n=Nobs, sd=SigmaPQZ[2]), rnorm(n=Nobs, sd=SigmaPQZ[3])), ncol=3) * AddNoise#
Noise2 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]), rnorm(n=Nobs, sd=SigmaPQZ[2]), rnorm(n=Nobs, sd=SigmaPQZ[3])), ncol=3) * AddNoise#
#
KgradSim <- Kgrad + (rnorm(n=Nobs, sd=Ksd)*AddKnoise)#
# Knoise2 <- rnorm(n=Nobs, sd=Ksd)*AddKnoise#
#
CataNoise1 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[2]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[3]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata)), ncol=3) * AddCata#
CataNoise2 <- matrix(data=c(rnorm(n=Nobs, sd=SigmaPQZ[1]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[2]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata), rnorm(n=Nobs, sd=SigmaPQZ[3]*CataAmp)*rbinom(n=Nobs, size=1, prob=ProbCata)), ncol=3) * AddCata#
#
#Simulate while increasing k#
# Burnt <- array(dim=c(nBurn*DailySteps, ncol(Xobs), Days*nBurnSave), dimnames=list("BurnIn"=seq_len(nBurn*DailySteps), "State"=c("P","Q","Z"), "K"=rep(round(seq(Kstart, Kstop, length.out=Days),3),nBurnSave)))#
Burnt <- array(dim=c(nBurn*DailySteps, ncol(Xobs), Days), dimnames=list("BurnIn"=seq_len(nBurn*DailySteps), "State"=c("P","Q","Z"), "K"=round(seq(Kstart, Kstop, length.out=Days),3)))#
# plot(seq_len(Days), round(seq(Kstart, Kstop, length.out=Days),3))#
#
Burnt[1,,1] <- xNaught#
Last <- xNaught#
# iCountRoot <- 1#
iCount <- 1#
for(d in 1:Days){#
	Know <- KgradDaily[d]#
	for(b in seq_len(nBurn)){#
		# if(b<=(nBurn-nBurnSave)){#
			# iCount <- iCountRoot #reset the iCount value to what it would be if there was no burn-in period#
		# }#
		for(delT in 1:DailySteps){#
			if(d==1&b==1&delT==1){#
				next#
			}#
			bCount <- (b-1)*DailySteps + delT#
			# iCount <- (d-1)*DailySteps + delT#
			Burnt[bCount,,d] <- xRates(x0=Last, K=Know, kQ=kQuse)*dt + Last + (Noise1[iCount,] + CataNoise1[iCount,])*sqrt(dt)#
			Last <- Burnt[bCount,,d]#
			if(b>=(nBurn-nBurnSave+1)){#
				Xobs[iCount,] <- Last #xRates(x0=Xobs[iCount-1,], K=Know, kQ=kQuse)*dt + Xobs[iCount-1,] + (Noise1[iCount,] + CataNoise1[iCount,])*sqrt(dt)#
				iCount <- iCount+1#
			}#
		}#
	}#
}#
#
#
if(ForBac){#
	#Simulate while decreasing k#
	for(i in 2:Nobs){#
		revXobs[i,] <- xRates(x0=revXobs[i-1,], K=KgradSim[Nobs-i], kQ=kQuse)*dt + revXobs[i-1,] + Noise2[i,]*sqrt(dt)#
	}#
}#
#
#
# qui <- function(x) ma#
#
#
#Stability analysis#
Pvec <- seq(0.001, 1, length.out=nvec)#
Qvec <- seq(2, 5, length.out=nvec)#
Zvec <- seq(0.001, 2, length.out=nvec)#
Kvec <- seq(5, 7, length.out=nvec)#
StabilityStarts0 <- as.matrix(expand.grid(list("Pvec"=Pvec, "Qvec"=Qvec, "Zvec"=Zvec, "Kvec"=Kvec)))#
if(ExpStability){StabilityStarts <- log(StabilityStarts0)}#
# for(i in seq_len(nvec)){#
	# Roots0 <- multiroot(xRates, start=StabilityStarts[i,1:3], K=StabilityStarts[i,4], Exp=ExpStability)$root#
	# if(ExpStability){Roots <- exp(Roots0)}else{Roots <- Roots0}#
	# names(Roots) <- NULL#
	# JacMat <- jacobian.full(Roots, xRates_jac, K=StabilityStarts[i,4])#
	# Lambda <- eigen(JacMat, only.values=TRUE)#
	#
	# Pos <- ifelse(Roots[1]>0 & Roots[2]>0 & Roots[3],1,0) # is it positive?#
	# Stab <- ifelse(Re(Lamda$values[1])<0 & Re(Lamda$values[2])<0 & Re(Lamda$values[3])<0,1,0) # is it stable?#
	#
	# if(Im(Lamda$values[1])==0#
	#
	# Osc <- ifelse(Im(Lamda$values[1])!=0,1,0) # does it oscillate?\#
	#
	# Alogic <- matrix(c(0,0,0, 1,1,1#
	#
	# Atype <- 0 # Attractor type#
	# Atype <- ifelse(Pos==1 && Stab==1,1,0) # Stable point has Atype = 1#
	# Atype <- ifelse(Atype==0 && Osc==1,2,Atype ) # Limit cycle has Atype = 2#
# }#
#
#
#
#Calculate and plot Squeal Stats#
Xobs_daily <- apply(Xobs, 2, rollapply, width=DailySteps, mean, by=DailySteps)#
Time_daily <- rollapply(Time, width=DailySteps, mean, by=DailySteps)#
Kgrad_daily <- rollapply(Kgrad, width=DailySteps, mean, by=DailySteps)#
Stats_Xobs <- data.frame("Time"=rollapplyr(Time_daily, width=WinSize, max), "K"=rollapplyr(Kgrad_daily, width=WinSize, max), SquealStats(Xobs_daily, WinSize=WinSize))#
# Stats_Xobs <- data.frame("Time"=rollapplyr(Time, width=WinSize, max), SquealStats(Xobs, WinSize=WinSize))#
# head(Stats_Xobs); tail(Stats_Xobs)#
#
if(ForBac){#
	Xobs_daily_rev <- apply(revXobs, 2, rollapply, width=DailySteps, mean, by=DailySteps)#
	Time_daily_rev <- rollapply(Time, width=DailySteps, mean, by=DailySteps)#
	Kgrad_daily_rev <- rollapply(Kgrad[length(Kgrad):1], width=DailySteps, mean, by=DailySteps)#
	Stats_Xobs_rev <- data.frame("Time"=rollapplyr(Time_daily_rev, width=WinSize, max), "K"=rollapplyr(Kgrad_daily_rev, width=WinSize, max), SquealStats(Xobs_daily_rev, WinSize=WinSize))#
}#
#next use ggplot and ddply to make a multi-panel graph in one step.  this is going to be sick when it works.#
#
K2index <- which(Stats_Xobs[,"K"] >= K2graph[1] & Stats_Xobs[,"K"] <= K2graph[2])#
PQZ <- c("P", "Q", "Z")#
Statters <- unique(Stats_Xobs[,"Stat"])#
dev.new(width=8, height=8)#
par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
for(i in seq_along(PQZ)){#
	i_Xobs <- Stats_Xobs[K2index,c("Time", "K", PQZ[i],"Stat")]#
	for(j in seq_along(Statters)){#
		j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
		if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
		plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
		Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
		abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
		if(i!=3){axis(side=1, labels=FALSE)}#
		if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
		if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
		if(i==1){mtext("K", side=3, line=2.5, font=3)}#
		if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
		if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
		if(i==1){#
			Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(min(j_Xobs[,"K"]), max(j_Xobs[,"K"]), length.out=6),2))#
		}#
		# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
		#
	}#
	#
}#
#
#
if(ForBac){#
	#
	#
	K2index <- which(Stats_Xobs_rev[,"K"] >= K2graph_rev[1] & Stats_Xobs_rev[,"K"] <= K2graph_rev[2])#
	PQZ <- c("P", "Q", "Z")#
	Statters <- unique(Stats_Xobs_rev[,"Stat"])#
	dev.new(width=8, height=8)#
	par(mfrow=c(length(PQZ), length(Statters)), mar=c(1,3,1,0.1), oma=c(3, 1.5, 4, 0.4), cex=1)#
	for(i in seq_along(PQZ)){#
		i_Xobs <- Stats_Xobs_rev[K2index,c("Time", "K", PQZ[i],"Stat")]#
		for(j in seq_along(Statters)){#
			j_Xobs <- i_Xobs[which(i_Xobs[,"Stat"]==Statters[j]),]#
			if(i==3){Xaxt <- "s"}else{Xaxt <- "n"}#
			plot(j_Xobs[,"Time"], j_Xobs[,PQZ[i]], type="l", xlab="", ylab="", xaxt=Xaxt)#j_Xobs[,"Time"]#
			Ktranscrit <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==1.67)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			Khopf <- j_Xobs[round(median(which(round(j_Xobs[,"K"],2)==8.33)),0),"Time"] #serizawa 2008 figure 3, hq=0.5#
			abline(v=c(Ktranscrit, Khopf), col="blue", lty="dashed")#
			if(i!=3){axis(side=1, labels=FALSE)}#
			if(i!=1){axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=FALSE)}#
			if(i==1){mtext(Statters[j], side=3, line=4, font=2)}#
			if(i==1){mtext("K", side=3, line=2.5, font=3)}#
			if(i==3){mtext("Time", side=1, line=2.5, font=3)}#
			if(j==1){mtext(PQZ[i], side=2, line=3, font=2)}#
			if(i==1){#
				Kaxis <- axis(side=3, at=seq(min(j_Xobs[,"Time"]), max(j_Xobs[,"Time"]), length.out=6), labels=round(seq(max(j_Xobs[,"K"]), min(j_Xobs[,"K"]), length.out=6),2))#
			}#
			# if(i==1){axis(side=3, labels=pretty(Kaxis), at=pretty(j_Xobs[,"Time"]))}#
#
		}#
#
	}#
	#
}#
#
#
#
# axis(side=1, labels=TRUE, at=pretty(Kgrad), line=3)#
#
if(ForBac){#
	pYlim <- range(c(range(Xobs[,"P"]), range(revXobs[,"P"])))#
	qYlim <- range(c(range(Xobs[,"Q"]), range(revXobs[,"Q"])))#
	zYlim <- range(c(range(Xobs[,"Z"]), range(revXobs[,"Z"])))#
}else{#
	pYlim <- range(Xobs[,"P"])#
	qYlim <- range(Xobs[,"Q"])#
	zYlim <- range(Xobs[,"Z"])#
}#
#
#
dev.new(height=7, width=5)#
par(mfrow=c(3,1), mar=c(1,3,1,1), cex=1.25, oma=c(3,0,0,0))#
#
plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"P"], lwd=2, col="green")}#
axis(side=1, labels=FALSE)#
mtext("Unicell", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Q"], lwd=2, col="cyan")}#
axis(side=1, labels=FALSE)#
mtext("Colonial", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
if(ForBac){lines(rev(Kgrad), revXobs[,"Z"], lwd=2, col="magenta")}#
mtext("Zooplankton", side=2, line=2, cex=1.25)#
abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
if(ForBac){mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=3, cex=1.25)}else{mtext("K \n Dark = Increasing", side=1, line=3, cex=1.25)}#
#
#
#
# ==================================================================================#
# = Basically same plot as above, but in separate panels for fowards and backwards =#
# ==================================================================================#
if(ForBac){#
	dev.new(height=7, width=5)#
	par(mfrow=c(3,2), mar=c(1,1,1,1), cex=1.25, oma=c(3,2,0,0))#
#
	plot(Kgrad, Xobs[,"P"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="green4", ylim=pYlim)#
	axis(side=1, labels=FALSE)#
	mtext("Unicell", side=2, line=2, cex=1.25)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
	plot(rev(Kgrad), revXobs[,"P"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="green", ylim=pYlim, xlim=range(rev(Kgrad))[c(2,1)])#
	axis(side=1, labels=FALSE)#
	axis(side=2, labels=FALSE)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
	plot(Kgrad, Xobs[,"Q"], type="l", xaxt="n", xlab="", ylab="", lwd=2, col="cyan4", ylim=qYlim)#
	axis(side=1, labels=FALSE)#
	mtext("Colonial", side=2, line=2, cex=1.25)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
	plot(rev(Kgrad), revXobs[,"Q"], type="l", xaxt="n", yaxt="n", xlab="", ylab="", lwd=2, col="cyan",  ylim=qYlim, xlim=range(rev(Kgrad))[c(2,1)])#
	axis(side=1, labels=FALSE)#
	axis(side=2, labels=FALSE)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
#
	plot(Kgrad, Xobs[,"Z"], type="l", xlab="", ylab="", lwd=2, col="magenta4", ylim=zYlim)#
	mtext("Zooplankton", side=2, line=2, cex=1.25)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
#
	plot(rev(Kgrad), revXobs[,"Z"], type="l", xlab="", ylab="", yaxt="n", lwd=2, col="magenta", ylim=zYlim, xlim=range(rev(Kgrad))[c(2,1)])#
	axis(side=2, labels=FALSE)#
	abline(v=c(1.67, 8.33), col="blue", lty="dashed")#
	mtext("K \n Dark = Increasing, Light = Decreasing", side=1, line=2, cex=1.25, outer=TRUE)#
}#
#
#
# save.image("/Users/Battrd/Documents/School&Work/WiscResearch/BloomModel/Batt_Bloom_Seri08_v2_27Sept2012.RData")#
#
dev.new()#
par(mfrow=c(5,5), mar=c(2,2,0.5,0.5))#
for(i in c(trunc(seq(1,667,length.out=13)), trunc(seq(675,1000,length.out=12)))){#
	Color <- ifelse(round(KgradDaily[i],1)==8.3, "blue", "black")#
	plot(Burnt[,2,i], type="o", ylab="", xlab="", col=Color)#
}#
#
# plot(1:20000, Noise1[,2])#
#
# save.image("/Users/Battrd/Documents/School&Work/WiscResearch/BloomModel/Batt_Bloom_Seri08_v2_27Sept2012_longer.RData")
c(0.0001, 0.00256, 0.0019)*0.05
sequence(7.333, 9.333, length.out=500)
seq(7.333, 9.333, length.out=500)
rm(list=ls())#
graphics.off()#
library("plyr")#
#
setwd("/Users/Battrd/Documents/School&Work/WiscResearch/Data/IsotopeData2012")#
DataAll0 <- read.csv("WardIsotopes_2010&2012_09Jan2013.csv")#
DataAll <- subset(DataAll0, Taxon!="Nija" & !is.element(SampleID, c("O-0362", "V-0270", "P-1202", "P-1166", "O-0382", "P-1165", "P-1206", "P-1238", "P-1239", "P-1243", "Z-1110", "Z-1115", "Z-1195", "Z-1170", "O-0405")) & is.na(FishID))#
#
setwd("/Users/Battrd/Documents/School&Work/WiscResearch/Isotopes_2012Analysis")#
load("WardMetabolism_WardMetab2012_v1.RData")#
load("Chla_WardMetab2012_v1.RData")#
load("Photic_WardMetab2012_v1.RData")#
load("DOM_WardMetab2012_v1.RData")#
load("Ward2012_AquaConc.RData")#
#
#
#
# ========================#
# = Plot "invertebrates" =#
# ========================#
dev.new(width=8, height=7)#
par(mfrow=c(2,2), mar=c(2.5,4,1,1))#
# =============#
# = Calanoids =#
# =============#
InverYlim <- NULL#
CalanoidD <- subset(DataAll, Type=="Zooplankton" & Taxon=="Calanoid")#
boxplot(dD~Week*Year*as.character(Habitat), data=CalanoidD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),4), ylim=InverYlim)#
abline(v=8.5)#
text(c(3, 11), -240, c("Epilimnion", "Metalimnion"), font=4, cex=0.9)#
mtext("Calanoid dD (‰)", side=2, line=2.5)#
legend("topright", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")#
#
boxplot(d13C~Week*Year*as.character(Habitat), data=CalanoidD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),4), ylim=InverYlim)#
abline(v=8.5)#
mtext("Calanoid d13C (‰)", side=2, line=2.5)#
#
boxplot(d15N~Week*Year*as.character(Habitat), data=CalanoidD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),4), ylim=InverYlim)#
abline(v=8.5)#
mtext("Calanoid d15N (‰)", side=2, line=2.5)#
#
#
# =============#
# = Chaoborus =#
# =============#
dev.new(width=8, height=7)#
par(mfrow=c(2,2), mar=c(2.5,4,1,1))#
#
ChaobD <- subset(DataAll, Type=="Zooplankton" & Taxon=="Chaoborus")#
boxplot(dD~Week*Year, data=ChaobD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),2), ylim=InverYlim)#
mtext("Chaoborus dD (‰)", side=2, line=2.5)#
text(3, -240, c("Depth Integrated"), font=4, cex=0.9)#
#
boxplot(d13C~Week*Year, data=ChaobD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),2), ylim=InverYlim)#
mtext("Chaoborus d13C (‰)", side=2, line=2.5)#
text(3, -240, c("Depth Integrated"), font=4, cex=0.9)#
legend("topright", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")#
#
boxplot(d15N~Week*Year, data=ChaobD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),2), ylim=InverYlim)#
mtext("Chaoborus d15N (‰)", side=2, line=2.5)#
text(3, -240, c("Depth Integrated"), font=4, cex=0.9)#
#
# =============#
# = Mesocyclops =#
# =============#
dev.new(width=8, height=7)#
par(mfrow=c(2,2), mar=c(2.5,4,1,1))#
#
MesoD <- subset(DataAll, Type=="Zooplankton" & Taxon=="Mesocyclops")#not enough points to detect seasonal differences.  Years appear similar.#
boxplot(dD~Week*Year, data=MesoD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),2), ylim=InverYlim)#
mtext("Mesocyclops dD (‰)", side=2, line=2.5)#
text(3, -240, "Metalimnion Only", font=4, cex=0.9)#
legend("topleft", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")#
#
boxplot(d13C~Week*Year, data=MesoD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),2), ylim=InverYlim)#
mtext("Mesocyclops d13C (‰)", side=2, line=2.5)#
text(3, -240, "Metalimnion Only", font=4, cex=0.9)#
#
boxplot(d15N~Week*Year, data=MesoD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),2), ylim=InverYlim)#
mtext("Mesocyclops d15N (‰)", side=2, line=2.5)#
text(3, -240, "Metalimnion Only", font=4, cex=0.9)#
#
# =============#
# = Snail =#
# =============#
dev.new(width=8, height=7)#
par(mfrow=c(2,2), mar=c(2.5,4,1,1))#
SnailD <- subset(DataAll, Type=="Snail")#
#Snails were very similar within and between years, with the exception that in June of 2012 the snails were ~25‰ more depleted than at any other sampling period.#
SnailMonths <- c("May","Jun","Jul","Aug")[expand.grid(sort(unique(SnailD[,"Week"])), sort(unique(SnailD[,"Year"])))[,1]]#
SnailYears <- as.character(expand.grid(sort(unique(SnailD[,"Week"])), sort(unique(SnailD[,"Year"])))[,2])#
BGcols <- c("2010"="#FA807225", "2012"="#3A5FCD25")[SnailYears]#
FG2010 <- c("2010"="red", "2012"="blue")[SnailYears]#
boxplot(dD~Week*Year, data=SnailD, col=BGcols, border=FG2010, names=SnailMonths, ylim=InverYlim)#
mtext("Snail dD (‰)", side=2, line=2.5)#
boxplot(d13C~Week*Year, data=SnailD, col=BGcols, border=FG2010, names=SnailMonths, ylim=InverYlim)#
mtext("Snail d13C (‰)", side=2, line=2.5)#
legend("topright", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")#
boxplot(d15N~Week*Year, data=SnailD, col=BGcols, border=FG2010, names=SnailMonths, ylim=InverYlim)#
mtext("Snail d15N (‰)", side=2, line=2.5)#
#
#
#
#
# =======#
# = POM =#
# =======#
dev.new(width=8, height=7)#
par(mfrow=c(2,2), mar=c(2.5,4,1,1))#
PomD <- subset(DataAll, Type=="POM" & Habitat!="Hypo" & Habitat!="Littoral")#
boxplot(dD~Week*Year*as.character(Habitat), data=PomD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),4))#
abline(v=8.5)#
text(c(3, 14), -225, c("Epilimnion", "Metalimnion"), font=4, cex=0.9)#
mtext("POM dD (‰)", side=2, line=2.5)#
legend("topleft", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n", inset=c(0.05,0))#
#
boxplot(d13C~Week*Year*as.character(Habitat), data=PomD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),4))#
abline(v=8.5)#
mtext("POM d13C (‰)", side=2, line=2.5)#
#
boxplot(d15N~Week*Year*as.character(Habitat), data=PomD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),4))#
abline(v=8.5)#
mtext("POM d15N (‰)", side=2, line=2.5)#
#
# =============#
# = Periphyton =#
# =============#
dev.new(width=8, height=7)#
par(mfrow=c(2,2), mar=c(2.5,4,1,1))#
PeriD <- subset(DataAll, Type=="Periphyton")#
PeriMonths <- c("May","Jun","Jul","Aug")[expand.grid(sort(unique(PeriD[,"Week"])), sort(unique(PeriD[,"Year"])))[,1]]#
RepYearCol <- length(PeriMonths)/2#
boxplot(dD~Week*Year, data=PeriD, col=c(rep("#FA807225",RepYearCol), rep("#3A5FCD25",RepYearCol)), border=c(rep("red",RepYearCol), rep("blue",RepYearCol)), names=PeriMonths)#
mtext("Periphyton dD (‰)", side=2, line=2.5)#
boxplot(d13C~Week*Year, data=PeriD, col=c(rep("#FA807225",RepYearCol), rep("#3A5FCD25",RepYearCol)), border=c(rep("red",RepYearCol), rep("blue",RepYearCol)), names=PeriMonths)#
mtext("Periphyton d13C (‰)", side=2, line=2.5)#
legend("topright", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")#
boxplot(d15N~Week*Year, data=PeriD, col=c(rep("#FA807225",RepYearCol), rep("#3A5FCD25",RepYearCol)), border=c(rep("red",RepYearCol), rep("blue",RepYearCol)), names=PeriMonths)#
mtext("Periphyton d15N (‰)", side=2, line=2.5)#
#
# =============#
# = DOM =#
# =============#
dev.new(width=8, height=7)#
par(mfrow=c(2,2), mar=c(2.5,4,1,1))#
DomD <- subset(DataAll, Type=="DOM" & Habitat!="Hypo")#
DomMonths <- c("May","Jun","Jul","Aug")[expand.grid(sort(unique(DomD[,"Week"])), sort(unique(DomD[,"Year"])), sort(unique(DomD[,"Habitat"])))[,1]]#
RepYearCol <- length(DomMonths)/2#
DomYears <- as.character(expand.grid(sort(unique(DomD[,"Week"])), sort(unique(DomD[,"Year"])), sort(unique(DomD[,"Habitat"])))[,2])#
BGcols <- c("2010"="#FA807225", "2012"="#3A5FCD25")[DomYears]#
FG2010 <- c("2010"="red", "2012"="blue")[DomYears]#
boxplot(dD~Week*Year*as.character(Habitat), data=DomD, col=BGcols, border=FG2010, names=DomMonths)#
abline(v=6.5)#
text(c(1.75, 8.25), -164, c("Epilimnion", "Metalimnion"), font=4, cex=0.9)#
mtext("DOM dD (‰)", side=2, line=2.5)#
#
boxplot(d13C~Week*Year*as.character(Habitat), data=DomD, col=BGcols, border=FG2010, names=DomMonths)#
abline(v=6.5)#
mtext("DOM d13C (‰)", side=2, line=2.5)#
legend("topright", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")#
#
boxplot(d15N~Week*Year*as.character(Habitat), data=DomD, col=BGcols, border=FG2010, names=DomMonths)#
abline(v=6.5)#
mtext("DOM d15N (‰)", side=2, line=2.5)#
#
# =============#
# = Water =#
# =============#
dev.new(width=8, height=7)#
par(mar=c(2.5,4,1,1))#
WaterD <- subset(DataAll, Type=="Water" & Habitat!="Hypo")#
Watermonths <- c("May","Jun","Jul","Aug")[expand.grid(sort(unique(WaterD[,"Week"])), sort(unique(WaterD[,"Year"])), sort(unique(WaterD[,"Habitat"])))[,1]]#
RepYearCol <- length(Watermonths)/2#
boxplot(dD~Week*Year*as.character(Habitat), data=WaterD, col=c(rep("#FA807225",4), rep("#3A5FCD25",4)), border=c(rep("red",4), rep("blue",4)), names=rep(c("May","Jun","Jul","Aug"),4))#
mtext("Water dD (‰)", side=2, line=2.5)#
abline(v=8.5)#
text(c(3, 14), -75, c("Epilimnion", "Metalimnion"), font=4, cex=0.9)#
legend("topleft", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")#
#
#
#
# =============#
# = Fish =#
# =============#
AllFishD <- subset(DataAll, Type=="Fish" & Tissue=="Whole" & Taxon!="YWP") #& Taxon!="PKS"#
#
FishSpecies <- as.character(unique(subset(DataAll, Type=="Fish" & Tissue=="Whole", select=Taxon))[,])#
#
for(i in 1:length(FishSpecies)){#
	dev.new(width=8, height=7)#
	par(mfrow=c(2,2), mar=c(2,3.5,1,1), ps=10, cex=1)#
	ThisFish <- FishSpecies[i]#
	FishD <- subset(DataAll, Type=="Fish" & Taxon==ThisFish & Tissue=="Whole")#
	FishMonths <- c("May","Jun","Jul","Aug")[expand.grid(sort(unique(FishD[,"Week"])), sort(unique(FishD[,"Year"])))[,1]]#
	RepYearCol <- length(FishMonths)/2#
	boxplot(dD~Week*Year, data=FishD, col=c(rep("#FA807225",RepYearCol), rep("#3A5FCD25",RepYearCol)), border=c(rep("red",RepYearCol), rep("blue",RepYearCol)), names=FishMonths)#
	mtext(paste(ThisFish, "dD (‰)"), side=2, line=2.5)#
	legend("topleft", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")#
	#
	boxplot(d13C~Week*Year, data=FishD, col=c(rep("#FA807225",RepYearCol), rep("#3A5FCD25",RepYearCol)), border=c(rep("red",RepYearCol), rep("blue",RepYearCol)), names=FishMonths)#
	mtext(paste(ThisFish, "d13C (‰)"), side=2, line=2.5)#
	#
	boxplot(d15N~Week*Year, data=FishD, col=c(rep("#FA807225",RepYearCol), rep("#3A5FCD25",RepYearCol)), border=c(rep("red",RepYearCol), rep("blue",RepYearCol)), names=FishMonths)#
	mtext(paste(ThisFish, "d15N (‰)"), side=2, line=2.5)#
}#
#
#
# =============#
# = Vegetation =#
# =============#
AllVegD <- subset(DataAll, Type=="Macrophyte") #& Taxon!="PKS"#
summary(lm(dD~as.factor(Year)+Taxon*Week, data=AllVegD))#
#No differences between years was detected for any species.  However, there really isn't enough 2012 data for any of the species to detect a seasonal trend, b/c each species only had 2 2012 samples sent in for analysis.  There really isn't anything too striking here.#
VegSpecies <- as.character(unique(subset(DataAll, is.element(Type, c("Macrophyte", "Terrestrial")), select=Taxon))[,])#
VegKey <- c("Nuphar"="Nuphar", "Brasenia schreberi"="B. schreberi", "Sedge"="Sedge", "Alder"="Alder", "Potamogeton pusillus"="P. pusillus", "Chara"="Chara", "Nymphaea odorata"="N. odorata", "Najas flexilis"="N. flexilis", "Nuphar variegata"="N. variegata", "Tamarack"="Tamarack", "Potamogeton amplifolius"="P. amplif", "Pickerell Weed"="Pick Weed", "Potamogeton nodosus"="P. nodosus")#
dev.new(width=7, height=6)#
par(mfrow=c(4,3), mar=c(2,3,1,1), ps=9, cex=1)#
for(i in 1:length(VegSpecies)){#
	ThisVeg <- VegSpecies[i]#
	VegD <- subset(DataAll, is.element(Type, c("Macrophyte", "Terrestrial")) & Taxon==ThisVeg)#
	#
	VegMonths <- c("May","Jun","Jul","Aug")[expand.grid(sort(unique(VegD[,"Week"])), sort(unique(VegD[,"Year"])))[,1]]#
	VegYears <- as.character(expand.grid(sort(unique(VegD[,"Week"])), sort(unique(VegD[,"Year"])))[,2]) #as.character(VegD[,"Year"])#
	BGcols <- c("2010"="#FA807225", "2012"="#3A5FCD25")[VegYears]#
	FG2010 <- c("2010"="red", "2012"="blue")[VegYears]#
	boxplot(dD~Week*Year, data=VegD, col=BGcols, border=FG2010, names=VegMonths)#
	mtext(VegKey[ThisVeg], side=2, line=2)#
	if(i==2){legend("topright", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")}#
}#
#
#
#
#
#
solve(a=matrix(data=c(-238,1,-135,1), nrow=2), b=matrix(data=c(-175,1), nrow=2))#
#
#
#
#
# ====================#
# = Metabolism Plots =#
# ====================#
#
Metabolism_Plots <- expand.grid(c("GPP", "R", "NEP"), c("BK", "LM"))#
dev.new(width=9, height=6)#
par(mfrow=c(2,3), mar=c(2,3.5,1,1), ps=10, cex=1, oma=c(0,1,2,0))#
#
for(i in 1:nrow(Metabolism_Plots)){#
	MetabD <- subset(WardMetabolism, Method==as.character(Metabolism_Plots[i,2]))#
	#
	MetabMonths <- c("Apr","May","Jun","Jul","Aug")[1+expand.grid(sort(unique(MetabD[,"Week"])), sort(unique(MetabD[,"Year"])))[,1]]#
	RepYearCol <- length(MetabMonths)/2#
	#
	Response <- MetabD[,as.character(Metabolism_Plots[i,1])]#
	Pred_Week <- as.numeric(MetabD[,"Week"])#
	Pred_Year <- as.factor(MetabD[,"Year"])#
	# dev.new()#
	boxplot(Response~Pred_Week*Pred_Year, data=MetabD, col=c(rep("#FA807225",RepYearCol), rep("#3A5FCD25",RepYearCol)), border=c(rep("red",RepYearCol), rep("blue",RepYearCol)), names=MetabMonths)#
	# abline(v=8.5)#
	# text(c(2, 10.5), -240, c("Epilimnion", "Metalimnion"), font=4, cex=1.25)#
	# mtext(as.character(Metabolism_Plots[i,]), side=2, line=2.5)#
	if(i==1){mtext("BK", side=2, line=2.5)}#
	if(i==1){mtext("GPP", side=3, line=1)}#
	if(i==2){mtext("R", side=3, line=1)}#
	if(i==3){mtext("NEP", side=3, line=1)}#
	if(i==4){mtext("LM", side=2, line=2.5)}#
	if(i==1){legend("topleft", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n")}#
}#
#
colMeans(WardMetabolism[,-c(1:4)])#
#
summary(lm(GPP~as.factor(Year)*Method + Method*relevel(as.factor(Week),5) +relevel(as.factor(Week),5)*as.factor(Year), data=WardMetabolism))#
#The grand mean of gross primary production was 35 µmol O2/ L / d. The volumetric rate of GPP was not significantly different between years (p=0.6853). May GPP was lower in 2012 than in 2010 (14 µmol O2/ L / d lower, p=0.0366).  On the other hand, there were stronger month-to-month differences in GPP in 2012 than in 2010.  For example, July GPP was high in 2012, and May GPP was low in 2012. On average, there was no detectable difference between GPP estimates from the two methods (linear model [LM] and bookkeeping [BK]) (p=0.3692). However, the seasonal pattern in GPP was different between methods. April metabolism was only measured in 2012. Despite the models being generally similar, the April 2012 GPP estimate was lower for the LM method than it was for BK method (18 µmol O2/ L / d lower, p=0.0580). If such month-specific differences between the methods are accounted for, then LM is shown to have slightly higher estimates of GPP in 2012 than BK in 2012 (8 µmol O2/ L / d, p=0.0717).  The adjusted R^2 for this model was 0.2291.#
#
summary(lm(R~as.factor(Year)*Method + Method*relevel(as.factor(Week),5) +relevel(as.factor(Week),5)*as.factor(Year), data=WardMetabolism))#
#The grand mean of respiration was 39 µmol O2/ L / d.  The volumetric rate of R was significantly greater in 2012 than it was in 2010 (25 µmol O2/ L / d greater, p=2.63e-06).  Overall, our data did not reveal a difference between the two methods' estimates of R (p=0.313). However, 2012 R estimated by LM was significantly lower than 2012 R estimated by BK (23 µmol O2/ L / d less respiration for LM 2012 than for BK 2012, p=4.56e-06).  This effectively means that both methods estimated greater R in 2012 than in 2010, but the difference between years was much greater for BK (25) than for LM (25-23=2). In general, respiration rates tended to increase over the season (low R in April, high R in August). The LM method estimated much greater rates of April 2012 R than did the BK method (32 µmol O2/ L / d, p=0.001808).  June and July R was much greater in 2012 than in 2010 (24 and 25 µmol O2/ L / d, respectively; p=0.000413 and p=0.000123, respectively).  The adjusted R^2 for this model was 0.4149.#
#
#
summary(lm(NEP~as.factor(Year)*Method + Method*relevel(as.factor(Week),5) +relevel(as.factor(Week),5)*as.factor(Year), data=WardMetabolism))#
#The grand mean of net ecosystem production was -4 µmol O2/ L / d.  In summer, BK estimates that 2012 NEP is much lower than 2010 NEP (27 µmol O2/ L / d lower, p=2.84e-12), while LM adjusts this estimate upwards by 31 µmol O2/ L / d (p<2e-16), such that NEP is ~0 (the intercept was -4 µmol O2/ L / d).  In addition to the overall balance between the years, BK also shows large differences between the monthly rates of NEP, especially in 2010 (in 2012 BK estimates April NEP as positive, while the other weeks are negative).  The adjusted R^2 for this model was 0.381.#
#
# =====================#
# = Chlorophyll Plots =#
# =====================#
Chla_Habitat <- c()#
Chla_Habitat[which(Chla[,"Depth"] <=1)] <- "Epi"#
Chla_Habitat[which(Chla[,"Depth_ID"] == "M")] <- "Meta"#
Chla_Habitat[which(Chla[,"Depth"] >1 & Chla[,"Depth_ID"] != "M")] <- "Other"#
# ChlaD <- data.frame(Chla[which(Chla_Habitat!="Other"),], "Habitat"=Chla_Habitat[which(Chla_Habitat!="Other")])#
dev.new(width=4, height=7)#
par(mfrow=c(2,1), mar=c(3,4,1,1))#
for(i in 1:2){#
	ChlaD <- data.frame(Chla[which(Chla_Habitat==c("Epi", "Meta")[i]),], "Habitat"=Chla_Habitat[which(Chla_Habitat==c("Epi", "Meta")[i])])#
	ChlaMonths <- c("April","May","Jun","Jul","Aug")[expand.grid(sort(1+unique(ChlaD[,"Week"])), sort(unique(ChlaD[,"Year"])))[,1]]#
	RepYearCol <- length(ChlaMonths)/2#
	ChlaYears <- as.character(expand.grid(sort(unique(ChlaD[,"Week"])), sort(unique(ChlaD[,"Year"])), sort(unique(ChlaD[,"Habitat"])))[,2])#
	BGcols <- c("2010"="#FA807225", "2012"="#3A5FCD25")[ChlaYears]#
	FG2010 <- c("2010"="red", "2012"="blue")[ChlaYears]#
	boxplot(Chla~Week*Year, data=ChlaD, col=BGcols, border=FG2010, names=ChlaMonths)#
	# abline(v=6.5)#
	# text(c(1.75, 8.25), -164, c("Epilimnion", "Metalimnion"), font=4, cex=0.9)#
	if(i==1){legend("topleft", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n", inset=c(-0.06,0))}#
	mtext(c("Epilimnetic Chla (µg/L)","Metalimnetic Chla (µg/L)")[i], side=2, line=2.5)#
}#
#
# =====================#
# = Photic Zone Plots =#
# =====================#
Perc1 <- function(x){x[which.min(abs(x[,"PercSurf"]-0.01)),]}#
PhoticD <- ddply(Photic, .variables=c("Year","DoY"), .fun=Perc1)#
dev.new(width=7, height=7)#
par(mar=c(4,4,1,4))#
with(PhoticD[which(PhoticD[,"Year"]==2010),], plot(DoY, Depth, type="o", ylim=c(5,0), xlim=c(105,240), col="red", ylab="", xlab=""))#
with(PhoticD[which(PhoticD[,"Year"]==2012),], lines(DoY, Depth, type="o", ylim=c(5,0), xlim=c(105,240), col="blue"))#
mtext("Day of year", side=1, line=2.5)#
mtext("Depth (m)", side=2, line=2.5)#
legend("bottomleft", c("Photic Depth (2010)", "Photic Depth (2012)", "[Aquashade]"), text.col=c("red", "blue", "darkturquoise"), bty="n", inset=c(-0.03,0))#
par(new=TRUE)#
AquaDoY <- as.numeric(format.Date(OrderedFileDates, format="%j"))#
plot(AquaDoY, EstAquashadeConc, xlim=c(105,240), ylim=c(0,2), type="o", col="darkturquoise", xaxt="n", yaxt="n", xlab="", ylab="")#
axis(side=4)#
mtext("Aquashade (ppm)", side=4, line=2.5)#
#
#
#
#
# =====================#
# = DOM Plots =#
# =====================#
dev.new(width=4, height=7)#
par(mfrow=c(2,1), mar=c(3,4,1,1))#
for(i in 1:2){#
	DOMD <- subset(DOM, Habitat==c("Epi","Meta")[i])#
	DOMMonths <- c("Apr","May","Jun","Jul","Aug")[expand.grid(sort(1+unique(DOMD[,"Week"])), sort(unique(DOMD[,"Year"])))[,1]]#
	RepYearCol <- length(DOMMonths)/2#
	DOMYears <- as.character(expand.grid(sort(unique(DOMD[,"Week"])), sort(unique(DOMD[,"Year"])), sort(unique(DOMD[,"Habitat"])))[,2])#
	BGcols <- c("2010"="#FA807225", "2012"="#3A5FCD25")[DOMYears]#
	FG2010 <- c("2010"="red", "2012"="blue")[DOMYears]#
	boxplot(DOM~Week*Year, data=DOMD, col=BGcols, border=FG2010, names=DOMMonths)#
	# abline(v=6.5)#
	# text(c(1.75, 8.25), -164, c("Epilimnion", "Metalimnion"), font=4, cex=0.9)#
	if(i==2){legend("topleft", c("Reference (2010)", "Aquashade (2012)"), text.col=c("red", "blue"), bty="n", inset=c(-0.06,0))}#
	mtext(c("Epilimnetic DOM (mg/L)","Metalimnetic DOM (mg/L)")[i], side=2, line=2.5)#
}#
#
#
#
#
DOM_Conc_2010 <- mean(subset(DOM, Year==2010 & Habitat=="Epi", select="DOM")[,])#
DOM_Conc_2012 <- mean(subset(DOM, Year==2012 & Habitat=="Epi", select="DOM")[,])#
#
DOM_dD_2010 <- mean(subset(DomD, Year==2010 & Habitat=="Epi", select="dD")[,])#
DOM_dD_2012 <- mean(subset(DomD, Year==2012 & Habitat=="Epi", select="dD")[,])#
#
(DOM_dD_2012 - ((DOM_Conc_2010/DOM_Conc_2012)*DOM_dD_2010))/((DOM_Conc_2012-DOM_Conc_2010)/(DOM_Conc_2012))#
#
(DOM_dD_2012-((1.5/DOM_Conc_2012)*-64))/((DOM_Conc_2012-1.5)/DOM_Conc_2012)
